Question,Answer
What is Amazon Elastic Compute Cloud (Amazon EC2)?,"Amazon Elastic Compute Cloud (Amazon EC2) is a web service that provides resizable compute capacity in 
the cloud
. It is designed to make web-scale computing easier for developers."
What can I do with Amazon EC2?,"Just as Amazon Simple Storage Service (Amazon S3) enables storage in the cloud, Amazon EC2 enables “compute” in the cloud. Amazon EC2’s simple web service interface allows you to obtain and configure capacity with minimal friction. It provides you with complete control of your computing resources and lets you run on Amazon’s proven computing environment. Amazon EC2 reduces the time required to obtain and boot new server instances to minutes, allowing you to quickly scale capacity, both up and down, as your computing requirements change. Amazon EC2 changes the economics of computing by allowing you to pay only for capacity that you actually use."
How can I get started with Amazon EC2?,"To sign up for Amazon EC2, click the “Sign up for This Web Service” button on the Amazon EC2 detail page. You must have an Amazon Web Services account to access this service; if you do not already have one, you will be prompted to create one when you begin the Amazon EC2 sign-up process. After signing up, please refer to the 
Amazon EC2 documentation
, which includes our Getting Started Guide."
Why am I asked to verify my phone number when signing up for Amazon EC2?,Amazon EC2 registration requires you to have a valid phone number and email address on file with AWS in case we ever need to contact you. Verifying your phone number takes only a couple of minutes and involves receiving a phone call during the registration process and entering a PIN number using the phone key pad.
What can developers now do that they could not before?,"Until now, small developers did not have the capital to acquire massive compute resources and ensure they had the capacity they needed to handle unexpected spikes in load. Amazon EC2 enables any developer to leverage Amazon’s own benefits of massive scale with no up-front investment or performance compromises. Developers are now free to innovate knowing that no matter how successful their businesses become, it will be inexpensive and simple to ensure they have the compute capacity they need to meet their business requirements.
The “Elastic” nature of the service allows developers to instantly scale to meet spikes in traffic or demand. When computing requirements unexpectedly change (up or down), Amazon EC2 can instantly respond, meaning that developers have the ability to control how many resources are in use at any given point in time. In contrast, traditional hosting services generally provide a fixed number of resources for a fixed amount of time, meaning that users have a limited ability to easily respond when their usage is rapidly changing, unpredictable, or is known to experience large peaks at various intervals."
How do I run systems in the Amazon EC2 environment?,"Once you have set up your account and select or create your AMIs, you are ready to boot your instance. You can start your AMI on any number of On-Demand instances by using the RunInstances API call. You simply need to indicate how many instances you wish to launch. If you wish to run more than 20 On-Demand instances, complete the 
Amazon EC2 instance request form
.
If Amazon EC2 is able to fulfill your request, RunInstances will return success, and we will start launching your instances. You can check on the status of your instances using the DescribeInstances API call. You can also programmatically terminate any number of your instances using the TerminateInstances API call.
If you have a running instance using an Amazon EBS boot partition, you can also use the StopInstances API call to release the compute resources but preserve the data on the boot partition. You can use the StartInstances API when you are ready to restart the associated instance with the Amazon EBS boot partition.
In addition, you have the option to use Spot Instances to reduce your computing costs when you have flexibility in when your applications can run. Read more about Spot Instances for a more detailed explanation on how 
Spot Instances
 work.
If you prefer, you can also perform all these actions from the 
AWS Management Console
 or through the command line using our command line tools, which have been implemented with this web service API."
What is the difference between using the local instance store and Amazon Elastic Block Store (Amazon EBS) for the root device?,"When you launch your Amazon EC2 instances you have the ability to store your root device data on Amazon EBS or the local instance store. By using Amazon EBS, data on the root device will persist independently from the lifetime of the instance. This enables you to stop and restart the instance at a subsequent time, which is similar to shutting down your laptop and restarting it when you need it again.
Alternatively, the local instance store only persists during the life of the instance. This is an inexpensive way to launch instances where data is not stored to the root device. For example, some customers use this option to run large web sites where each instance is a clone to handle web traffic."
How quickly will systems be running?,"It typically takes less than 10 minutes from the issue of the RunInstances call to the point where all requested instances begin their boot sequences. This time depends on a number of factors including: the size of your AMI, the number of instances you are launching, and how recently you have launched that AMI. Images launched for the first time may take slightly longer to boot."
How do I load and store my systems with Amazon EC2?,"Amazon EC2 allows you to set up and configure everything about your instances from your operating system up to your applications. An Amazon Machine Image (AMI) is simply a packaged-up environment that includes all the necessary bits to set up and boot your instance. Your AMIs are your unit of deployment. You might have just one AMI or you might compose your system out of several building block AMIs (e.g., webservers, appservers, and databases). Amazon EC2 provides a number of tools to make creating an AMI easy. Once you create a custom AMI, you will need to bundle it. If you are bundling an image with a root device backed by Amazon EBS, you can simply use the bundle command in the AWS Management Console. If you are bundling an image with a boot partition on the instance store, then you will need to use the AMI Tools to upload it to Amazon S3. Amazon EC2 uses Amazon EBS and Amazon S3 to provide reliable, scalable storage of your AMIs so that we can boot them when you ask us to do so.
Or, if you want, you don’t have to set up your own AMI from scratch. You can choose from a number of globally available AMIs that provide useful instances. For example, if you just want a simple Linux server, you can choose one of the standard Linux distribution AMIs."
How do I access my systems?,"The RunInstances call that initiates execution of your application stack will return a set of DNS names, one for each system that is being booted. This name can be used to access the system exactly as you would if it were in your own data center. You own that machine while your operating system stack is executing on it."
Is Amazon EC2 used in conjunction with Amazon S3?,"Yes, Amazon EC2 is used jointly with Amazon S3 for instances with root devices backed by local instance storage. By using Amazon S3, developers have access to the same highly scalable, reliable, fast, inexpensive data storage infrastructure that Amazon uses to run its own global network of web sites. In order to execute systems in the Amazon EC2 environment, developers use the tools provided to load their AMIs into Amazon S3 and to move them between Amazon S3 and Amazon EC2. See 
How do I load and store my systems with Amazon EC2?
 for more information about AMIs.
We expect developers to find the combination of Amazon EC2 and Amazon S3 to be very useful. Amazon EC2 provides cheap, scalable compute in the cloud while Amazon S3 allows users to store their data reliably."
How many instances can I run in Amazon EC2?,"You are limited to running up to a total of 20 On-Demand instances across the instance family, purchasing 20 Reserved Instances, and requesting Spot Instances per your 
dynamic Spot limit
 per region. New AWS accounts may start with limits that are lower than the limits described here. Certain instance types are further limited per region as follows:
Note that cc2.8xlarge, hs1.8xlarge, cr1.8xlarge, G2, D2, and I2 instances are not available in all regions.
If you need more instances, complete the 
Amazon EC2 instance request form
 with your use case and your instance increase will be considered. Limit increases are tied to the region they were requested for."
Are there any limitations in sending email from Amazon EC2 instances?,"Yes. In order to maintain the quality of Amazon EC2 addresses for sending email, we enforce default limits on the amount of email that can be sent from EC2 accounts. If you wish to send larger amounts of email from EC2, you can apply to have these limits removed from your account by 
filling out this form
."
How quickly can I scale my capacity both up and down?,"Amazon EC2 provides a truly elastic computing environment. Amazon EC2 enables you to increase or decrease capacity within minutes, not hours or days. You can commission one, hundreds or even thousands of server instances simultaneously. When you need more instances, you simply call RunInstances, and Amazon EC2 will typically set up your new instances in a matter of minutes. Of course, because this is all controlled with web service APIs, your application can automatically scale itself up and down depending on its needs."
What operating system environments are supported?,"Amazon EC2 currently supports a variety of operating systems including: Amazon Linux, Ubuntu, Windows Server, Red Hat Enterprise Linux, SUSE Linux Enterprise Server, Fedora, Debian, CentOS, Gentoo Linux, Oracle Linux, and FreeBSD. We are looking for ways to expand it to other platforms."
Does Amazon EC2 use ECC memory?,"In our experience, ECC memory is necessary for server infrastructure, and all the hardware underlying Amazon EC2 uses ECC memory."
How is this service different than a plain hosting service?,"Traditional hosting services generally provide a pre-configured resource for a fixed amount of time and at a predetermined cost. Amazon EC2 differs fundamentally in the flexibility, control and significant cost savings it offers developers, allowing them to treat Amazon EC2 as their own personal data center with the benefit of Amazon.com’s robust infrastructure.
When computing requirements unexpectedly change (up or down), Amazon EC2 can instantly respond, meaning that developers have the ability to control how many resources are in use at any given point in time. In contrast, traditional hosting services generally provide a fixed number of resources for a fixed amount of time, meaning that users have a limited ability to easily respond when their usage is rapidly changing, unpredictable, or is known to experience large peaks at various intervals.
Secondly, many hosting services don’t provide full control over the compute resources being provided. Using Amazon EC2, developers can choose not only to initiate or shut down instances at any time, they can completely customize the configuration of their instances to suit their needs – and change it at any time. Most hosting services cater more towards groups of users with similar system requirements, and so offer limited ability to change these.
Finally, with Amazon EC2 developers enjoy the benefit of paying only for their actual resource consumption – and at very low rates. Most hosting services require users to pay a fixed, up-front fee irrespective of their actual computing power used, and so users risk overbuying resources to compensate for the inability to quickly scale up resources within a short time frame."
How will I be charged and billed for my use of Amazon EC2?,"You pay only for what you use. Displayed pricing is an hourly rate but depending on which instances you choose, you pay by the hour or second (minimum of 60 seconds) for each instance type. Partial instance-hours consumed are billed based on instance usage. Data transferred between AWS services in different regions will be charged as Internet Data Transfer on both sides of the transfer. Usage for other Amazon Web Services is billed separately from Amazon EC2.
For EC2 pricing information, please visit the 
pricing section on the EC2 detail page
."
When does billing of my Amazon EC2 systems begin and end?,"Billing commences when Amazon EC2 initiates the boot sequence of an AMI instance. Billing ends when the instance terminates, which could occur through a web services command, by running ""shutdown -h"", or through instance failure. When you stop an instance, we shut it down but don't charge hourly usage for a stopped instance, or data transfer fees, but we do charge for the storage for any Amazon EBS volumes. To learn more, visit the 
AWS Documentation
."
What defines billable EC2 instance usage?,"Instance usages are billed for any time your instances are in a ""running"" state. If you no longer wish to be charged for your instance, you must ""stop"" or ""terminate"" the instance to avoid being billed for additional instance usage. Billing starts when an instance transitions into the running state."
"If I have two instances in different availability zones, how will I be charged for regional data transfer?","Each instance is charged for its data in and data out at corresponding Data Transfer rates. Therefore, if data is transferred between these two instances, it is charged at ""Data Transfer Out from EC2 to Another AWS Region"" for the first instance and at ""Data Transfer In from Another AWS Region"" for the second instance. Please refer to 
this page
 for detailed data transfer."
"If I have two instances in different regions, how will I be charged for data transfer?","Each instance is charged for its data in and data out at Internet Data Transfer rates. Therefore, if data is transferred between these two instances, it is charged at Internet Data Transfer Out for the first instance and at Internet Data Transfer In for the second instance."
How will my monthly bill show per-second versus per-hour?,"Although EC2 charges in your monthly bill will now be calculated based on a per second basis, for consistency, the monthly EC2 bill will show cumulative usage for each instance that ran in a given month in decimal hours. An example would be an instance running for 1 hour 10 minutes and 4 seconds would look like 1.1677. Below is an example of a detailed billing report. The two highlighted areas show how the new report will look based on decimal hours."
Do your prices include taxes?,"Except as otherwise noted, our prices are exclusive of applicable taxes and duties, including VAT and applicable sales tax. For customers with a Japanese billing address, use of AWS services is subject to Japanese Consumption Tax. 
Learn more
."
What kind of hardware will my application stack run on?,"Visit 
Amazon EC2 Instance Type
 for a list of EC2 instances available by region."
How do I select the right instance type?,"Amazon EC2 instances are grouped into 5 families: General Purpose, Compute Optimized, Memory Optimized, Storage Optimized and Accelerated Computing instances. General Purpose Instances have memory to CPU ratios suitable for most general purpose applications and come with fixed performance (M5, M4) or burstable performance (T2); Compute Optimized instances (C5, C4) have proportionally more CPU resources than memory (RAM) and are well suited for scale out compute-intensive applications and High Performance Computing (HPC) workloads; Memory Optimized Instances (X1e, X1, R4) offer larger memory sizes for memory-intensive applications, including database and memory caching applications; Accelerating Computing instances (P3, P2, G3, F1) take advantage of the parallel processing capabilities of NVIDIA Tesla GPUs for high performance computing and machine/deep learning; GPU Graphics instances (G3) offer high-performance 3D graphics capabilities for applications using OpenGL and DirectX; F1 instances deliver Xilinx FPGA-based reconfigurable computing; Storage Optimized Instances (H1, I3, D2) that provide very high, low latency, I/O capacity using SSD-based local instance storage for I/O-intensive applications, with D2 or H1, the dense-storage and HDD-storage instances, provide local high storage density and sequential I/O performance for data warehousing, Hadoop and other data-intensive applications. When choosing instance types, you should consider the characteristics of your application with regards to resource utilization (i.e. CPU, Memory, Storage) and select the optimal instance family and instance size."
What is an “EC2 Compute Unit” and why did you introduce it?,"Transitioning to a utility computing model fundamentally changes how developers have been trained to think about CPU resources. Instead of purchasing or leasing a particular processor to use for several months or years, you are renting capacity by the hour. Because Amazon EC2 is built on commodity hardware, over time there may be several different types of physical hardware underlying EC2 instances. Our goal is to provide a consistent amount of CPU capacity no matter what the actual underlying hardware.
Amazon EC2 uses a variety of measures to provide each instance with a consistent and predictable amount of CPU capacity. In order to make it easy for developers to compare CPU capacity between different instance types, we have defined an Amazon EC2 Compute Unit. The amount of CPU that is allocated to a particular instance is expressed in terms of these EC2 Compute Units. We use several benchmarks and tests to manage the consistency and predictability of the performance from an EC2 Compute Unit. The EC2 Compute Unit (ECU) provides the relative measure of the integer processing power of an Amazon EC2 instance. Over time, we may add or substitute measures that go into the definition of an EC2 Compute Unit, if we find metrics that will give you a clearer picture of compute capacity."
What is the regional availability of Amazon EC2 instance types?,"For a list of all instances and regional availability, visit 
Amazon EC2 Pricing."
How do I prevent other people from viewing my systems?,"You have complete control over the visibility of your systems. The Amazon EC2 security systems allow you to place your running instances into arbitrary groups of your choice. Using the web services interface, you can then specify which groups may communicate with which other groups, and also which IP subnets on the Internet may talk to which groups. This allows you to control access to your instances in our highly dynamic environment. Of course, you should also secure your instance as you would any other server."
Can I get a history of all EC2 API calls made on my account for security analysis and operational troubleshooting purposes? ,"Yes. To receive a history of all EC2 API calls (including VPC and EBS) made on your account, you simply turn on CloudTrail in the 
AWS Management Console
.  For more information, visit the 
CloudTrail
 home page."
Where can I find more information about security on AWS?,"For more information on security on AWS please refer to our 
Amazon Web Services: Overview of Security Processes
 white paper and to our 
Amazon EC2 running Windows Security Guide
."
Why am I limited to 5 Elastic IP addresses per region?,"Public (IPV4) internet addresses are a scarce resource. There is only a limited amount of public IP space available, and Amazon EC2 is committed to helping use that space efficiently.
By default, all accounts are limited to 5 Elastic IP addresses per region. If you need more the 5 Elastic IP addresses, we ask that you apply for your limit to be raised. We will ask you to think through your use case and help us understand your need for additional addresses. You can 
apply for more Elastic IP address here
. Any increases will be specific to the region they have been requested for."
Why am I charged when my Elastic IP address is not associated with a running instance?,"In order to help ensure our customers are efficiently using the Elastic IP addresses, we impose a small hourly charge for each address when it is not associated to a running instance."
Do I need one Elastic IP address for every instance that I have running?,"No. You do not need an Elastic IP address for all your instances. By default, every instance comes with a private IP address and an internet routable public IP address. The private address is associated exclusively with the instance and is only returned to Amazon EC2 when the instance is stopped or terminated. The public address is associated exclusively with the instance until it is stopped, terminated or replaced with an Elastic IP address. These IP addresses should be adequate for many applications where you do not need a long lived internet routable end point. Compute clusters, web crawling, and backend services are all examples of applications that typically do not require Elastic IP addresses."
How long does it take to remap an Elastic IP address?,The remap process currently takes several minutes from when you instruct us to remap the Elastic IP until it fully propagates through our system.
Can I configure the reverse DNS record for my Elastic IP address?,"Yes, you can configure the reverse DNS record of your Elastic IP address by 
filling out this form
. Note that a corresponding forward DNS record pointing to that Elastic IP address must exist before we can create the reverse DNS record."
How isolated are Availability Zones from one another?,"Each Availability Zone runs on its own physically distinct, independent infrastructure, and is engineered to be highly reliable. Common points of failures like generators and cooling equipment are not shared across Availability Zones. Additionally, they are physically separate, such that even extremely uncommon disasters such as fires, tornados or flooding would only affect a single Availability Zone."
Is Amazon EC2 running in more than one region?,"Yes. Please refer to 
Regional Products and Services
 for more details of our product and service availability by region."
How can I make sure that I am in the same Availability Zone as another developer?,"We do not currently support the ability to coordinate launches into the same Availability Zone across AWS developer accounts. One Availability Zone name (for example, us-east-1a) in two AWS customer accounts may relate to different physical Availability Zones."
"If I transfer data between Availability Zones using public IP addresses, will I be charged twice for Regional Data Transfer (once because it’s across zones, and a second time because I’m using public IP addresses)?","No. Regional Data Transfer rates apply if at least one of the following is true, but is only charged once for a given instance even if both are true:
The other instance is in a different Availability Zone, regardless of which type of address is used.
Public or Elastic IP addresses are used, regardless of which Availability Zone the other instance is in."
What is the Nitro Hypervisor?,"The launch of C5 instances introduced a new hypervisor for Amazon EC2, the Nitro Hypervisor. As a component of the Nitro system, the Nitro Hypervisor primarily provides CPU and memory isolation for EC2 instances. VPC networking and EBS storage resources are implemented by dedicated hardware components, Nitro Cards that are part of all current generation EC2 instance families. The Nitro Hypervisor is built on core Linux Kernel-based Virtual Machine (KVM) technology, but does not include general-purpose operating system components."
How does the Nitro Hypervisor benefit customers?,"The Nitro Hypervisor provides consistent performance and increased compute and memory resources for EC2 virtualized instances by removing host system software components. It allows AWS to offer larger instance sizes (like c5.18xlarge) that provide practically all of the resources from the server to customers. Previously, C3 and C4 instances each eliminated software components by moving VPC and EBS functionality to hardware designed and built by AWS. This hardware enables the Nitro Hypervisor to be very small and uninvolved in data processing tasks for networking and storage."
Will all EC2 instances use the Nitro Hypervisor?,"Eventually all new instance types will use the Nitro Hypervisor, but in the near term, some new instance types will use Xen depending on the requirements of the platform."
Will AWS continue to invest in its Xen-based hypervisor?,"Yes. As AWS expands its global cloud infrastructure, EC2’s use of its Xen-based hypervisor will also continue to grow. Xen will remain a core component of EC2 instances for the foreseeable future. AWS is a founding member of the Xen Project since its establishment as a Linux Foundation Collaborative Project and remains an active participant on its Advisory Board. As AWS expands its global cloud infrastructure, EC2’s Xen-based hypervisor also continues to grow. Therefore EC2’s investment in Xen continues to grow, not shrink"
How many EBS volumes and Elastic Network Interfaces (ENIs) can be attached to instances running on the Nitro Hypervisor?,"Instances running on the Nitro Hypervisor support a maximum of 27 additional PCI devices for EBS volumes and VPC ENIs. Each EBS volume or VPC ENI uses a PCI device. For example, if you attach 3 additional network interfaces to an instance that uses the Nitro Hypervisor, you can attach up to 24 EBS volumes to that instance."
Will the Nitro Hypervisor change the APIs used to interact with EC2 instances?,"No, all the public facing APIs for interacting with EC2 instances that run using the Nitro Hypervisor will remain the same. For example, the “hypervisor” field of the DescribeInstances response, which will continue to report “xen” for all EC2 instances, even those running under the Nitro Hypervisor. This field may be removed in a future revision of the EC2 API."
Which AMIs are supported on instances that use the Nitro Hypervisor?,"EBS backed HVM AMIs with support for ENA networking and booting from NVMe storage can be used with instances that run under the Nitro Hypervisor. The latest Amazon Linux AMI and Windows AMIs provided by Amazon are supported, as are the latest AMI of Ubuntu, Debian, Red Hat Enterprise Linux, SUSE Enterprise Linux, CentOS, and FreeBSD."
Will I notice any difference between instances using Xen hypervisor and those using the Nitro Hypervisor?,"Yes. For example, instances running under the Nitro Hypervisor boot from EBS volumes using an NVMe interface. Instances running under Xen boot from an emulated IDE hard drive, and switch to the Xen paravirtualized block device drivers.
Operating systems can identify when they are running under a hypervisor. Some software assumes that EC2 instances will run under the Xen hypervisor and rely on this detection. Operating systems will detect they are running under KVM when an instance uses the Nitro Hypervisor, so the process to identify EC2 instances should be used to identify EC2 instances that run under both hypervisors.
All the features of EC2 such as Instance Metadata Service work the same way on instances running under both Xen and the Nitro Hypervisor. The majority of applications will function the same way under both Xen and the Nitro Hypervisor as long as the operating system has the needed support for ENA networking and NVMe storage."
How are instance reboot and termination EC2 API requests implemented by the Nitro Hypervisor?,"The Nitro Hypervisor signals the operating system running in the instance that it should shut down cleanly by industry standard ACPI methods. For Linux instances, this requires that acpid be installed and functioning correctly. If acpid is not functioning in the instance, termination events will be delayed by multiple minutes and will then execute as a hard reset or power off."
How do EBS volumes behave when accessed by NVMe interfaces?,"There are some important differences in how operating system NVMe drivers behave compared to Xen paravirtual (PV) block drivers.
First, the NVMe device names used by Linux based operating systems will be different than the parameters for EBS volume attachment requests and block device mapping entries such as /dev/xvda and /dev/xvdf. NVMe devices are enumerated by the operating system as /dev/nvme0n1, /dev/nvme1n1, and so on. The NVMe device names are not persistent mappings to volumes, therefore other methods like file system UUIDs or labels should be used when configuring the automatic mounting of file systems or other startup activities. When EBS volumes are accessed via the NVMe interface, the EBS volume ID is available via the controller serial number and the device name specified in EC2 API requests is provided by an NVMe vendor extension to the Identify Controller command. This enables backward compatible symbolic links to be created by a utility script. For more information see the EC2 documentation on device naming and NVMe based EBS volumes.
Second, by default the NVMe drivers included in most operating systems implement an I/O timeout. If an I/O does not complete in an implementation specific amount of time, usually tens of seconds, the driver will attempt to cancel the I/O, retry it, or return an error to the component that issued the I/O. The Xen PV block device interface does not time out I/O, which can result in processes that cannot be terminated if it is waiting for I/O. The Linux NVMe driver behavior can be modified by specifying a higher value for the nvme.io timeout kernel module parameter.
Third, the NVMe interface can transfer much larger amounts of data per I/O, and in some cases may be able to support more outstanding I/O requests, compared to the Xen PV block interface. This can cause higher I/O latency if very large I/Os or a large number of I/O requests are issued to volumes designed to support throughput workloads like EBS Throughput Optimized HDD (st1) and Cold HDD (sc1) volumes. This I/O latency is normal for throughput optimized volumes in these scenarios, but may cause I/O timeouts in NVMe drivers. The I/O timeout can be adjusted in the Linux driver by specifying a larger value for the nvme_core.io_timeout kernel module parameter."
What networking capabilities are included in this feature?,"We currently support enhanced networking capabilities using SR-IOV (Single Root I/O Virtualization). SR-IOV is a method of device virtualization that provides higher I/O performance and lower CPU utilization compared to traditional implementations. For supported Amazon EC2 instances, this feature provides higher packet per second (PPS) performance, lower inter-instance latencies, and very low network jitter."
Why should I use Enhanced Networking?,"If your applications benefit from high packet-per-second performance and/or low latency networking, Enhanced Networking will provide significantly improved performance, consistence of performance and scalability."
How can I enable Enhanced Networking on supported instances?,"In order to enable this feature, you must launch an HVM AMI with the appropriate drivers. M5, C5, H1, R4, X1, I3, P3, P2, G3, and m4.16xlarge instances provide the Elastic Network Adapter (ENA) interface (which uses the “ena” Linux driver) for Enhanced Networking. C3, C4, R3, I2, M4 (except m4.16xlarge) and D2 instances use Intel® 82599g Virtual Function Interface (which uses the “ixgbevf” Linux driver). Amazon Linux AMI includes both of these drivers by default. For AMIs that do not contain these drivers, you will need to download and install the appropriate drivers based on the instance types you plan to use. You can use Linux or Windows instructions to enable Enhanced Networking in AMIs that do not include the SR-IOV driver by default. Enhanced Networking is only supported in Amazon VPC."
Do I need to pay an additional fee to use Enhanced Networking?,"No, there is no additional fee for Enhanced Networking. To take advantage of Enhanced Networking you need to launch the appropriate AMI on a supported instance type in a VPC."
Why is Enhanced Networking only supported in Amazon VPC?,Amazon VPC allows us to deliver many advanced networking features to you that are not possible in EC2-Classic. Enhanced Networking is another example of a capability enabled by Amazon VPC.
Which instance types support Enhanced Networking?,"Currently C3, C4, C5, D2, I3, I2, H1, M5, M4, X1 and R3 instances support Enhanced Networking. X1, P2, P3, G3, I3, R4 and m4.16xlarge instances provide the Elastic Network Adapter (ENA) interface for Enhanced Networking. C3, C4, R3, I2, M4 (except m4.16xlarge) and D2 instances, use Intel® 82599 Virtual Function Interface."
Q. Which instance types offer NVMe instance storage?,"High I/O instances use NVMe based local instance storage to deliver very high, low latency, I/O capacity to applications, and are optimized for applications that require millions of IOPS. Like Cluster instances, High I/O instances can be clustered via cluster placement groups for high bandwidth networking."
What happens to my data when a system terminates?,"The data stored on a local instance store will persist only as long as that instance is alive. However, data that is stored on an Amazon EBS volume will persist independently of the life of the instance. Therefore, we recommend that you use the local instance store for temporary data and, for data requiring a higher level of durability, we recommend using Amazon EBS volumes or backing up the data to Amazon S3. If you are using an Amazon EBS volume as a root partition, you will need to set the Delete On Terminate flag to ""N"" if you want your Amazon EBS volume to persist outside the life of the instance."
What kind of performance can I expect from Amazon EBS volumes?,"Amazon EBS provides four current generation volume types and are divided into two major categories: SSD-backed storage for transactional workloads and HDD-backed storage for throughput intensive workloads. These volume types differ in performance characteristics and price, allowing you to tailor your storage performance and cost to the needs of your applications. For more information on see the 
EBS product details page
, and for additional information on performance, see the 
Amazon EC2 User Guide's EBS Performance section
."
What are Throughput Optimized HDD (st1) and Cold HDD (sc1) volume types?,"ST1 volumes are backed by hard disk drives (HDDs) and are ideal for frequently accessed, throughput intensive workloads with large datasets and large I/O sizes, such as MapReduce, Kafka, log processing, data warehouse, and ETL workloads. These volumes deliver performance in terms of throughput, measured in MB/s, and include the ability to burst up to 250 MB/s per TB, with a baseline throughput of 40 MB/s per TB and a maximum throughput of 500 MB/s per volume. ST1 is designed to deliver the expected throughput performance 99% of the time and has enough I/O credits to support a full-volume scan at the burst rate.
SC1 volumes are backed by hard disk drives (HDDs) and provides the lowest cost per GB of all EBS volume types. It is ideal for less frequently accessed workloads with large, cold datasets. Similar to st1, sc1 provides a burst model: these volumes can burst up to 80 MB/s per TB, with a baseline throughput of 12 MB/s per TB and a maximum throughput of 250 MB/s per volume. For infrequently accessed data, sc1 provides extremely inexpensive storage. SC1 is designed to deliver the expected throughput performance 99% of the time and has enough I/O credits to support a full-volume scan at the burst rate.
To maximize the performance of st1 and sc1, we recommend using 
EBS-optimized EC2 instances
."
Which volume type should I choose?,"Amazon EBS includes two major categories of storage: SSD-backed storage for transactional workloads (performance depends primarily on IOPS) and HDD-backed storage for throughput workloads (performance depends primarily on throughput, measured in MB/s). SSD-backed volumes are designed for transactional, IOPS-intensive database workloads, boot volumes, and workloads that require high IOPS. SSD-backed volumes include Provisioned IOPS SSD (io1) and General Purpose SSD (gp2). HDD-backed volumes are designed for throughput-intensive and big-data workloads, large I/O sizes, and sequential I/O patterns. HDD-backed volumes include Throughput Optimized HDD (st1) and Cold HDD (sc1). For more information on Amazon EBS see the 
EBS product details page
."
Do you support multiple instances accessing a single volume?,"While you are able to attach multiple volumes to a single instance, attaching multiple instances to one volume is not supported at this time."
Will I be able to access my EBS snapshots using the regular Amazon S3 APIs?,"No, EBS snapshots are only available through the Amazon EC2 APIs."
Do volumes need to be un-mounted in order to take a snapshot? Does the snapshot need to complete before the volume can be used again? ,"No, snapshots can be done in real time while the volume is attached and in use. However, snapshots only capture data that has been written to your Amazon EBS volume, which might exclude any data that has been locally cached by your application or OS. In order to ensure consistent snapshots on volumes attached to an instance, we recommend cleanly detaching the volume, issuing the snapshot command, and then reattaching the volume. For Amazon EBS volumes that serve as root devices, we recommend shutting down the machine to take a clean snapshot."
Are snapshots versioned? Can I read an older snapshot to do a point-in-time recovery?,"Each snapshot is given a unique identifier, and customers can create volumes based on any of their existing snapshots."
What charges apply when using Amazon EBS shared snapshots?,"If you share a snapshot, you won’t be charged when other users make a copy of your snapshot. If you make a copy of another user’s shared volume, you will be charged normal EBS rates."
Can users of my Amazon EBS shared snapshots change any of my data?,"Users who have permission to create volumes based on your shared snapshots will first make a copy of the snapshot into their account. Users can modify their own copies of the data, but the data on your original snapshot and any other volumes created by other users from your original snapshot will remain unmodified."
How can I discover Amazon EBS snapshots that have been shared with me?,You can find snapshots that have been shared with you by selecting “Private Snapshots” from the viewing dropdown in the Snapshots section of the AWS Management Console. This section will list both snapshots you own and snapshots that have been shared with you.
How can I find what Amazon EBS snapshots are shared globally?,You can find snapshots that have been shared globally by selecting “Public Snapshots” from the viewing dropdown in the Snapshots section of the AWS Management Console.
Do you offer encryption on Amazon EBS volumes and snapshots?,Yes. EBS offers seamless encryption of data volumes and snapshots. EBS encryption better enables you to meet security and encryption compliance requirements.
How can I find a list of Amazon Public Data Sets?,"All information on Public Data Sets is available in our 
Public Data Sets Resource Center
. You can also obtain a listing of Public Data Sets within the AWS Management Console by choosing “Amazon Snapshots” from the viewing dropdown in the Snapshots section."
Where can I learn more about EBS?,You can visit the
Amazon EBS FAQ page,0
How do I access a file system from an Amazon EC2 instance?,"To access your file system, you mount the file system on an Amazon EC2 Linux-based instance using the standard Linux mount command and the file system’s DNS name. Once you’ve mounted, you can work with the files and directories in your file system just like you would with a local file system.
Amazon EFS uses the NFSv4.1 protocol. For a step-by-step example of how to access a file system from an Amazon EC2 instance, please see the 
Amazon EFS Getting Started guide
."
What Amazon EC2 instance types and AMIs work with Amazon EFS?,"Amazon EFS is compatible with all Amazon EC2 instance types and is accessible from Linux-based AMIs. You can mix and match the instance types connected to a single file system. For a step-by-step example of how to access a file system from an Amazon EC2 instance, please see the 
Amazon EFS Getting Started guide
."
How do I load data into a file system?,"You can load data into an Amazon EFS file system from your Amazon EC2 instances or from your on-premises datacenter servers.
Amazon EFS file systems can be mounted on an Amazon EC2 instance, so any data that is accessible to an Amazon EC2 instance can also be read and written to Amazon EFS. To load data that is not currently stored on the Amazon cloud, you can use the same methods you use to transfer files to Amazon EC2 today, such as Secure Copy (SCP).
Amazon EFS file systems can also be mounted on an on-premises server, so any data that is accessible to an on-premises server can be read and written to Amazon EFS using standard Linux tools. For more information about accessing a file system from an on-premises server, please see the 
On-premises Access section"
 of the Amazon EFS FAQ.,"For more information about moving data to the Amazon cloud, please see the 
Cloud Data Migration page
."
How do I access my file system from outside my VPC?,"Amazon EC2 instances within your VPC can access your file system directly, and Amazon EC2 Classic instances outside your VPC can mount a file system via 
ClassicLink
. On-premises servers can mount your file systems via an 
AWS Direct Connect
 connection to your VPC."
How many Amazon EC2 instances can connect to a file system?,Amazon EFS supports one to thousands of Amazon EC2 instances connecting to a file system concurrently.
Where can I learn more about EFS?,You can visit the
Amazon EFS FAQ page,0
What is the minimum time interval granularity for the data that Amazon CloudWatch receives and aggregates?,Metrics are received and aggregated at 1 minute intervals.
Which operating systems does Amazon CloudWatch support?,Amazon CloudWatch receives and provides metrics for all Amazon EC2 instances and should work with any operating system currently supported by the Amazon EC2 service.
Will I lose the metrics data if I disable monitoring for an Amazon EC2 instance?,"You can retrieve metrics data for any Amazon EC2 instance up to 2 weeks from the time you started to monitor it. After 2 weeks, metrics data for an Amazon EC2 instance will not be available if monitoring was disabled for that Amazon EC2 instance. If you want to archive metrics beyond 2 weeks you can do so by calling mon-get-stats command from the command line and storing the results in Amazon S3 or Amazon SimpleDB."
Can I access the metrics data for a terminated Amazon EC2 instance or a deleted Elastic Load Balancer?,Yes. Amazon CloudWatch stores metrics for terminated Amazon EC2 instances or deleted Elastic Load Balancers for 2 weeks.
Does the Amazon CloudWatch monitoring charge change depending on which type of Amazon EC2 instance I monitor?,"No, the Amazon CloudWatch monitoring charge does not vary by Amazon EC2 instance type."
Why does the graphing of the same time window look different when I view in 5 minute and 1 minute periods?,"If you view the same time window in a 5 minute period versus a 1 minute period, you may see that data points are displayed in different places on the graph. For the period you specify in your graph, Amazon CloudWatch will find all the available data points and calculates a single, aggregate point to represent the entire period. In the case of a 5 minute period, the single data point is placed at the beginning of the 5 minute time window. In the case of a 1 minute period, the single data point is placed at the 1 minute mark. We recommend using a 1 minute period for troubleshooting and other activities that require the most precise graphing of time periods."
Can I automatically scale my Amazon EC2 fleets?,"Yes. 
Amazon EC2 Auto Scaling
 is a fully managed service designed to launch or terminate Amazon EC2 instances automatically to help ensure you have the correct number of Amazon EC2 instances available to handle the load for your application. EC2 Auto Scaling helps you maintain application availability through fleet management for EC2 instances, which detects and replaces unhealthy instances, and by scaling your Amazon EC2 capacity up or down automatically according to conditions you define. You can use EC2 Auto Scaling to automatically increase the number of Amazon EC2 instances during demand spikes to maintain performance and decrease capacity during lulls to reduce costs. For more information see the"
Amazon EC2 Auto Scaling FAQ,0
What load balancing options does the Elastic Load Balancing service offer?,"Elastic Load Balancing offers two types of load balancers that both feature high availability, automatic scaling, and robust security. These include the 
Classic Load Balancer
 that routes traffic based on either application or network level information, and the 
Application Load Balancer
 that routes traffic based on advanced application level information that includes the content of the request."
When should I use the Classic Load Balancer and when should I use the Application Load Balancer?,"The Classic Load Balancer is ideal for simple load balancing of traffic across multiple EC2 instances, while the Application Load Balancer is ideal for applications needing advanced routing capabilities, microservices, and container-based architectures. Please visit 
Elastic Load Balancing
 for more information."
What is a Reserved Instance?,A Reserved Instance (RI) is an EC2 offering that provides you with a significant discount on EC2 usage when you commit to a one-year or three-year term.
What are the differences between Standard RIs and Convertible RIs?,"Standard RIs offer a significant discount on EC2 instance usage when you commit to a particular instance family. 
Convertible RIs
 offer you the option to change your instance configuration during the term, and still receive a discount on your EC2 usage. For more information on Convertible RIs, please 
click here
."
Do RIs provide a capacity reservation?,"Yes, when a Standard or Convertible RI is scoped to a specific Availability Zone (AZ), instance capacity matching the exact RI configuration is reserved for your use (these are referred to as “zonal RIs”). Zonal RIs give you additional confidence in your ability to launch instances when you need them.
You can also choose to forego the capacity reservation and purchase Standard or Convertible RIs that are scoped to a region (referred to as “regional RIs”). Regional RIs automatically apply the discount to usage across Availability Zones and instance sizes in a region, making it easier for you to take advantage of the RI’s discounted rate."
When should I purchase a zonal RI?,"If you want to take advantage of the capacity reservation, then you should buy an RI in a specific Availability Zone."
When should I purchase a regional RI?,"If you do not require the capacity reservation, then you should buy a regional RI. Regional RIs provide AZ and instance size flexibility, which offers broader applicability of the RI’s discounted rate."
What are Availability Zone and instance size flexibility?,"Availability Zone and instance size flexibility make it easier for you to take advantage of your regional RI’s discounted rate. Availability Zone flexibility applies your RI’s discounted rate to usage in any Availability Zone in a region, while instance size flexibility applies your RI’s discounted rate to usage of any size within an instance family. Let’s say you own an m5.2xlarge Linux/Unix regional RI with default tenancy in US East (N.Virginia). Then this RI’s discounted rate can automatically apply to two m5.xlarge instances in us-east-1a or four m5.large instances in us-east-1b."
What types of RIs provide instance size flexibility?,
"Linux/Unix regional RIs with the default tenancy provide instance size flexibility. Instance size flexibility is not available on RIs of other platforms such as Windows, Windows with SQL Standard, Windows with SQL Server Enterprise, Windows with SQL Server Web, RHEL, and SLES.",
Q: Do I need to take any action to take advantage of Availability Zone and instance size flexibility?,Regional RIs do not require any action to take advantage of Availability Zone and instance size flexibility.
I own zonal RIs how do I assign them to a region?,You can assign your Standard zonal RIs to a region by modifying the scope of the RI from a specific Availability Zone to a region from the EC2 management console or by using the ModifyReservedInstances API.
How do I purchase an RI?,"To get started, you can purchase an RI from the EC2 Management Console or by using the AWS CLI. Simply specify the instance type, platform, tenancy, term, payment option, and region or Availability Zone."
Can I purchase an RI for a running instance?,"Yes, AWS will automatically apply an RI’s discounted rate to any applicable instance usage from the time of purchase. Visit the 
Getting Started page
 to learn more."
Can I control which instances are billed at the discounted rate?,"No. AWS automatically optimizes which instances are charged at the discounted rate to ensure you always pay the lowest amount. For information about billing, and how it applies to RIs, see 
Billing Benefits and Payment Options
."
How does instance size flexibility work?,"EC2 uses the scale shown below, to compare different sizes within an instance family. In the case of instance size flexibility on RIs, this scale is used to apply the discounted rate of RIs to the normalized usage of the instance family. For example, if you have an m5.2xlarge RI that is scoped to a region, then your discounted rate could apply towards the usage of 1 m5.2xlarge or 2 m5.xlarge instances.
Click here
 to learn more about how instance size flexibility of RIs applies to your EC2 usage. And 
click here
 to learn about how instance size flexibility of RIs is presented in the Cost and Usage Report."
Can I change my RI during its term?,"Yes, you can modify the Availability Zone of the RI, change the scope of the RI from Availability Zone to region (and vice-versa), change the network platform from EC2-VPC to EC2-Classic (and vice versa) or modify instance sizes within the same instance family (on the Linux/Unix platform)."
Can I change the instance type of my RI during its term?,
"Yes, Convertible RIs offer you the option to change the instance type, operating system, tenancy or payment option of your RI during its term. Please refer to the Convertible RI section of the FAQ for additional information.",
What are the different payment options for RIs?,"You can choose from three payment options when you purchase an RI. With the All Upfront option, you pay for the entire RI term with one upfront payment. With the Partial Upfront option, you make a low upfront payment and are then charged a discounted hourly rate for the instance for the duration of the RI term. The No Upfront option does not require any upfront payment and provides a discounted hourly rate for the duration of the term."
When are RIs activated?,"The billing discount and capacity reservation (if applicable) is activated once your payment has successfully been authorized. You can view the status (pending | active | retired) of your RIs on the ""Reserved Instances"" page of the Amazon EC2 Console."
Do RIs apply to Spot instances or instances running on a Dedicated Host?,"No, RIs do not apply to Spot instances or instances running on Dedicated Hosts. To lower the cost of using Dedicated Hosts, purchase Dedicated Host Reservations."
How do RIs work with Consolidated Billing?,"Our system automatically optimizes which instances are charged at the discounted rate to ensure that the consolidated accounts always pay the lowest amount. If you own RIs that apply to an Availability Zone, then only the account which owns the RI will receive the capacity reservation. However, the discount will automatically apply to usage in any account across your consolidated billing family."
Can I get a discount on RI purchases?,"Yes, EC2 provides tiered discounts on RI purchases. These discounts are determined based on the total list value (non-discounted price) for the active RIs you have per region. Your total list value is the sum of all expected payments for an RI within the term, including both the upfront and recurring hourly payments. The tier ranges and corresponding discounts are shown alongside."
Can you help me understand how volume discounts are applied to my RI purchases?,"Sure. Let's assume that you currently have $400,000 worth of active RIs in the US-east-1 region. Now, if you purchase RIs worth $150,000 in the same region, then the first $100,000 of this purchase would not receive a discount. However, the remaining $50,000 of this purchase would be discounted by 5 percent, so you would only be charged $47,500 for this portion of the purchase over the term based on your payment option.
To learn more, please visit the 
Understanding Reserved Instance Discount Pricing Tier
 portion of the 
Amazon EC2 User Guide
."
How do I calculate the list value of an RI?,Here is a sample list value calculation for three-year Partial Upfront Reserved Instances:
How are volume discounts calculated if I use Consolidated Billing?,"If you leverage Consolidated Billing, AWS will use the aggregate total list price of active RIs across all of your consolidated accounts to determine which volume discount tier to apply. Volume discount tiers are determined at the time of purchase, so you should activate Consolidated Billing prior to purchasing RIs to ensure that you benefit from the largest possible volume discount that your consolidated accounts are eligible to receive."
Do Convertible RIs qualify for Volume Discounts?,"No, however the value of each Convertible RI that you purchase contributes to your volume discount tier standing."
How do I determine which volume discount tier applies to me?,"To determine your current volume discount tier, please consult the 
Understanding Reserved Instance Discount Pricing Tiers
 portion of the 
Amazon EC2 User Guide
."
"Will the cost of my RIs change, if my future volume qualifies me for other discount tiers?","No. Volume discounts are determined at the time of purchase, therefore the cost of your RIs will continue to remain the same as you qualify for other discount tiers. Any new purchase will be discounted according to your eligible volume discount tier at the time of purchase."
Do I need to take any action at the time of purchase to receive volume discounts?,"No, you will automatically receive volume discounts when you use the existing PurchaseReservedInstance API or EC2 Management Console interface to purchase RIs. If you purchase more than $10M worth of RIs 
contact us
 about receiving discounts beyond those that are automatically provided."
What is a Convertible RI?,A Convertible RI is a type of Reserved Instance with attributes that can be changed during the term.
When should I purchase a Convertible RI instead of a Standard RI?,"The Convertible RI is useful for customers who can commit to using EC2 instances for a three-year term in exchange for a significant discount on their EC2 usage, are uncertain about their instance needs in the future, or want to benefit from changes in price."
What term length options are available on Convertible RIs?,"Like Standard RIs, Convertible RIs are available for purchase for a one-year or three-year term."
"Can I exchange my Convertible RI to benefit from a Convertible RI matching a different instance type, operating system, tenancy, or payment option? ","Yes, you can select a new instance type, operating system, tenancy, or payment option when you exchange your Convertible RIs. You also have the flexibility to exchange a portion of your Convertible RI or merge the value of multiple Convertible RIs in a single exchange. Click 
here
 to learn more about exchanging Convertible RIs."
Can I transfer a Convertible or Standard RI from one region to another?,"No, a RI is associated with a specific region, which is fixed for the duration of the reservation's term."
How do I change the configuration of a Convertible RI?,You can change the configuration of your Convertible RI using the EC2 Management Console or the
GetReservedInstancesExchangeQuote API,". You also have the flexibility to exchange a portion of your Convertible RI or merge the value of multiple Convertible RIs in a single exchange. Click 
here
 to learn more about exchanging Convertible RIs."
Do I need to pay a fee when I exchange my Convertible RIs?,"No, you do not pay a fee when you exchange your RIs. However may need to pay a one-time true-up charge that accounts for differences in pricing between the Convertible RIs that you have and the Convertible RIs that you want."
How do Convertible RI exchanges work?,"When you exchange one Convertible RI for another, EC2 ensures that the total value of the Convertible RIs is maintained through a conversion. So, if you are converting your RI with a total value of $1000 for another RI, you will receive a quantity of Convertible RIs with a value that’s equal to or greater than $1000. You cannot convert your Convertible RI for Convertible RI(s) of a lesser total value."
Can you define total value? ,The total value is the sum of all expected payments that you’d make during the term for the RI.
Can you walk me through how the true-up cost is calculated for a conversion between two All Upfront Convertible RIs?,"Sure, let’s say you purchased an All Upfront Convertible RI for $1000 upfront, and halfway through the term you decide to change the attributes of the RI. Since you’re halfway through the RI term, you have $500 left of prorated value remaining on the RI. The All Upfront Convertible RI that you want to convert into costs $1,200 upfront today. Since you only have half of the term left on your existing Convertible RI, there is $600 of value remaining on the desired new Convertible RI. The true-up charge that you’ll pay will be the difference in upfront value between original and desired Convertible RIs, or $100 ($600 - $500)."
Can you walk me through a conversion between No Upfront Convertible RIs?,"Unlike conversions between Convertible RIs with an upfront value, since you’re converting between RIs without an upfront cost, there will not be a true-up charge. However, the amount you pay on an hourly basis before the exchange will need to be greater than or equal to the amount you pay on a total hourly basis after the exchange.
For example, let’s say you purchased one No Upfront Convertible RI (A) with a $0.10/hr rate, and you decide to exchange Convertible RI A for another RI (B) that costs $0.06/hr. When you convert, you will receive two RIs of B because the amount that you pay on an hourly basis must be greater than or equal to the amount you’re paying for A on an hourly basis."
Can I customize the number of instances that I receive as a result of a Convertible RI exchange?,"No, EC2 uses the value of the Convertible RIs you’re trading in to calculate the minimal number of Convertible RIs you’ll receive while ensuring the result of the exchange gives you Convertible RIs of equal or greater value."
Are there exchange limits for Convertible RIs?,"No, there are no exchange limits for Convertible RIs."
Do I have the freedom to choose any instance type when I exchange my Convertible RIs?,"No, you can only exchange into Convertible RIs that are currently offered by AWS."
Can I upgrade the payment option associated with my Convertible RI?,"Yes, you can upgrade the payment option associated with your RI. For example, you can exchange your No Upfront RIs for Partial or All Upfront RIs to benefit from better pricing. You cannot change the payment option from All Upfront to No Upfront, and cannot change from Partial Upfront to No Upfront."
Do Convertible RIs allow me to benefit from price reductions when they happen?,"Yes, you can exchange your RIs to benefit from lower pricing. For example, if the price of new Convertible RIs reduces by 10%, you can exchange your Convertible RIs and benefit from the 10% reduction in price."
What is the Reserved Instance Marketplace?,The Reserved Instance Marketplace is an online marketplace that provides AWS customers the flexibility to sell their Amazon Elastic Compute Cloud (Amazon EC2) Reserved Instances to other businesses and organizations. Customers can also browse the Reserved Instance Marketplace to find an even wider selection of Reserved Instance term lengths and pricing options sold by other AWS customers.
When can I list a Reserved Instance on the Reserved Instance Marketplace?,"You can list a Reserved Instance when:
You've registered as a seller in the Reserved Instance Marketplace.
You've paid for your Reserved Instance.
You've owned the Reserved Instance for longer than 30 days."
How will I register as a seller for the Reserved Instance Marketplace?,"To register for the Reserved Instance Marketplace, you can enter the registration workflow by selling a Reserved Instance from the 
EC2 Management Console
 or setting up your profile from the ""Account Settings"" page on the AWS portal. No matter the route, you will need to complete the following steps:
Start by reviewing the overview of the registration process.
Log in to your AWS Account.
Enter in the bank account into which you want us to disburse funds. Once you select ""Continue"", we will set that bank account as the default disbursement option.
In the confirmation screen, choose ""Continue to Console to Start Listing"".
If you exceed $20,000 in sales of Reserved Instances, or plan to sell 50 or more Reserved Instances, you will need to provide tax information before you can list your Reserved Instances. Choose ""Continue with Tax Interview"". During the tax interview pipeline, you will be prompted to enter your company name, contact name, address, and Tax Identification Number using the TIMS workflow. 
Additionally, if you plan to sell Reserved Instances worth more than $50,000 per year you will also need to file a limit increase."
How will I know when I can start selling on the Reserved Instance Marketplace?,"You can start selling on the Reserved Instance Marketplace after you have added a bank account through the registration pipeline. Once activation is complete, you will receive a confirmation email. However, it is important to note that you will not be able to receive disbursements until we are able to receive verification from your bank, which may take up to two weeks, depending on the bank you use."
How do I list a Reserved Instance for sale?,"To list a Reserved Instance, simply complete these steps in the Amazon EC2 Console:
Select the Reserved Instances you wish to sell, and choose ""Sell Reserved Instances"". If you have not completed the registration process, you will be prompted to register using the registration pipeline.
For each Reserved Instance type, set the number of instances you’d like to sell, and the price for the one-time fee you would like to set. Note that you can set the one-time price to different amounts depending on the amount of time remaining so that you don’t have to keep adjusting your one-time price if your Reserved Instance doesn’t sell quickly. By default you just need to set the current price and we will automatically decrease the one-time price by the same increment each month.
Once you have configured your listing, a final confirmation screen will appear. Choose ""Sell Reserved Instance""."
Which Reserved Instances can I list for sale?,"You can list any Reserved Instances that have been active for at least 30 days, and for which we have received payment. Typically, this means that you can list your reservations once they are in the 
active
 state. It is important to note that if you are an invoice customer, your Reserved Instance can be in the 
active
 state prior to AWS receiving payment. In this case, your Reserved Instance will not be listed until we have received your payment."
How are listed Reserved Instances displayed to buyers?,"Reserved Instances (both third-party and those offered by AWS) that have been listed on the Reserved Instance Marketplace can be viewed in the ""Reserved Instances"" section of the Amazon EC2 Console. You can also use the DescribeReservedInstancesListings API call.
The listed Reserved Instances are grouped based on the type, term remaining, upfront price, and hourly price. This makes it easier for buyers to find the right Reserved Instances to purchase."
How much of my Reserved Instance term can I list?,"You can sell a Reserved Instance for the term remaining, rounded down to the nearest month. For example, if you had 9 months and 13 days remaining, you will list it for sale as a 9-month-term Reserved Instance."
Can I remove my Reserved Instance after I’ve listed it for sale?,"Yes, you can remove your Reserved Instance listings at any point until a sale is 
pending
 (meaning a buyer has bought your Reserved Instance and confirmation of payment is pending)."
Which pricing dimensions can I set for the Reserved Instances I want to list?,"Using the Reserved Instance Marketplace, you can set an upfront price you’d be willing to accept. You cannot set the hourly price (which will remain the same as was set on the original Reserved Instance), and you will not receive any funds collected from payments associated with the hourly prices."
Can I still use my reservation while it is listed on the Reserved Instance Marketplace?,"Yes, you will continue to receive the capacity and billing benefit of your reservation until it is sold. Once sold, any running instance that was being charged at the discounted rate will be charged at the On-Demand rate until and unless you purchase a new reservation, or terminate the instance."
Can I resell a Reserved Instance that I purchased from the Reserved Instance Marketplace?,"Yes, you can resell Reserved Instances purchased from the Reserved Instance Marketplace just like any other Reserved Instance."
Are there any restrictions when selling Reserved Instances?,"Yes, you must have a US bank account to sell Reserved Instances in the Reserved Instance Marketplace. Support for non-US bank accounts will be coming soon. Also, you may not sell Reserved Instances in the US GovCloud region."
Can I sell Reserved Instances purchased from the public volume pricing tiers?,"No, this capability is not yet available."
Is there a charge for selling Reserved Instances on the Reserved Instance Marketplace?,"Yes, AWS charges a service fee of 12% of the total upfront price of each Reserved Instance you sell in the Reserved Instance Marketplace."
Can AWS sell subsets of my listed Reserved Instances?,"Yes, AWS may potentially sell a subset of the quantity of Reserved Instances that you have listed. For example, if you list 100 Reserved instances, we may only have a buyer interested in purchasing 50 of them. We will sell those 50 instances and continue to list your remaining 50 Reserved Instances until and unless you decide not to list them any longer."
How do buyers pay for Reserved Instances that they've purchased?,Payment for completed Reserved Instance sales are done via ACH wire transfers to a US bank account.
When will I receive my money?,"Once AWS has received funds from the customer that has bought your reservation, we will disburse funds via wire transfer to the bank account you specified when you registered for the Reserved Instance Marketplace.
Then, we will send you an email notification letting you know that we’ve wired you the funds. Typically, funds will appear in your account within 3-5 days of when your Reserved Instance was been sold."
"If I sell my Reserved Instance in the Reserved Instance Marketplace, will I get refunded for the Premium Support I was charged too?","No, you will not receive a pro-rated refund for the upfront portion of the AWS Premium Support Fee."
Will I be notified about Reserved Instance Marketplace activities?,"Yes, you will receive a single email once a day that details your Reserved Instance Marketplace activity whenever you create or cancel Reserved Instance listings, buyers purchase your listings, or AWS disburses funds to your bank account."
What information is exchanged between the buyer and seller to help with the transaction tax calculation?,"The buyer’s city, state, zip+4, and country information will be provided to the seller via a disbursement report. This information will enable sellers to calculate any necessary transaction taxes they need to remit to the government (e.g., sales tax, value-added tax, etc.). The legal entity name of the seller will also be provided on the purchase invoice."
Are there any restrictions on the customers when purchasing third-party Reserved Instances?,"Yes, you cannot purchase your own listed Reserved Instances, including those in any of your linked accounts (via Consolidated Billing)."
Do I have to pay for Premium Support when purchasing Reserved Instances from the Reserved Instance Marketplace?,"Yes, if you are a Premium Support customer, you will be charged for Premium Support when you purchase a Reserved Instance through the Reserved Instance Marketplace."
What is Amazon EC2 Fleet?,"With a single API call, EC2 Fleet lets you provision compute capacity across different instance types, Availability Zones and across On-Demand, Reserved Instances (RI) and Spot Instances purchase models to help optimize scale, performance and cost."
If I currently use Amazon EC2 Spot Fleet should I migrate to Amazon EC2 Fleet?,"If you are leveraging Amazon EC2 Spot Instances with Spot Fleet, you can continue to use that. Spot Fleet and EC2 Fleet offer the same functionality. There is no requirement to migrate."
Can I use Reserved Instance (RI) discounts with Amazon EC2 Fleet?,"Yes, Similar to other EC2 APIs or other AWS services that launches EC2 instances, if the On-Demand instance launched by EC2 Fleet matches an existing RI, that instance will receive the RI discount. For example, if you own Regional RIs for M4 instances and you have specified only M4 instances in your EC2 Fleet, RI discounts will be automatically applied to this usage of M4."
Will Amazon EC2 Fleet failover to On-Demand if EC2 Spot capacity is not fully fulfilled?,"No, EC2 Fleet will continue to attempt to meet your desired Spot capacity based on the number of Spot instances you requested in your Fleet launch specification."
What is the pricing for Amazon EC2 Fleet?,"EC2 Fleet comes at no additional charge, you only pay for the underlying resources that EC2 Fleet launches."
Can you provide a real world example of how I can use Amazon EC2 Fleet?,"There are a number of ways to take advantage of Amazon EC2 Fleet, such as in big data workloads, containerized application, grid processing workloads etc. In 
this
 example of a genomic sequencing workload, you can launch a grid of worker nodes with a single API call: select your favorite instances, assign weights for these instances, specify target capacity for On-Demand and Spot Instances, and build a fleet within seconds to crunch through genomic data quickly."
How can I allocate resources in an Amazon EC2 Fleet?,"By default, EC2 Fleet will launch the On-Demand option that is lowest price. For Spot Instances, EC2 Fleet provides two allocation strategies: lowest price and diversified. The lowest price strategy allows you to provision Spot Instances in pools that provide the lowest price per unit of capacity at the time of the request. The diversified strategy allows you to provision Spot Instances across multiple Spot pools and you can maintain your fleet’s target capacity to increase application."
Can I submit a multi-region Amazon EC2 Fleet request?,"No, we do not support multi-region EC2 Fleet requests."
Can I tag an Amazon EC2 Fleet?,"Yes. You can tag a EC2 Fleet request to create business-relevant tag groupings to organize resources along technical, business, and security dimensions."
Can I modify my Amazon EC2 Fleet?,"Yes, you can modify the total target capacity of your EC2 Fleet when in maintain mode. You may need to cancel the request and submit a new one to change other request configuration parameters."
Can I specify a different AMI for each instance type that I want to use?,"Yes, simply specify the AMI you’d like to use in each launch specification you provide in your EC2 Fleet."
What is a Spot Instance?,"Spot instances are spare EC2 capacity that can save you up 90% off of On-Demand prices that AWS can interrupt with a 2-minute notification. Spot uses the same underlying EC2 instances as On-Demand and Reserved Instances, and is best suited for fault-tolerant, flexible workloads. Spot instances provides an additional option for obtaining compute capacity and can be used along with On-Demand and Reserved Instances."
How is a Spot instance different than an On-Demand instance or Reserved Instance?,"While running, Spot instances are exactly the same as On-Demand or Reserved instances. The main differences are that Spot instances typically offer a significant discount off the On-Demand prices, your instances can be interrupted by Amazon EC2 for capacity requirements with a 2-minute notification, and Spot prices adjust gradually based on long term supply and demand for spare EC2 capacity.
 See 
here
 for more details on Spot instances."
How do I purchase and start up a Spot instance?,"Spot instances can be launched using the same tools you use launch instances today, including AWS Management Console, Auto-Scaling Groups, Run Instances and Spot Fleet. In addition many AWS services support launching Spot instances such as EMR, ECS, Datapipeline, Cloudformation and Batch.
 To start up a Spot instance, you simply need to choose a Launch Template and the number of instances you would like to request.
 See 
here
 for more details on how to request Spot instances."
How many Spot instances can I request?,"You can request Spot instances up to your Spot limit for each region. Note that customers new to AWS might start with a lower limit. To learn more about Spot instance limits, please refer to the 
Amazon EC2 User Guide
.
If you would like a higher limit, complete the 
Amazon EC2 instance request form
 with your use case and your instance increase will be considered. Limit increases are tied to the region they were requested for."
What price will I pay for a Spot instance?,"You pay the Spot price that’s in effect at the beginning of each instance-hour for your running instance. If Spot price changes after you launch the instance, the new price is charged against the instance usage for the subsequent hour."
What is a Spot capacity pool?,"A Spot capacity pool is a set of unused EC2 instances with the same instance type, operating system, Availability Zone, and network platform (EC2-Classic or EC2-VPC). Each spot capacity pool can have a different price based on supply and demand."
What are the best practices to use Spot instances?,"We highly recommend using multiple Spot capacity pools to maximize the amount of Spot capacity available to you. EC2 provides built-in automation to find the most cost-effective capacity across multiple Spot capacity pools using Spot Fleet. For more information, please see 
Spot Best Practices
."
How can I determine the status of my Spot request?,"You can determine the status of your Spot request via Spot Request Status code and message. You can access Spot Request Status information on the Spot Instance page of the EC2 console of the AWS Management Console, API and CLI. For more information, please visit the 
Amazon EC2 Developer guide
."
Are Spot instances available for all instance families and sizes and in all regions?,"Spot instances are available in all public AWS regions. Spot is available for nearly all EC2 instance families and sizes, including the newest compute-optimized instances, accelerated graphics, and FPGA instance types. A full list of instance types supported in each region are listed 
here
."
Which operating systems are available as Spot instances?,
Linux/UNIX and Windows Server are available. Windows Server with SQL Server is not currently available.,
Can I use a Spot instance with a paid AMI for third-party software (such as IBM’s software packages)?,Not at this time.
When would my Spot instance get interrupted?,"Over the last 3 months, 92% of Spot instance interruptions were from a customer manually terminating the instance because the application had completed its work.
In the circumstance EC2 needs to reclaim your Spot instance it can be for two possible reasons, with the primary one being Amazon EC2 capacity requirements (e.g. On Demand or Reserved Instance usage). Secondarily, if you have chosen to set a “maximum Spot price” and the Spot price rises above this, your instance will be reclaimed with a two-minute notification. This parameter determines the maximum price you would be willing to pay for a Spot instance hour, and by default, is set at the On-Demand price. As before, you continue to pay the Spot market price, not your maximum price, at the time your instance was running, charged in per-second increments."
What happens to my Spot instance when it gets interrupted?,"You can choose to have your Spot instances terminated, stopped or hibernated upon interruption. Stop and hibernate options are available for persistent Spot requests and Spot Fleets with the “maintain” option enabled. By default, your instances are terminated.
Refer to 
Spot Hibernation
 to learn more about handling interruptions."
What is the difference between Stop and Hibernate interruption behaviors?,"In the case of Hibernate, your instance gets hibernated and the RAM data persisted. In the case of Stop, your instance gets shutdown and RAM is cleared.
 In both the cases, data from your EBS root volume and any attached EBS data volumes is persisted. Your private IP address remains the same, as does your elastic IP address (if applicable). The network layer behavior will be similar to that of 
EC2 Stop-Start workflow
. Stop and Hibernate are available for Amazon EBS backed instances only. Local instance storage is not persisted."
What if my EBS root volume is not large enough to store memory state (RAM) for Hibernate?,"You should have sufficient space available on your EBS root volume to write data from memory. If the EBS root volume does not enough space, hibernation will fail and the instance will get shutdown instead. Ensure that your EBS volume is large enough to persist memory data before choosing the hibernate option."
What is the benefit if Spot hibernates my instance on interruption?,"With hibernate, Spot instances will pause and resume around any interruptions so your workloads can pick up from exactly where they left off. You can use hibernation when your instance(s) need to retain instance state across shutdown-startup cycles, i.e. when your applications running on Spot depend on contextual, business, or session data stored in RAM."
What do I need to do to enable hibernation for my Spot instances?,"Refer to 
Spot Hibernation
 to learn about enabling hibernation for your Spot instances."
Do I have to pay for hibernating my Spot instance?,There is no additional charge for hibernating your instance beyond the EBS storage costs and any other EC2 resources you may be using. You are not charged instance usage fees once your instance is hibernated.
Can I restart a stopped instance or resume a hibernated instance?,"No, you will not be able to re-start a stopped instance or resume a hibernated instance directly. Stop-start and hibernate-resume cycles are controlled by Amazon EC2. If an instance is stopped or hibernated by Spot, it will be restarted or resumed by Amazon EC2 when the capacity becomes available."
Which instances and operating systems support hibernation?,"Spot Hibernation is currently supported for Amazon Linux AMIs, Ubuntu and Microsoft Windows operating systems running on any instance type across C3, C4, C5, M4, M5, R3, R4 instances with memory (RAM) size less than 100 GiB.
To review the list of supported OS versions, refer to 
Spot Hibernation
."
How will I be charged if my Spot instance is interrupted?,"If your Spot instance is terminated or stopped by Amazon EC2 in the first instance hour, you will not be charged for that usage. However, if you terminate the instance yourself, you will be charged to the nearest second. If the Spot instance is terminated or stopped by Amazon EC2 in any subsequent hour, you will be charged for your usage to the nearest second. If you are running on Windows and you terminate the instance yourself, you will be charged for an entire hour."
How am I charged if Spot price changes while my instance is running? ,"You will pay the price per instance-hour set at the beginning of each instance-hour for the entire hour, billed to the nearest second."
Where can I see my usage history for Spot instances and see how much I was billed?,The AWS Management Console makes a detailed billing report available which shows Spot instance start and termination/stop times for all instances. Customers can check the billing report against historical Spot prices via the API to verify that the Spot price they were billed is correct.
 Are Spot blocks (Fixed Duration Spot instances) ever interrupted?,"Spot blocks are designed not to be interrupted and will run continuously for the duration you select, independent of Spot market price. In rare situations, Spot blocks may be interrupted due to AWS capacity needs. In these cases, we will provide a two-minute warning before we terminate your instance (
termination notice
), and you will not be charged for the affected instance(s)."
What is a Spot fleet?,"A Spot Fleet allows you to automatically request and manage multiple Spot instances that provide the lowest price per unit of capacity for your cluster or application, like a batch processing job, a Hadoop workflow, or an HPC grid computing job. You can include the instance types that your application can use. You define a target capacity based on your application needs (in units including instances, vCPUs, memory, storage, or network throughput) and update the target capacity after the fleet is launched. Spot fleets enable you to launch and maintain the target capacity, and to automatically request resources to replace any that are disrupted or manually terminated. 
Learn more about Spot fleets
."
Is there any additional charge for making Spot Fleet requests,"No, there is no additional charge for Spot Fleet requests."
 What limits apply to a Spot Fleet request?,"Visit the 
Spot Fleet Limits
 section of the Amazon EC2 User Guide to learn about the limits that apply to your Spot Fleet request."
 What happens if my Spot Fleet request tries to launch Spot instances but exceeds my regional Spot request limit?,"If your Spot Fleet request exceeds your regional Spot instance request limit, individual Spot instance requests will fail with a Spot request limit exceeded request status. Your Spot Fleet request’s history will show any Spot request limit errors that the Fleet request received. Visit the 
Monitoring Your Spot Fleet
 section of the Amazon EC2 User Guide to learn how to describe your Spot Fleet request's history."
 Are Spot fleet requests guaranteed to be fulfilled?,"No. Spot fleet requests allow you to place multiple Spot instance requests simultaneously, and are subject to the same availability and prices as a single Spot instance request. For example, if no resources are available for the instance types listed in your Spot Fleet request, we may be unable to fulfill your request partially or in full. We recommend you to include all the possible instance types and availability zones that are suitable for your workloads in the Spot Fleet."
 Can I submit a multi-Availability Zone Spot Fleet request?,"Yes, visit the 
Spot Fleet Examples
 section of the Amazon EC2 User Guide to learn how to submit a multi-Availability Zone Spot Fleet request."
 Can I submit a multi-region Spot Fleet request?,"No, we do not support multi-region Fleet requests."
How does Spot Fleet allocate resources across the various Spot instance pools specified in the launch specifications?,"The RequestSpotFleet API provides two allocation strategies: lowestPrice and diversified. The lowestPrice strategy allows you to provision your Spot Fleet resources in instance pools that provide the lowest price per unit of capacity at the time of the request. The diversified strategy allows you to provision your Spot Fleet resources across multiple Spot instance pools. This enables you to maintain your fleet’s target capacity and increase your application’s availability as Spot capacity fluctuates.
Running your application’s resources across diverse Spot instance pools also allows you to further reduce your fleet’s operating costs over time. Visit the 
Amazon EC2 User Guide
 to learn more."
Can I tag a Spot Fleet request?,You can request to launch Spot instances with tags via Spot Fleet. The Fleet by itself cannot be tagged.
How can I see which Spot fleet owns my Spot instances?,"You can identify the Spot instances associated with your Spot Fleet by describing your fleet request. Fleet requests are available for 48 hours after all its Spot instances have been terminated. See the 
Amazon EC2 User Guide
 to learn how to describe your Spot Fleet request."
Can I modify my Spot Fleet request?,"Yes, you can modify the target capacity of your Spot Fleet request. You may need to cancel the request and submit a new one to change other request configuration parameters."
Can I specify a different AMI for each instance type that I want to use?,"Yes, simply specify the AMI you’d like to use in each launch specification you provide in your Spot Fleet request."
"Can I use Spot Fleet with Elastic Load Balancing, Auto Scaling, or Elastic MapReduce?","You can use Auto Scaling features with Spot Fleet such as target tracking, health checks, cloudwatch metrics etc and can attach instances to your Elastic load balancers (both classic and application load balancers). Elastic MapReduce has a feature named “Instance fleets” that provides capabilities similar to Spot Fleet."
Does a Spot Fleet request terminate Spot instances when they are no longer running in the lowest priced Spot pools and relaunch them in the lowest priced pools?,"No, Spot Fleet requests do not automatically terminate and re-launch instances while they are running. However, if you terminate a Spot instance, Spot Fleet will replenish it with a new Spot instance in the new lowest priced pool."
Can I use stop or Hibernation interruption behaviors with Spot Fleet?,"Yes, stop-start and hibernate-resume are supported with Spot Fleet with “maintain” fleet option enabled."
How much compute power do Micro instances provide?,"Micro instances provide a small amount of consistent CPU resources and allow you to burst CPU capacity up to 2 ECUs when additional cycles are available. They are well suited for lower throughput applications and web sites that consume significant compute cycles periodically but very little CPU at other times for background processes, daemons, etc. 
Learn more
 about use of this instance type."
How does a Micro instance compare in compute power to a Standard Small instance?,"At steady state, Micro instances receive a fraction of the compute resources that Small instances do. Therefore, if your application has compute-intensive or steady state needs we recommend using a Small instance (or larger, depending on your needs). However, Micro instances can periodically burst up to 2 ECUs (for short periods of time). This is double the number of ECUs available from a Standard Small instance. Therefore, if you have a relatively low throughput application or web site with an occasional need to consume significant compute cycles, we recommend using Micro instances."
How can I tell if an application needs more CPU resources than a Micro instance is providing?,The CloudWatch metric for CPU utilization will report 100% utilization if the instance bursts so much that it exceeds its available CPU resources during that CloudWatch monitored minute. CloudWatch reporting 100% CPU utilization is your signal that you should consider scaling – manually or via Auto Scaling – up to a larger instance type or scale out to multiple Micro instances.
Are all features of Amazon EC2 available for Micro instances?,Currently Amazon DevPay is not available for Micro instances.
When should I use Compute Optimized instances?,"Compute Optimized instances are designed for applications that benefit from high compute power. These applications include compute-intensive applications like high-performance web servers, high-performance computing (HPC), scientific modelling, distributed analytics and machine learning inference."
Can I launch C4 instances as Amazon EBS-optimized instances?,"Each C4 instance type is EBS-optimized by default. C4 instances 500 Mbps to 4,000 Mbps to EBS above and beyond the general-purpose network throughput provided to the instance. Since this feature is always enabled on C4 instances, launching a C4 instance explicitly as EBS-optimized will not affect the instance's behavior."
How can I use the processor state control feature available on the c4.8xlarge instance?,"The c4.8xlarge instance type provides the ability for an operating system to control processor C-states and P-states. This feature is currently available only on Linux instances. You may want to change C-state or P-state settings to increase processor performance consistency, reduce latency, or tune your instance for a specific workload. By default, Amazon Linux provides the highest-performance configuration that is optimal for most customer workloads; however, if your application would benefit from lower latency at the cost of higher single- or dual-core frequencies, or from lower-frequency sustained performance as opposed to bursty Turbo Boost frequencies, then you should consider experimenting with the C-state or P-state configuration options that are available to these instances. For additional information on this feature, see the Amazon EC2 User Guide section on 
Processor State Control
."
Which instances are available within Compute Optimized instances category?,"C5 instances
: C5 instances are the latest generation of EC2 Compute Optimized instances. C5 instances are based on Intel Xeon Platinum processors, part of the Intel Xeon Scalable (codenamed Skylake-SP) processor family, and are available in 6 sizes and offer up to 72 vCPUs and 144 GiB memory. C5 instances deliver 25% improvement in price/performance compared to C4 instances.
C4 instances
: C4 instances are based on Intel Xeon E5-2666 v3 (codenamed Haswell) processors. C4 instances are available in 5 sizes and offer up to 36 vCPUs and 60 GiB memory."
Should I move my workloads from C3 or C4 instances to C5 instances?,"The generational improvement in CPU performance and lower price of C5 instances, which combined result in a 25% price/performance improvement relative to C4 instances, benefit a broad spectrum of workloads that currently run on C3 or C4 instances. For floating point intensive applications, Intel AVX-512 enables significant improvements in delivered TFLOPS by effectively extracting data level parallelism. Customers looking for absolute performance for graphics rendering and HPC workloads that can be accelerated with GPUs or FPGAs should also evaluate other instance families in the Amazon EC2 portfolio that include those resources to find the ideal instance for their workload."
Which operating systems/AMIs are supported on C5 Instances?,"EBS backed HVM AMIs with support for ENA networking and booting from NVMe-based storage can be used with C5 instances. The following AMIs are supported on C5:
Amazon Linux 2014.03 or newer
Ubuntu 14.04 or newer
SUSE Linux Enterprise Server 12 or newer
Red Hat Enterprise Linux 7.4 or newer
CentOS 7 or newer
Windows Server 2008 R2
Windows Server 2012
Windows Server 2012 R2
Windows Server 2016
FreeBSD 11.1-RELEASE
For optimal local NVMe-based SSD storage performance on C5d, Linux kernel version 4.9+ is recommended."
What are the storage options available to C5 customers?,"C5 instances use EBS volumes for storage, are EBS-optimized by default, and offer up to 9 Gbps throughput to both encrypted and unencrypted EBS volumes. C5 instances access EBS volumes via PCI attached NVM Express (NVMe) interfaces. NVMe is an efficient and scalable storage interface commonly used for flash based SSDs such as local NVMe storage provided with I3 instances. Though the NVMe interface may provide lower latency compared to Xen paravirtualized block devices, when used to access EBS volumes the volume type, size, and provisioned IOPS (if applicable) will determine the overall latency and throughput characteristics of the volume. When NVMe is used to provide EBS volumes, they are attached and detached by PCI hotplug."
What network interface is supported on C5 instances?,"C5 instances use the Elastic Network Adapter (ENA) for networking and enable Enhanced Networking by default. With ENA, C5 instances can utilize up to 25 Gbps of network bandwidth."
Which storage interface is supported on C5 instances?,C5 instances will support only NVMe EBS device model. EBS volumes attached to C5 instances will appear as NVMe devices. NVMe is a modern storage interface that provides latency reduction and results in increased disk I/O and throughput.
How many EBS volumes can be attached to C5 instances?,"C5 instances support a maximum for 27 EBS volumes for all Operating systems. The limit is shared with ENI attachments which can be found here http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/using-eni.html. For example: since every instance has at least 1 ENI, if you have 3 additional ENI attachments on the c4.2xlarge, you can attach 24 EBS volumes to that instance."
What is the underlying hypervisor on C5 instances?,C5 instances use a new EC2 hypervisor that is based on core KVM technology.
Why does the total memory reported by Linux not match the advertised memory of the C5 instance type?,"In C5, portions of the total memory for an instance are reserved from use by the Operating System including areas used by the virtual BIOS for things like ACPI tables and for devices like the virtual video RAM."
What are Accelerated Computing instances?,"Accelerated Computing instance family is a family of instances which use hardware accelerators, or co-processors, to perform some functions, such as floating-point number calculation and graphics processing, more efficiently than is possible in software running on CPUs. Amazon EC2 provides three types of Accelerated Computing instances – GPU compute instances for general-purpose computing, GPU graphics instances for graphics intensive applications, and FPGA programmable hardware compute instances for advanced scientific workloads."
When should I use GPU Graphics and Compute instances?,"GPU instances work best for applications with massive parallelism such as workloads using thousands of threads. Graphics processing is an example with huge computational requirements, where each of the tasks is relatively small, the set of operations performed form a pipeline, and the throughput of this pipeline is more important than the latency of the individual operations. To be able build applications that exploit this level of parallelism, one needs GPU device specific knowledge by understanding how to program against various graphics APIs (DirectX, OpenGL) or GPU compute programming models (CUDA, OpenCL)."
How are P3 instances different from G3 instances?,"P3 instances are the next-generation of EC2 general-purpose GPU computing instances, powered by up to 8 of the latest-generation NVIDIA Tesla V100 GPUs. These new instances significantly improve performance and scalability, and add many new features, including new Streaming Multiprocessor (SM) architecture for machine learning (ML)/deep learning (DL) performance optimization, second-generation NVIDIA NVLink high-speed GPU interconnect, and highly tuned HBM2 memory for higher-efficiency.
G3 instances use NVIDIA Tesla M60 GPUs and provide a high-performance platform for graphics applications using DirectX or OpenGL. NVIDIA Tesla M60 GPUs support NVIDIA GRID Virtual Workstation features, and H.265 (HEVC) hardware encoding. Each M60 GPU in G3 instances supports 4 monitors with resolutions up to 4096x2160, and is licensed to use NVIDIA GRID Virtual Workstation for one Concurrent Connected User. Example applications of G3 instances include 3D visualizations, graphics-intensive remote workstation, 3D rendering, application streaming, video encoding, and other server-side graphics workloads."
What are the benefits of NVIDIA Volta GV100 GPUs?,"The new NVIDIA Tesla V100 accelerator incorporates the powerful new Volta GV100 GPU. GV100 not only builds upon the advances of its predecessor, the Pascal GP100 GPU, it significantly improves performance and scalability, and adds many new features that improve programmability. These advances will supercharge HPC, data center, supercomputer, and deep learning systems and applications."
Who will benefit from P3 instances?,"P3 instances with their high computational performance will benefit users in artificial intelligence (AI), machine learning (ML), deep learning (DL) and high performance computing (HPC) applications. Users includes data scientists, data architects, data analysts, scientific researchers, ML engineers, IT managers and software developers. Key industries include transportation, energy/oil & gas, financial services (banking, insurance), healthcare, pharmaceutical, sciences, IT, retail, manufacturing, high-tech, transportation, government, academia, among many others."
What are some key use cases of P3 instances?,"P3 instance use GPUs to accelerate numerous deep learning systems and applications including autonomous vehicle platforms, speech, image, and text recognition systems, intelligent video analytics, molecular simulations, drug discovery, disease diagnosis, weather forecasting, big data analytics, financial modeling, robotics, factory automation, real-time language translation, online search optimizations, and personalized user recommendations, to name just a few."
Why should customers use GPU-powered Amazon P3 instances for AI/ML and HPC?,"GPU-based compute instances provide greater throughput and performance because they are designed for massively parallel processing using thousands of specialized cores per GPU, versus CPUs offering sequential processing with a few cores. In addition, developers have built hundreds of GPU-optimized scientific HPC applications such as quantum chemistry, molecular dynamics, meteorology, among many others. Research indicates that over 70% of the most popular HPC applications provide built-in support for GPUs."
Will P3 instances support EC2 Classic networking and Amazon VPC?,P3 instances will support VPC only.
How are G3 instances different from P2 instances?,"G3 instances use NVIDIA Tesla M60 GPUs and provide a high-performance platform for graphics applications using DirectX or OpenGL. NVIDIA Tesla M60 GPUs support NVIDIA GRID Virtual Workstation features, and H.265 (HEVC) hardware encoding. Each M60 GPU in G3 instances supports 4 monitors with resolutions up to 4096x2160, and is licensed to use NVIDIA GRID Virtual Workstation for one Concurrent Connected User. Example applications of G3 instances include 3D visualizations, graphics-intensive remote workstation, 3D rendering, application streaming, video encoding, and other server-side graphics workloads.
P2 instances use NVIDIA Tesla K80 GPUs and are designed for general purpose GPU computing using the CUDA or OpenCL programming models. P2 instances provide customers with high bandwidth 25 Gbps networking, powerful single and double precision floating-point capabilities, and error-correcting code (ECC) memory, making them ideal for deep learning, high performance databases, computational fluid dynamics, computational finance, seismic analysis, molecular modeling, genomics, rendering, and other server-side GPU compute workloads."
How are P3 instances different from G2 instances?,"P3 Instances are the next-generation of EC2 general-purpose GPU computing instances, powered by up to 8 of the latest-generation NVIDIA Volta GV100 GPUs. These new instances significantly improve performance and scalability and add many new features, including new Streaming Multiprocessor (SM) architecture, optimized for machine learning (ML)/deep learning (DL) performance, second-generation NVIDIA NVLink high-speed GPU interconnect, and highly tuned HBM2 memory for higher-efficiency.
P2 instances use NVIDIA Tesla K80 GPUs and are designed for general purpose GPU computing using the CUDA or OpenCL programming models. P2 instances provide customers with high bandwidth 25 Gbps networking, powerful single and double precision floating-point capabilities, and error-correcting code (ECC) memory."
What APIs and programming models are supported by GPU Graphics and Compute instances?,"P3 instances support CUDA 9 and OpenCL, P2 instances support CUDA 8 and OpenCL 1.2 and G3 instances support DirectX 12, OpenGL 4.5, CUDA 8, and OpenCL 1.2."
Where do I get NVIDIA drivers for P3 and G3 instances?,"There are two methods by which NVIDIA drivers may be obtained. There are listings on the 
AWS Marketplace
 which offer Amazon Linux AMIs and Windows Server AMIs with the NVIDIA drivers pre-installed. You may also launch 64-bit, HVM AMIs and install the drivers yourself. You must visit the NVIDIA driver website and search for the NVIDIA Tesla V100 for P3, NVIDIA Tesla K80 for P2, and NVIDIA Tesla M60 for G3 instances."
"Which AMIs can I use with P3, P2 and G3 instances?","You can currently use Windows Server, SUSE Enterprise Linux, Ubuntu, and Amazon Linux AMIs on P2 and G3 instances. P3 instances only support HVM AMIs. If you want to launch AMIs with operating systems not listed here, contact AWS 
Customer Support
 with your request or reach out through 
EC2 Forums
."
Does the use of G2 and G3 instances require third-party licenses?,"Aside from the NVIDIA drivers and GRID SDK, the use of G2 and G3 instances does not necessarily require any third-party licenses. However, you are responsible for determining whether your content or technology used on G2 and G3 instances requires any additional licensing. For example, if you are streaming content you may need licenses for some or all of that content. If you are using third-party technology such as operating systems, audio and/or video encoders, and decoders from Microsoft, Thomson, Fraunhofer IIS, Sisvel S.p.A., MPEG-LA, and Coding Technologies, please consult these providers to determine if a license is required. For example, if you leverage the on-board h.264 video encoder on the NVIDIA GRID GPU you should reach out to MPEG-LA for guidance, and if you use mp3 technology you should contact Thomson for guidance."
Why am I not getting NVIDIA GRID features on G3 instances using the driver downloaded from NVIDIA website?,"The NVIDIA Tesla M60 GPU used in G3 instances requires a special NVIDIA GRID driver to enable all advanced graphics features, and 4 monitors support with resolution up to 4096x2160. You need to use an AMI with NVIDIA GRID driver pre-installed, or download and install the NVIDIA GRID driver following the AWS documentation."
Why am I unable to see the GPU when using Microsoft Remote Desktop?,"When using Remote Desktop, GPUs using the WDDM driver model are replaced with a non-accelerated Remote Desktop display driver. In order to access your GPU hardware, you need to utilize a different remote access tool, such as VNC."
What is Amazon EC2 F1?,"Amazon EC2 F1 is a compute instance with programmable hardware you can use for application acceleration. The new F1 instance type provides a high performance, easy to access FPGA for developing and deploying custom hardware accelerations."
What are FPGAs and why do I need them?,"FPGAs are programmable integrated circuits that you can configure using software. By using FPGAs you can accelerate your applications up to 30x when compared with servers that use CPUs alone. And, FPGAs are reprogrammable, so you get the flexibility to update and optimize your hardware acceleration without having to redesign the hardware."
How does F1 compare with traditional FPGA solutions?,"F1 is an AWS instance with programmable hardware for application acceleration. With F1, you have access to FPGA hardware in a few simple clicks, reducing the time and cost of full-cycle FPGA development and scale deployment from months or years to days. While FPGA technology has been available for decades, adoption of application acceleration has struggled to be successful in both the development of accelerators and the business model of selling custom hardware for traditional enterprises, due to time and cost in development infrastructure, hardware design, and at-scale deployment. With this offering, customers avoid the undifferentiated heavy lifting associated with developing FPGAs in on-premises data centers."
What is an Amazon FPGA Image (AFI)?,"The design that you create to program your FPGA is called an Amazon FPGA Image (AFI). AWS provides a service to register, manage, copy, query, and delete AFIs. After an AFI is created, it can be loaded on a running F1 instance. You can load multiple AFIs to the same F1 instance, and can switch between AFIs in runtime without reboot. This lets you quickly test and run multiple hardware accelerations in rapid sequence. You can also offer to other customers on the AWS Marketplace a combination of your FPGA acceleration and an AMI with custom software or AFI drivers."
How do I list my hardware acceleration on the AWS Marketplace?,"You would develop your AFI and the software drivers/tools to use this AFI. You would then package these software tools/drivers into an Amazon Machine Image (AMI) in an encrypted format. AWS manages all AFIs in the encrypted format you provide to maintain the security of your code. To sell a product in the AWS Marketplace, you or your company must sign up to be an AWS Marketplace reseller, you would then submit your AMI ID and the AFI ID(s) intended to be packaged in a single product. AWS Marketplace will take care of cloning the AMI and AFI(s) to create a product, and associate a product code to these artifacts, such that any end-user subscribing to this product code would have access to this AMI and the AFI(s)."
What is available with F1 instances?,"For developers, AWS is providing a Hardware Development Kit (HDK) to help accelerate development cycles, a FPGA Developer AMI for development in the cloud, an SDK for AMIs running the F1 instance, and a set of APIs to register, manage, copy, query, and delete AFIs. Both developers and customers have access to the AWS Marketplace where AFIs can be listed and purchased for use in application accelerations."
Do I need to be a FPGA expert to use an F1 instance?,AWS customers subscribing to a F1-optimized AMI from AWS Marketplace do not need to know anything about FPGAs to take advantage of the accelerations provided by the F1 instance and the AWS Marketplace. Simply subscribe to an F1-optimized AMI from the AWS Marketplace with an acceleration that matches the workload. The AMI contains all the software necessary for using the FPGA acceleration. Customers need only write software to the specific API for that accelerator and start using the accelerator.
"I’m a FPGA developer, how do I get started with F1 instances?","Developers can get started on the F1 instance by creating an AWS account and downloading the AWS Hardware Development Kit (HDK). The HDK includes documentation on F1, internal FPGA interfaces, and compiler scripts for generating AFI. Developers can start writing their FPGA code to the documented interfaces included in the HDK to create their acceleration function. Developers can launch AWS instances with the FPGA Developer AMI. This AMI includes the development tools needed to compile and simulate the FPGA code. The Developer AMI is best run on the latest C5, M5, or R4 instances. Developers should have experience in the programming languages used for creating FPGA code (i.e. Verilog or VHDL) and an understanding of the operation they wish to accelerate."
"I’m not an FPGA developer, how do I get started with F1 instances?","Customers can get started with F1 instances by selecting an accelerator from the AWS Marketplace, provided by AWS Marketplace sellers, and launching an F1 instance with that AMI. The AMI includes all of the software and APIs for that accelerator. AWS manages programming the FPGA with the AFI for that accelerator. Customers do not need any FPGA experience or knowledge to use these accelerators. They can work completely at the software API level for that accelerator."
Does AWS provide a developer kit?,"Yes. The Hardware Development Kit (HDK) includes simulation tools and simulation models for developers to simulate, debug, build, and register their acceleration code. The HDK includes code samples, compile scripts, debug interfaces, and many other tools you will need to develop the FPGA code for your F1 instances. You can use the HDK either in an AWS provided AMI, or in your on-premises development environment. These models and scripts are available publically with an AWS account."
Can I use the HDK in my on-premises development environment?,"Yes. You can use the Hardware Development Kit HDK either in an AWS-provided AMI, or in your on-premises development environment."
Can I add an FPGA to any EC2 instance type?,No. F1 instances comes in two instance sizes f1.2xlarge and f1.16 xlarge.
What is a Cluster Compute Instance?,"Cluster Compute Instances combine high compute resources with a high performance networking for High Performance Compute (HPC) applications and other demanding network-bound applications. Cluster Compute Instances provide similar functionality to other Amazon EC2 instances but have been specifically engineered to provide high performance networking.
Amazon EC2 cluster placement group functionality allows users to group Cluster Compute Instances in clusters – allowing applications to get the low-latency network performance necessary for tightly-coupled node-to-node communication typical of many HPC applications. Cluster Compute Instances also provide significantly increased network throughput both within the Amazon EC2 environment and to the Internet. As a result, these instances are also well suited for customer applications that need to perform network-intensive operations.
Learn more
 about use of this instance type for HPC applications."
What kind of network performance can I expect when I launch instances in cluster placement group?,"The bandwidth an EC2 instance can utilize in a cluster placement group depends on the instance type and its networking performance specification. Inter-instance traffic within the same region can utilize 5 Gbps for single-flow and up to 25 Gbps for multi-flow traffic. When launched in a placement group, select EC2 instances can utilize up to 10 Gbps for single-flow traffic."
What is a Cluster GPU Instance?,"Cluster GPU Instances provide general-purpose graphics processing units (GPUs) with proportionally high CPU and increased network performance for applications benefiting from highly parallelized processing that can be accelerated by GPUs using the CUDA and OpenCL programming models. Common applications include modeling and simulation, rendering and media processing.
Cluster GPU Instances give customers with HPC workloads an option beyond Cluster Compute Instances to further customize their high performance clusters in the cloud for applications that can benefit from the parallel computing power of GPUs.
Cluster GPU Instances use the same cluster placement group functionality as Cluster Compute Instances for grouping instances into clusters – allowing applications to get the low-latency, high bandwidth network performance required for tightly-coupled node-to-node communication typical of many HPC applications.
Learn more
 about HPC on AWS."
What is a High Memory Cluster Instance?,"High Memory Cluster Instances provide customers with large amounts of memory and CPU capabilities per instance in addition to high network capabilities. These instance types are ideal for memory intensive workloads including in-memory analytics systems, graph analysis and many science and engineering applications
High Memory Cluster Instances use the same cluster placement group functionality as Cluster Compute Instances for grouping instances into clusters – allowing applications to get the low-latency, high bandwidth network performance required for tightly-coupled node-to-node communication typical of many HPC and other network intensive applications."
Does use of Cluster Compute and Cluster GPU Instances differ from other Amazon EC2 instance types?,"Cluster Compute and Cluster GPU Instances use differs from other Amazon EC2 instance types in two ways.
First, Cluster Compute and Cluster GPU Instances use Hardware Virtual Machine (HVM) based virtualization and run only Amazon Machine Images (AMIs) based on HVM virtualization. Paravirtual Machine (PVM) based AMIs used with other Amazon EC2 instance types cannot be used with Cluster Compute or Cluster GPU Instances.
Second, in order to fully benefit from the available low latency, full bisection bandwidth between instances, Cluster Compute and Cluster GPU Instances must be launched into a cluster placement group through the Amazon EC2 API or AWS Management Console."
What is a cluster placement group?,A cluster placement group is a logical entity that enables creating a cluster of instances by launching instances as part of a group. The cluster of instances then provides low latency connectivity between instances in the group. Cluster placement groups are created through the Amazon EC2 API or AWS Management Console.
Are all features of Amazon EC2 available for Cluster Compute and Cluster GPU Instances?,"Currently, Amazon DevPay is not available for Cluster Compute or Cluster GPU Instances."
Is there a limit on the number of Cluster Compute or Cluster GPU Instances I can use and/or the size of cluster I can create by launching Cluster Compute Instances or Cluster GPU into a cluster placement group?,"There is no limit specific for Cluster Compute Instances. For Cluster GPU Instances, you can launch 2 Instances on your own. If you need more capacity, please complete the 
Amazon EC2 instance request form
 (selecting the appropriate primary instance type)."
Are there any ways to optimize the likelihood that I receive the full number of instances I request for my cluster via a cluster placement group?,"We recommend that you launch the minimum number of instances required to participate in a cluster in a single launch. For very large clusters, you should launch multiple placement groups, e.g. two placement groups of 128 instances, and combine them to create a larger, 256 instance cluster."
Can Cluster GPU and Cluster Compute Instances be launched into a single cluster placement group?,"While it may be possible to launch different cluster instance types into a single placement group, at this time we only support homogenous placement groups."
"If an instance in a cluster placement group is stopped then started again, will it maintain its presence in the cluster placement group?","Yes. A stopped instance will be started as part of the cluster placement group it was in when it stopped. If capacity is not available for it to start within its cluster placement group, the start will fail."
What are the key use cases for Amazon EC2 M5 Instances?,"M5 instances offer a good choice for running development and test environments, web, mobile and gaming applications, analytics applications, and business critical applications including ERP, HR, CRM, and collaboration apps. Customers who are interested in running their data intensive workloads (e.g. HPC, or SOLR clusters) on instances with a higher memory footprint will also find M5 to be a good fit. Workloads that heavily use single and double precision floating point operations and vector processing such as video processing workloads and need higher memory can benefit substantially from the AVX-512 instructions that M5 supports."
Why should customers choose EC2 M5 Instances over EC2 M4 Instances?,"Compared with EC2 M4 Instances, the new EC2 M5 Instances deliver customers greater compute and storage performance, larger instance sizes for less cost, consistency and security. The biggest benefit of EC2 M5 Instances is based on its usage of the latest generation of Intel Xeon Scalable processors (aka Skylake), which deliver up to 14% improvement in price/performance compared to M4. With AVX-512 support in M5 vs. the older AVX2 in M4, customers will gain 2x higher performance in workloads requiring floating point operations. M5 instances offer up to 25 Gbps of network bandwidth and up to 10 Gbps of dedicated bandwidth to Amazon EBS. M5 instances also feature significantly higher networking and Amazon EBS performance on smaller instance sizes with EBS burst capability."
How does support for Intel AVX-512 benefit EC2 M5 Instance customers?,"Intel Advanced Vector Extension 512 (AVX-512) is a set of new CPU instructions available on the latest Intel Xeon Scalable processor family, that can accelerate performance for workloads and usages such as scientific simulations, financial analytics, artificial intelligence, machine learning/deep learning, 3D modeling and analysis, image and video processing, cryptography and data compression, among others. Intel AVX-512 offers exceptional processing of encryption algorithms, helping to reduce the performance overhead for cryptography, which means EC2 M5 customers can deploy more secure data and services into distributed environments without compromising performance"
What are the various storage options available to M5 customers?,M5 instances leverage EBS volumes for storage. There is currently no local storage option for M5 instances.
Which network interface is supported on M5 instances?,"M5 instances support only ENA based Enhanced Networking. M5 instances will not support netback. With ENA, M5 instances can deliver up to 25 Gbps of network bandwidth between instances when launched within a Placement Group."
Which operating systems/AMIs are supported on M5 Instances?,"EBS backed HVM AMIs with support for ENA networking and booting from NVMe-based storage can be used with M5 instances. The following AMIs are supported on M5:
Amazon Linux 2014.03 or newer
Ubuntu 14.04 or newer
SUSE Linux Enterprise Server 12 or newer
Red Hat Enterprise Linux 7.4 or newer
CentOS 7 or newer
Windows Server 2008 R2
Windows Server 2012
Windows Server 2012 R2
Windows Server 2016
FreeBSD 11.1-RELEASE
For optimal local NVMe-based SSD storage performance on M5d, Linux kernel version 4.9+ is recommended."
What are the storage options available to M5 customers?,"M5 instances use EBS volumes for storage, are EBS-optimized by default, and offer up to 10 Gbps throughput to both encrypted and unencrypted EBS volumes. M5 instances access EBS volumes via PCI attached NVM Express (NVMe) interfaces. NVMe is an efficient and scalable storage interface commonly used for flash based SSDs such as local NVMe storage provided with I3 instances. Though the NVMe interface may provide lower latency compared to Xen paravirtualized block devices, when used to access EBS volumes the volume type, size, and provisioned IOPS (if applicable) will determine the overall latency and throughput characteristics of the volume. When NVMe is used to provide EBS volumes, they are attached and detached by PCI hotplug."
How many EBS volumes can be attached to M5 instances?,"M5 instances support a maximum for 27 EBS volumes for all Operating systems. The limit is shared with ENI attachments which can be found here http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/using-eni.html. For example: since every instance has at least 1 ENI, if you have 3 additional ENI attachments on the m4.2xlarge, you can attach 24 EBS volumes to that instance."
What is the underlying hypervisor on M5 instances?,M5 instances use a new lightweight Nitro Hypervisor that is based on core KVM technology.
Why does the total memory reported by Linux not match the advertised memory of the M5 instance type?,"In M5, portions of the total memory for an instance are reserved from use by the operating system including areas used by the virtual BIOS for things like ACPI tables and for devices like the virtual video RAM."
How are Burstable Performance Instances different?,"Amazon EC2 allows you to choose between Fixed Performance Instances (e.g. C, M and R instance families) and 
Burstable Performance Instances
 (e.g. T2). Burstable Performance Instances provide a baseline level of CPU performance with the ability to burst above the baseline.
T2 instances’ baseline performance and ability to burst are governed by CPU Credits. Each T2 instance receives CPU Credits continuously, the rate of which depends on the instance size. T2 instances accrue CPU Credits when they are idle, and consume CPU credits when they are active. A CPU Credit provides the performance of a full CPU core for one minute.
* For the t2.medium, single threaded applications can use 40% of 1 core, or if needed, multithreaded applications can use 20% each of 2 cores.
**For the t2.large, single threaded applications can use 60% of 1 core, or if needed, multithreaded applications can use 30% each of 2 cores.
*** For the t2.xlarge, single threaded applications can use 90% of 1 core, or if needed, multithreaded applications can use 45% each of 2 cores or 22.5% of all 4 cores.
**** For the t2.large, single threaded applications can use all of 1 core, or if needed, multithreaded applications can use 67.5% each of 2 cores or 16.875% of all 8 cores."
How do I choose the right Amazon Machine Image (AMI) for my T2 instances?,"You will want to verify that the minimum memory requirements of your operating system and applications are within the memory allocated for each T2 instance size (e.g. 512 MiB for t2.nano). Operating systems with Graphical User Interfaces (GUI) that consume significant memory and CPU, for example Microsoft Windows, might need a t2.micro or larger instance size for many use cases. You can find AMIs suitable for the t2.nano instance types on 
AWS Marketplace
. Windows customers who do not need the GUI can use the 
Microsoft Windows Server 2012 R2 Core AMI."
"When should I choose a Burstable Performance Instance, such as T2?","T2 instances provide a cost-effective platform for a broad range of general purpose production workloads. T2 Unlimited instances can sustain high CPU performance for as long as required. If your workloads consistently require CPU usage much higher than the baseline, consider a dedicated CPU instance family such as the M or C."
How can I see the CPU Credit balance for each T2 instance?,"You can see the CPU Credit balance for each T2 instance in EC2 per-Instance metrics in Amazon CloudWatch. T2 instances have four metrics, CPUCreditUsage, CPUCreditBalance, CPUSurplusCreditBalance and CPUSurplusCreditsCharged. CPUCreditUsage indicates the amount of CPU Credits used. CPUCreditBalance indicates the balance of CPU Credits. CPUSurplusCredit Balance indicates credits used for bursting in the absence of earned credits. CPUSurplusCreditsCharged indicates credits that are charged when average usage exceeds the baseline."
What happens to CPU performance if my T2 instance is running low on credits (CPU Credit balance is near zero)?,"If your T2 instance has a zero CPU Credit balance, performance will remain at baseline CPU performance. For example, the t2.micro provides baseline CPU performance of 10% of a physical CPU core. If your instance’s CPU Credit balance is approaching zero, CPU performance will be lowered to baseline performance over a 15-minute interval."
Does my T2 instance credit balance persist at stop / start?,"No, a stopped instance does not retain its previously earned credit balance."
Can T2 instances be purchased as Reserved Instances or Spot Instances?,"T2 instances can be purchased as On-Demand Instances, Reserved Instances or Spot Instances."
What is a Dense-storage Instance?,"Dense-storage instances are designed for workloads that require high sequential read and write access to very large data sets, such as Hadoop distributed computing, massively parallel processing data warehousing, and log processing applications. The Dense-storage instances offer the best price/GB-storage and price/disk-throughput across other EC2 instances."
Q. How do Dense-storage and HDD-storage instances compare to High I/O instances? ,High I/O instances (I2) are targeted at workloads that demand low latency and high random I/O in addition to moderate storage density and provide the best price/IOPS across other EC2 instance types. Dense-storage instances (D2) and HDD-storage instances (H1) are optimized for applications that require high sequential read/write access and low cost storage for very large data sets and provide the best price/GB-storage and price/disk-throughput across other EC2 instances.
How much disk throughput can Dense-storage and HDD-storage instances deliver?,"The largest current generation of Dense-storage instances, d2.8xlarge, can deliver up to 3.5 GBps read and 3.1 GBps write disk throughput with a 2 MiB block size. The largest H1 instances size, h1.16xlarge, can deliver up to 1.15 GBps read and write. To ensure the best disk throughput performance from your D2 instances on Linux, we recommend that you use the most recent version of the 
Amazon Linux AMI
, or another Linux AMI with a kernel version of 3.8 or later that supports persistent grants - an extension to the Xen block ring protocol that significantly improves disk throughput and scalability."
Do Dense-storage and HDD-storage instances provide any failover mechanisms or redundancy?,"The primary data storage for Dense-storage instances is HDD-based instance storage. Like all instance storage, these storage volumes persist only for the life of the instance. Hence, we recommend that you build a degree of redundancy (e.g. RAID 1/5/6) or use file systems (e.g. HDFS and MapR-FS) that support redundancy and fault tolerance. You can also back up data periodically to more durable data storage solutions such as Amazon Simple Storage Service (S3) for additional data durability. Please refer to 
Amazon S3
 for reference."
How do Dense-storage and HDD-storage instances differ from Amazon EBS?,"Amazon EBS offers simple, elastic, reliable (replicated), and persistent block level storage for Amazon EC2 while abstracting the details of the underlying storage media in use. Amazon EC2 instance storage provides directly attached non-persistent, high performance storage building blocks that can be used for a variety of storage applications. Dense-storage instances are specifically targeted at customers who want high sequential read/write access to large data sets on local storage, e.g. for Hadoop distributed computing and massively parallel processing data warehousing."
Can I launch H1 instances as Amazon EBS-optimized instances?,"Each H1 instance type is EBS-optimized by default. H1 instances offer 1,750 Mbps to 14,000 Mbps to EBS above and beyond the general-purpose network throughput provided to the instance. Since this feature is always enabled on H1 instances, launching a H1 instance explicitly as EBS-optimized will not affect the instance's behavior."
Can I launch D2 instances as Amazon EBS-optimized instances?,"Each D2 instance type is EBS-optimized by default. D2 instances 500 Mbps to 4,000 Mbps to EBS above and beyond the general-purpose network throughput provided to the instance. Since this feature is always enabled on D2 instances, launching a D2 instance explicitly as EBS-optimized will not affect the instance's behavior."
Are HDD-storage instances offered in EC2 Classic?,"The current generation of HDD-storage instances (H1 instances) can only be launched in Amazon VPC. With Amazon VPC, you can leverage a number of features that are available only on the Amazon VPC platform – such as enabling enhanced networking, assigning multiple private IP addresses to your instances, or changing your instances' security groups. For more information about the benefits of using a VPC, see Amazon EC2 and 
Amazon Virtual Private Cloud
 (Amazon VPC)."
Are Dense-storage instances offered in EC2 Classic?,"The current generation of Dense-storage instances (D2 instances) can be launched in both EC2-Classic and Amazon VPC. However, by launching a Dense-storage instance into a VPC, you can leverage a number of features that are available only on the Amazon VPC platform – such as enabling enhanced networking, assigning multiple private IP addresses to your instances, or changing your instances' security groups. For more information about the benefits of using a VPC, see 
Amazon EC2 and Amazon Virtual Private Cloud
 (Amazon VPC). You can take steps to migrate your resources from EC2-Classic to Amazon VPC. For more information, see 
Migrating a Linux Instance from EC2-Classic to a VPC
."
What is a High I/O instance?,"High I/O instances use NVMe based local instance storage to deliver very high, low latency, I/O capacity to applications, and are optimized for applications that require millions of IOPS. Like Cluster instances, High I/O instances can be clustered via cluster placement groups for low latency networking."
Are all features of Amazon EC2 available for High I/O instances?,"High I/O instance support all Amazon EC2 features. I3 instances offer NVMe only storage, while previous generation I2 instances allow legacy blkfront storage access. Currently you can only purchase High I/O instances as On-Demand, Reserved Instances or as Spot instances."
Is there a limit on the number of High I/O instances I can use?,"Currently, you can launch 2 i3.16xlarge instances by default. If you wish to run more than 2 On-Demand instances, please complete the 
Amazon EC2 instance request form
."
How many IOPS can i3.16.xlarge instances deliver?,"Using HVM AMIs, High I/O I3 instances can deliver up to 3.3 million IOPS measured at 100% random reads using 4KB block size, and up to 300,000 100% random write IOPs, measured at 4KB block sizes to applications across 8 x 1.9 TB NVMe devices."
What is the sequential throughput of i3 instances?,"The maximum sequential throughput, measured at 128K block sizes is 16 GB/s read throughput and 6.4 GB/s write throughput."
AWS has other database and Big Data offerings. When or why should I use High I/O instances?,"High I/O instances are ideal for applications that require access to millions of low latency IOPS, and can leverage data stores and architectures that manage data redundancy and availability. Example applications are:"
NoSQL databases like Cassandra and MongoDB,"In-memory databases like Aerospike
Elasticsearch and analytics workloads
OLTP systems"
Do High I/O instances provide any failover mechanisms or redundancy?,"Like other Amazon EC2 instance types, instance storage on i3.16xlarge instances persists during the life of the instance. Customers are expected to build resilience into their applications. We recommend using databases and file systems that support redundancy and fault tolerance. Customers should back up data periodically to Amazon S3 for improved data durability."
Do High I/O instances support TRIM?,"The TRIM command allows the operating system to inform SSDs which blocks of data are no longer considered in use and can be wiped internally. In the absence of TRIM, future write operations to the involved blocks can slow down significantly. I3 instances support TRIM."
When should I use Memory-optimized instances?,"Memory-optimized instances offer large memory size for memory intensive applications including in-memory applications, in-memory databases, in-memory analytics solutions, High Performance Computing (HPC), scientific computing, and other memory-intensive applications."
When should I use X1 instances?,"X1 instances are ideal for running in-memory databases like SAP HANA, big data processing engines like Apache Spark or Presto, and high performance computing (HPC) applications. X1 instances are certified by SAP to run production environments of the next-generation Business Suite S/4HANA, Business Suite on HANA (SoH), Business Warehouse on HANA (BW), and Data Mart Solutions on HANA on the AWS cloud."
When should I use X1e instances?,"X1e instances are ideal for running in-memory databases like SAP HANA, high-performance databases and other memory optimized enterprise applications. X1e instances offer twice the memory per vCPU compared to the X1 instances. The x1e.32xlarge instance is certified by SAP to run production environments of the next-generation Business Suite S/4HANA, Business Suite on HANA (SoH), Business Warehouse on HANA (BW), and Data Mart Solutions on HANA on the AWS Cloud."
How do X1 and X1e instances differ?,"X1e instances offer 32GB of memory per vCPU whereas X1 instances offer 16GB of memory per vCPU. X1e instance sizes enable six instance configurations starting from 4 vCPUs and 122 GiB memory up to 128 vCPUs and 3,904 GiB of memory. X1 instances enable two instance configurations, 64 vCPUs with 976 GiB memory and 128 vCPUs with 1,952 GiB memory."
What are the key specifications of Intel E7 (codenamed Haswell) processors that power X1 and X1e instances?,"The E7 processors have a high core count to support workloads that scale efficiently on large number of cores. The Intel E7 processors also feature high memory bandwidth and larger L3 caches to boost the performance of in-memory applications. In addition, the Intel E7 processor:
Enables increased cryptographic performance via the latest Intel AES-NI feature.
Supports Transactional Synchronization Extensions (TSX) to boost the performance of in-memory transactional data processing.
Supports Advanced Vector Extensions 2 (Intel AVX2) processor instructions to expand most integer commands to 256 bits."
Do X1 and X1e instances enable CPU power management state control,"Yes. You can configure C-states and P-states on x1e.32xlarge, x1e.16xlarge, x1e.8xlarge, x1.32xlarge and x1.16xlarge instances. You can use C-states to enable higher turbo frequencies (as much as 3.1 GHz with one or two core turbo). You can also use P-states to lower performance variability by pinning all cores at P1 or higher P states, which is similar to disabling Turbo, and running consistently at the base CPU clock speed."
What operating systems are supported on X1 and X1e instances?,"X1 and X1e instances provide high number of vCPUs, which might cause launch issues in some Linux operating systems that have a lower vCPU limit. We strongly recommend that you use the latest AMIs when you launch these instances. 
AMI support for SAP HANA workloads include: SUSE Linux 12, SUSE Linux 12 SP1, SLES for SAP 12 SP1, SLES for SAP 12 SP2, and RHEL 7.2 for SAP HANA. 
x1e.32xlarge will also support Windows Server 2012 R2 and 2012 RTM.  x1e.xlarge, x1e.2xlarge, x1e.4xlarge, x1e.8xlarge, x1e.16xlarge and x1.32xlarge will also support Windows Server 2012 R2, 2012 RTM and 2008 R2 64bit (Windows Server 2008 SP2 and older versions will not be supported) and x1.16xlarge will support Windows Server 2012 R2, 2012 RTM, 2008 R2 64bit, 2008 SP2 64bit, and 2003 R2 64bit (Windows Server 32bit versions will not be supported)."
What storage options are available for X1 customers?,"X1 instances offer SSD based instance store, which is ideal for temporary storage of information such as logs, buffers, caches, temporary tables, temporary computational data, and other temporary content. X1 instance store provides the best I/O performance when you use a Linux kernel that supports 
persistent grants
, an extension to the Xen block ring protocol.
X1 instances are EBS-optimized by default and offer up to 14 Gbps of dedicated bandwidth to EBS volumes. EBS offers multiple volume types to support a wide variety of workloads. For more information see the 
EC2 User Guide
."
What storage options are available for X1e customers?,"X1e instances offer SSD based instance store, which is ideal for temporary storage of information such as logs, buffers, caches, temporary tables, temporary computational data, and other temporary content. X1e instance store provides the best I/O performance when you use a Linux kernel that supports 
persistent grants
, an extension to the Xen block ring protocol.
X1e instances enable dedicated throughput to Amazon Elastic Block Storage (EBS) starting from 500 Mbps (x1e.xlarge) up to 14 Gbps (x1e.32xlarge) and are EBS-optimized by default at no additional cost. For more information see the 
EC2 User Guide
."
How do I build cost-effective failover solution on X1 and X1e instances?,"You can design simple and cost-effective failover solutions on X1 instances using Amazon EC2 
Auto Recovery
, an Amazon EC2 feature that is designed to better manage failover upon instance impairment. You can enable Auto Recovery for X1 instances by creating an AWS CloudWatch alarm. Choose the “EC2 Status Check Failed (System)” metric and select the “Recover this instance” action. Instance recovery is subject to underlying limitations, including those reflected in the 
Instance Recovery Troubleshooting documentation
. For more information visit 
Auto Recovery documentation
 and 
Creating Amazon CloudWatch Alarms
 respectively."
Are there standard SAP HANA reference deployment frameworks available for the X1 instance and the AWS Cloud?,
"You can use the AWS Quick Start reference HANA deployments to rapidly deploy all the necessary HANA building blocks on X1 instances following SAP’s recommendations for high performance and reliability. AWS Quick Starts are modular and customizable, so you can layer additional functionality on top or modify them for your own implementations. For additional information on deploying HANA on AWS, please refer to ",
SAP HANA on AWS Cloud: Quick Start Reference Deployment Guide.,
Are there standard SAP HANA reference deployment frameworks available for the X1e instance and the AWS Cloud?,
"You can use the AWS Quick Start reference HANA deployments to rapidly deploy all the necessary HANA building blocks on x1e.32xlarge instance following SAP’s recommendations for high performance and reliability. AWS Quick Starts are modular and customizable, so you can layer additional functionality on top or modify them for your own implementations. For additional information on deploying HANA on AWS, please refer to ",
SAP HANA on AWS Cloud: Quick Start Reference Deployment Guide,0
"Why don’t I see M1, C1, CC2 and HS1 instances on the pricing pages any more?","These have been moved to the 
Previous Generation Instance
 page."
Are these Previous Generation instances still being supported?,Yes. Previous Generation instances are still fully supported.
Can I still use/add more Previous Generation instances?,"Yes. Previous Generation instances are still available as On-Demand, Reserved Instances, and Spot Instance, from our APIs, CLI and EC2 Management Console interface."
Are my Previous Generation instances going to be deleted?,"No. Your C1, C3, CC2, CR1, G2, HS1, M1, M2, M3, R3 and T1 instances are still fully functional and will not be deleted because of this change."
Are Previous Generation instances being discontinued soon?,"Currently, there are no plans to end of life Previous Generation instances. However, with any rapidly evolving technology the latest generation will typically provide the best performance for the price and we encourage our customers to take advantage of technological advancements."
Will my Previous Generation instances I purchased as a Reserved Instance be affected or changed?,"No. Your Reserved Instances will not change, and the Previous Generation instances are not going away."
Which instance types offer NVMe instance storage?,"Today, I3, C5d, M5d and F1 instances offer NVMe instance storage."
Is data stored on Amazon EC2 NVMe instance storage encrypted?,"Yes, all data is encrypted in an AWS Nitro hardware module prior to being written on the locally attached SSDs offered via NVMe instance storage."
What encryption algorithm is used to encrypt Amazon EC2 NVMe instance storage?  ,Amazon EC2 NVMe instance storage is encrypted using an XTS-AES-256 block cipher.
Are encryption keys unique to an instance or a particular device for NVMe instance storage?,"Encryption keys are securely generated within the Nitro hardware module, and are unique to each NVMe instance storage device that is provided with an EC2 instance."
What is the lifetime of encryption keys on NVMe instance storage?,"All keys are irrecoverably destroyed on any de-allocation of the storage, including instance stop and instance terminate actions."
Can I disable NVMe instance storage encryption?,"No, NVMe instance storage encryption is always on, and cannot be disabled."
Do the published IOPS performance numbers on I3 include data encryption?,"Yes, the documented IOPS numbers for I3 NVMe instance storage include encryption."
Does Amazon EC2 NVMe instance storage support AWS Key Management Service (KMS)? ,"No, disk encryption on NVMe instance storage does not support integration with AWS KMS system. Customers cannot bring in their own keys to use with NVMe instance storage."
What is Optimize CPUs?,"Optimize CPUs gives you greater control of your EC2 instances on two fronts. First, you can specify a custom number of vCPUs when launching new instances to save on vCPU-based licensing costs. Second, you can disable Intel Hyper-Threading Technology (Intel HT Technology) for workloads that perform well with single-threaded CPUs, such as certain high-performance computing (HPC) applications."
Why should I use Optimize CPUs feature?,"You should use Optimize CPUs if:
You are running EC2 workloads that are not compute bound and are incurring vCPU-based licensing costs. By launching instances with custom number of vCPUs you may be able to optimize your licensing spend.
You are running workloads that will benefit from disabling hyper-threading on EC2 instances."
How will the CPU optimized instances be priced?,CPU optimized instances will be priced the same as equivalent full-sized instance.
How will my application performance change when using Optimize CPUs on EC2?,Your application performance change with Optimize CPUs will be largely dependent on the workloads you are running on EC2. We encourage you to benchmark your application performance with Optimize CPUs to arrive at the right number of vCPUs and optimal hyper-threading behavior for your application.
Can I use Optimize CPUs on EC2 Bare Metal instance types (such as i3.metal)?,No. You can use Optimize CPUs with only virtualized EC2 instances.
How can I get started with using Optimize CPUs for EC2 Instances?,"For more information on how to get started with Optimize CPUs and supported instance types, please visit the Optimize CPUs documentation page 
here
."
What is VM Import/Export?,VM Import/Export enables customers to import Virtual Machine (VM) images in order to create Amazon EC2 instances. Customers can also export previously imported EC2 instances to create VMs. Customers can use VM Import/Export to leverage their previous investments in building VMs by migrating their VMs to Amazon EC2.
What operating systems are supported?,"VM Import/Export currently supports Windows and Linux VMs, including 
Windows Server 2003
, Windows Server 2003 R2, Windows Server 2008, Windows Server 2012 R1, Red Hat Enterprise Linux (RHEL) 5.1-6.5 (using Cloud Access), Centos 5.1-6.5, Ubuntu 12.04, 12.10, 13.04, 13.10, and Debian 6.0.0-6.0.8, 7.0.0-7.2.0. For more details on VM Import, including supported file formats, architectures, and operating system configurations, please see the VM Import/Export section of the 
Amazon EC2 User Guide
."
What virtual machine file formats are supported?,"You can import VMware ESX VMDK images, Citrix Xen VHD images, Microsoft Hyper-V VHD images and RAW images as Amazon EC2 instances. You can export EC2 instances to VMware ESX VMDK, VMware ESX OVA, Microsoft Hyper-V VHD or Citrix Xen VHD images. For a full list of support operating systems, please see 
What operating systems are supported?
."
What is VMDK?,"VMDK is a file format that specifies a virtual machine hard disk encapsulated within a single file. It is typically used by virtual IT infrastructures such as those sold by VMware, Inc."
How do I prepare a VMDK file for import using the VMware vSphere client?,The VMDK file can be prepared by calling File-Export-Export to OVF template in VMware vSphere Client. The resulting VMDK file is compressed to reduce the image size and is compatible with VM Import/Export. No special preparation is required if you are using the Amazon EC2 VM Import Connector vApp for VMware vCenter.
What is VHD?,VHD (Virtual Hard Disk) is a file format that that specifies a virtual machine hard disk encapsulated within a single file. The VHD image format is used by virtualization platforms such as Microsoft Hyper-V and Citrix Xen.
How do I prepare a VHD file for import from Citrix Xen?,"Open Citrix XenCenter and select the virtual machine you want to export. Under the Tools menu, choose ""Virtual Appliance Tools"" and select ""Export Appliance"" to initiate the export task. When the export completes, you can locate the VHD image file in the destination directory you specified in the export dialog."
How do I prepare a VHD file for import from Microsoft Hyper-V?,"Open the Hyper-V Manager and select the virtual machine you want to export. In the Actions pane for the virtual machine, select ""Export"" to initiate the export task. Once the export completes, you can locate the VHD image file in the destination directory you specified in the export dialog."
Are there any other requirements when importing a VM into Amazon EC2?,"The virtual machine must be in a stopped state before generating the VMDK or VHD image. The VM cannot be in a paused or suspended state. We suggest that you export the virtual machine with only the boot volume attached. You can import additional disks using the ImportVolume command and attach them to the virtual machine using AttachVolume. Additionally, encrypted disks (e.g. Bit Locker) and encrypted image files are not supported. You are also responsible for ensuring that you have all necessary rights and licenses to import into AWS and run any software included in your VM image."
Does the virtual machine need to be configured in any particular manner to enable import to Amazon EC2?,"Ensure Remote Desktop (RDP) or Secure Shell (SSH) is enabled for remote access and verify that your host firewall (Windows firewall, iptables, or similar), if configured, allows access to RDP or SSH. Otherwise, you will not be able to access your instance after the import is complete. Please also ensure that Windows VMs are configured to use strong passwords for all users including the administrator and that Linux VMs and configured with a public key for SSH access."
How do I import a virtual machine to an Amazon EC2 instance?,"You can import your VM images using the Amazon EC2 API tools:
Import the VMDK, VHD or RAW file via the ec2-import-instance API. The import instance task captures the parameters necessary to properly configure the Amazon EC2 instance properties (instance size, Availability Zone, and security groups) and uploads the disk image into Amazon S3.
If ec2-import-instance is interrupted or terminates without completing the upload, use ec2-resume-import to resume the upload. The import task will resume where it left off.
Use the ec2-describe-conversion-tasks command to monitor the import progress and obtain the resulting Amazon EC2 instance ID.
Once your import task is completed, you can boot the Amazon EC2 instance by specifying its instance ID to the ec2-run-instances API.
Finally, use the ec2-delete-disk-image command line tool to delete your disk image from Amazon S3 as it is no longer needed.
Alternatively, if you use the VMware vSphere virtualization platform, you can import your virtual machine to Amazon EC2 using a graphical user interface provided through 
AWS Management Portal for vCenter.
 Please refer to Getting Started Guide in AWS Management Portal for vCenter. AWS Management Portal for vCenter includes integrated support for 
VM Import
. Once the portal is installed within vCenter, you can right-click on a VM and select “Migrate to EC2” to create an EC2 instance from the VM. The portal will handle exporting the VM from vCenter, uploading it to S3, and converting it into an EC2 instance for you, with no additional work required. You can also track the progress of your VM migrations within the portal."
How do I export an Amazon EC2 instance back to my on-premise virtualization environment?,"You can export your Amazon EC2 instance using the Amazon EC2 CLI tools:
Export the instance using the ec2-create-instance-export-task command. The export command captures the parameters necessary (instance ID, S3 bucket to hold the exported image, name of the exported image, VMDK, OVA or VHD format) to properly export the instance to your chosen format. The exported file is saved in an S3 bucket that you previously created
Use ec2-describe-export-tasks to monitor the export progress
Use ec2-cancel-export-task to cancel an export task prior to completion"
Are there any other requirements when exporting an EC2 instance using VM Import/Export?,"You can export running or stopped EC2 instances that you previously imported using VM Import/Export. If the instance is running, it will be momentarily stopped to snapshot the boot volume. EBS data volumes cannot be exported. EC2 instances with more than one network interface cannot be exported."
Can I export Amazon EC2 instances that have one or more EBS data volumes attached?,"Yes, but VM Import/Export will only export the boot volume of the EC2 instance."
What does it cost to import a virtual machine?,"You will be charged standard Amazon S3 data transfer and storage fees for uploading and storing your VM image file. Once your VM is imported, standard Amazon EC2 instance hour and EBS service fees apply. If you no longer wish to store your VM image file in S3 after the import process completes, use the ec2-delete-disk-image command line tool to delete your disk image from Amazon S3."
What does it cost to export a virtual machine?,"You will be charged standard Amazon S3 storage fees for storing your exported VM image file. You will also be charged standard S3 data transfer charges when you download the exported VM file to your on-premise virtualization environment. Finally, you will be charged standard EBS charges for storing a temporary snapshot of your EC2 instance. To minimize storage charges, delete the VM image file in S3 after downloading it to your virtualization environment."
"When I import a VM of Windows Server 2003 or 2008, who is responsible for supplying the operating system license?","When you launch an imported VM using Microsoft Windows Server 2003 or 2008, you will be charged standard instance hour rates for Amazon EC2 running the appropriate Windows Server version, which includes the right to utilize that operating system within Amazon EC2. You are responsible for ensuring that all other installed software is properly licensed.
So then, what happens to my on-premise Microsoft Windows license key when I import a VM of Windows Server 2003 or 2008? Since your on-premise Microsoft Windows license key that was associated with that VM is not used when running your imported VM as an EC2 instance, you can reuse it for another VM within your on-premise environment."
Can I continue to use the AWS-provided Microsoft Windows license key after exporting an EC2 instance back to my on-premise virtualization environment?,"No. After an EC2 instance has been exported, the license key utilized in the EC2 instance is no longer available. You will need to reactivate and specify a new license key for the exported VM after it is launched in your on-premise virtualization platform."
"When I import a VM with Red Hat Enterprise Linux (RHEL), who is responsible for supplying the operating system license?","When you import Red Hat Enterprise Linux (RHEL) VM images, you can use license portability for your RHEL instances. With license portability, you are responsible for maintaining the RHEL licenses for imported instances, which you can do using Cloud Access subscriptions for Red Hat Enterprise Linux. Please contact Red Hat to learn more about Cloud Access and to verify your eligibility."
How long does it take to import a virtual machine?,"The length of time to import a virtual machine depends on the size of the disk image and your network connection speed. As an example, a 10 GB Windows Server 2008 SP2 VMDK image takes approximately 2 hours to import when it’s transferred over a 10 Mbps network connection. If you have a slower network connection or a large disk to upload, your import may take significantly longer."
In which Amazon EC2 regions can I use VM Import/Export?,"Visit the 
Region Table
 page to see product service availability by region."
How many simultaneous import or export tasks can I have?,Each account can have up to five active import tasks and five export tasks per region.
Can I run imported virtual machines in Amazon Virtual Private Cloud (VPC)?,"Yes, you can launch imported virtual machines within Amazon VPC."
Can I use the AWS Management Console with VM Import/Export?,"No. VM Import/Export commands are available via EC2 CLI and API. You can also use the 
AWS Management Portal for vCenter
 to import VMs into Amazon EC2. Once imported, the resulting instances are available for use via the AWS Management Console."
Can I use my existing Windows Server license with EC2?,"Yes you can. After you’ve imported your own Windows Server machine images using the ImportImage tool, you can launch instances from these machine images on EC2 Dedicated Hosts and effectively manage instances and report usage. Microsoft typically requires that you track usage of your licenses against physical resources such as sockets and cores and Dedicated Hosts helps you to do this. Visit the Dedicated Hosts detail page for more information on how to use your own Windows Server licenses on Amazon EC2 Dedicated Hosts."
What software licenses can I bring to the Windows environment?,"Specific software license terms vary from vendor to vendor. Therefore, we recommend that you check the licensing terms of your software vendor to determine if your existing licenses are authorized for use in Amazon EC2."
How am I billed for my use of Amazon EC2 running IBM?,"You pay only for what you use and there is no minimum fee. Pricing is per instance-hour consumed for each instance type. Partial instance-hours consumed are billed as full hours. Data transfer for Amazon EC2 running IBM is billed and tiered separately from Amazon EC2. There is no Data Transfer charge between two Amazon Web Services within the same region (i.e. between Amazon EC2 US West and another AWS service in the US West). Data transferred between AWS services in different regions will be charged as Internet Data Transfer on both sides of the transfer.
 For Amazon EC2 running IBM pricing information, please visit the pricing section on the 
Amazon EC2 running IBM detail page
."
Can I use Amazon DevPay with Amazon EC2 running IBM?,"No, you cannot use DevPay to bundle products on top of Amazon EC2 running IBM at this time."
 How do I use this service?,"The service provides an NTP endpoint at a link-local IP address (169.254.169.123) accessible from any instance running in a VPC. Instructions for configuring NTP clients are available for 
Linux
 and 
Windows
."
 What are the key benefits of using this service?,A consistent and accurate reference time source is crucial for many applications and services. The Amazon Time Sync Service provides a time reference that can be securely accessed from an instance without requiring VPC configuration changes and updates. It is built on Amazon’s proven network infrastructure and uses redundant reference time sources to ensure high accuracy and availability.
 Which instance types are supported for this service?,All instances running in a VPC can access the service.
What does your Amazon EC2 Service Level Agreement guarantee?,Our SLA guarantees a Monthly Uptime Percentage of at least 99.99% for Amazon EC2 and Amazon EBS within a Region.
How do I know if I qualify for a SLA Service Credit?,"You are eligible for a SLA credit for either Amazon EC2 or Amazon EBS (whichever was Unavailable, or both if both were Unavailable) if the Region that you are operating in has an Monthly Uptime Percentage of less than 99.95% during any monthly billing cycle. For full details on all of the terms and conditions of the SLA, as well as details on how to submit a claim, please see 
http://aws.amazon.com/ec2/sla/"
What is changing?,"Starting July 2018, all newly created EC2 resources will receive longer format IDs. The new format will only apply to newly created resources; your existing resources won’t be affected. Instances and volumes already use this ID format. Through the end of June 2018, customers will have the ability to opt-in to use longer IDs. During this time, you can choose which ID format resources are assigned and update your management tools and scripts to add support for the longer format. Please visit 
this
 documentation for instructions."
Why is this necessary?,"Given how fast AWS continues to grow, we will start to run low on IDs for certain resources in 2018. In order to enable the long-term, uninterrupted creation of new resources, we need to introduce a longer ID format. All Amazon EC2 resource IDs will change to the longer format in July 2018."
Q:  I already opted in for longer IDs last year. Why do I need to opt-in again?,"In 2016, we moved to the longer ID format for Amazon EC2 instances, reservations, volumes, and snapshots only. This opt-in changes the ID format for all remaining EC2 resource types"
What will the new identifier format look like?,"The new identifier format will follow the pattern of the current identifier format, but it will be longer. The new format will be -<17 characters>, e.g. “vpc-1234567890abcdef0” for VPCs or “subnet-1234567890abcdef0” for subnets."
Which IDs are changing?,"bundle
conversion-task
customer-gateway
dhcp-options
elastic-ip-allocation
elastic-ip-association
export-task
flow-log
image
import-task
internet-gateway
network-acl
network-acl-association
network-interface
network-interface-attachment
prefix-list
route-table
route-table-association
security-group
subnet
subnet-cidr-block-association
vpc
vpc-cidr-block-assocation
vpc-endpoint
vpc-peering-connection
vpn-connection
vpn-gateway"
 How does this impact me?,"There is a good chance that you won’t need to make any system changes to handle the new format. If you only use the console to manage AWS resources, you might not be impacted at all, but you should still update your settings to use the longer ID format as soon as possible. If you interact with AWS resources via APIs, SDKs, or the AWS CLI, you might be impacted, depending on whether your software makes assumptions about the ID format when validating or persisting resource IDs. If this is the case, you might need to update your systems to handle the new format.
Some failure modes could include:
If your systems use regular expressions to validate the ID format, you might error if a longer format is encountered.
If there are expectations about the ID length in your database schemas, you might be unable to store a longer ID."
Will this affect existing resources?,"No. Only resources that are created after you opt-in to the longer format will be affected. Once a resource has been assigned an ID (long or short), that ID will never change. Each ID is unique and will never be reused. Any resource created with the old ID format will always retain its shorter ID. Any resource created with the new format will retain its longer ID, even if you opt back out."
When will this happen?,"Through the end of June 2018, longer IDs will be available for opt-in via APIs and the EC2 Console. All accounts can opt-in and out of longer IDs as needed for testing. Starting on July 1, 2018, the option to switch formats will no longer be available, and newly created EC2 resources to receive longer IDs. All regions launching in July 2018 and onward will only support longer IDs."
Why is there an opt-in period?,"We want to give you as much time as possible to test your systems with the new format. This transition time offers maximum flexibility to test and update your systems incrementally and will help minimize interrupts as you add support for the new format, if necessary."
How do I opt in and out of receiving longer IDs?,"Throughout the transition period (Now through the end of June 2018), you can opt to receive longer or shorter IDs by using the APIs or the EC2 Console. Instructions are provided in 
this
 documentation."
What will happen if I take no action?,"If you do not opt-in to the new format during the transition period, you will be automatically begin receiving the longer format IDs after July 1, 2018. We do not recommend this approach. It is better to add support for the new format during the transition window, which offers the opportunity for controlled testing."
What if I prefer to keep receiving the shorter ID format after the end of June 2018?,This is not possible regardless of your user settings specified.
When will the longer IDs’ final transition happen?,"In July 2018, your newly created resources will start to receive longer IDs. You can check the scheduled transition date for your each region by using the AWS CLI 
describe-id-format
."
"If I opt in to longer IDs and then opt back out during the transition period, what will happen to resources that were created with longer IDs?","Once a resource has been assigned an ID it will not change, so resources that are created with longer IDs will retain the longer IDs regardless of later actions. If you opt in to the longer format, create resources, and then opt out, you will see a mix of long and short resource IDs, even after opting out. The only way to get rid of long IDs will be to delete or terminate the respective resources. For this reason, exercise caution and avoid creating critical resources with the new format until you have tested your tools and automation."
What should I do if my systems are not working as expected before the transition period ends?,"If your systems are not working as expected during the transition period, you can temporarily opt out of longer format IDs and remediate your systems, however your account will automatically be transitioned back to using longer IDs after the end of June 2018. Regardless of your account settings, all new resources will receive the longer format IDs, so it is important for you to test your systems with longer format IDs before the transition period ends. By testing and opting in earlier, you give yourself valuable time to make modifications to your resources with short resource IDs and you minimize the risk of any impact to your systems."
What will happen if I launch resources in multiple regions during the transition period?,"Your resources’ ID length will depend upon the region you launch your resources. If the region has already transitioned to using longer IDs, resources launched in that region will have longer format IDs; if not, they will have shorter resource IDs. Therefore, during the transition window, you may see a mix of shorter and longer resource IDs."
"If AWS adds new regions during the transition period, will new regions support longer IDs?",Yes. All new regions launching after July 2018 will issue longer format IDs by default for both new and existing accounts.
What will be the default ID type for new accounts?,"Accounts created on March 15, 2018 or later will be configured to receive the longer ID format by default in every AWS region except AWS GovCloud (US). If you are a new customer, this will make the transition to longer IDs really simple. If you would like your new account to assign the shorter ID format to your resources, then simply reconfigure your account for shorter IDs as described above. This workflow will be necessary until you are ready for your accounts to receive longer IDs."
Will I need to upgrade to a new version of the AWS SDKs or CLI?,"The following AWS CLI and SDKs are fully compatible with longer IDs: PHP v2.8.27+, PHP v3.15.0+, AWS CLI v1.10.2+, Boto3v1.2.1+, Botocorev1.3.24+, PHP v1, Boto v1, Boto v2, Ruby v1, Ruby v2, JavaScript, Java, .NET, AWS Tools for Windows PowerShell, and Go."
What is Amazon CloudSearch?,"Amazon CloudSearch is a fully-managed service in the AWS Cloud that makes it easy to set up, manage, and scale a search solution for your website or application."
What are the benefits of running a managed search service like Amazon CloudSearch over running my own search service on EC2?,"Amazon CloudSearch provides several benefits over running your own self-managed search service including easy configuration, auto scaling for data and traffic, self-healing clusters, and high availability with Multi-AZ. With a few clicks in the AWS Management Console, you can create a search domain and upload the data you want to make searchable, and Amazon CloudSearch automatically provisions the required resources and deploys a highly tuned search index."
What is a search engine?,"A search engine makes it possible to search large collections of mostly textual data items (called documents) to quickly find the best matching results. Search requests are usually a few words of unstructured text, such as ""matt damon movies"". The returned results are usually ranked with the best matching, or most relevant, items listed first (the ones that are most ""about"" the search words).
Documents may be completely unstructured, or they can contain multiple fields that can optionally be searched individually. For example, a search service for movies might have documents with fields for title, director, actor, description, and reviews. Results returned by a search engine are typically proxies for the underlying documents, such as URLs that reference particular web pages. However, the search service can also return the actual contents of individual fields."
What benefits does Amazon CloudSearch offer?,"Amazon CloudSearch is a fully managed search service that automatically scales with the volume of data and complexity of search requests to deliver fast and accurate results. Amazon CloudSearch lets customers add search capability without needing to manage hosts, traffic and data scaling, redundancy, or software packages. Users pay low hourly rates only for the resources consumed. Amazon CloudSearch can offer significantly lower total cost of ownership compared to operating and managing your own search environment."
Can Amazon CloudSearch be used with a storage service?,"A search service and a storage service are complementary. A search service requires that your documents already be stored somewhere, whether it's in files of a file system, data in Amazon S3, or records in an Amazon DynamoDB or Amazon RDS instance. The search service is a rapid retrieval system that makes those items searchable with sub-second latencies through a process called indexing."
Can Amazon CloudSearch be used with a database?,"Search engines and databases are not mutually exclusive - in fact, they are often used together. If you already have a database that contains structured data, you might want to use a search engine to intelligently filter and rank the database contents using search keywords as relevance criteria.
A search service can be used to index and search both structured and unstructured data. Content can come from multiple sources and can include database fields along with files in a variety of formats, web pages, and so on. A search service can support customizable result ranking as well as special search features such as using facets for filtering that are not available in databases."
What regions is Amazon CloudSearch available in?,"Amazon CloudSearch is available in the following AWS Regions: US East (Northern Virgina), US West (Oregon), US West (N. California), EU (Ireland), EU (Frankfurt), South America (Sao Paulo) and Asia Pacific (Singapore, Tokyo, Sydney, and Seoul)."
What new features does Amazon CloudSearch support?,"With this latest release Amazon CloudSearch supports several new search and administration features. The key new features include:
Language support: 
            
34 languages, plus ""multiple"" to handle mixed language fields
Per-field language configuration
Language-specific text analysis
Multiple levels of algorithmic stemming are available for many languages, including ""none""
Enhanced search features: 
            
Suggestions
Highlighting
Geospatial search
New data types: date, double, 64 bit signed int, latlon
Sloppy phrase search
Term boosting
Enhanced range searching for all field types
Support for multiple query parsers: simple, structured, lucene, dismax"
Query parser configuration options,"Administration features: 
            
High availability option
IAM integration
User configurable scaling
Available in additional AWS Regions: Asia Pacific (Tokyo), Asia Pacific (Singapore), Asia Pacific (Sydney), Asia Pacific (Seoul), and South America (Sao Paulo)"
Does Amazon CloudSearch still support dictionary stemming?,Yes. The new version of Amazon CloudSearch supports dictionary stemming in addition to algorithmic stemming.
Does the new version of Amazon CloudSearch use Apache Solr?,"Yes. The latest version of Amazon CloudSearch has been modified to use Apache Solr as the underlying text search engine. Amazon CloudSearch now provides several popular search engine features available with Apache Solr in addition to the managed search service experience that makes it easy to set up, operate, and scale a search domain."
Can I access the new version of Amazon CloudSearch through the console?,"Yes. You can access the new version of Amazon CloudSearch through the console. If you are a current Amazon CloudSearch customer with existing search domains, you have the option to select which version of Amazon CloudSearch you want to use when creating new search domains. New customers will use the new version of Amazon CloudSearch by default and will not have access to the 2011-01-01 version."
What data types does the new version of Amazon CloudSearch support?,"Amazon CloudSearch supports two types of text fields, text and literal. Text fields are processed according to the language configured for the field to determine individual words that can serve as matches for queries. Literal fields are not processed and must match exactly, including case. CloudSearch also supports four numeric types: int, double, date, and latlon. Int fields hold 64-bit, signed integer values. Double fields hold double-width floating point values. Date fields hold dates specified in UTC (Coordinated Universal Time) according to IETF RFC3339: yyyy-mm-ddT00:00:00Z. Latlon fields contain a location stored as a latitude and longitude value pair."
Will my existing search domains created with the 2011-02-01 version of Amazon CloudSearch continue to work?,Yes. Existing search domains created with the 2011-02-01 version of Amazon CloudSearch will continue to work.
Will I be able to use the new features on my existing search domains created with the 2011-01-01 version of Amazon CloudSearch?,No. Existing search domains created with the 2011-01-01 version of Amazon CloudSearch will not have access to the features available in the new version. To access the new features you will have to create a new search domain using the 2013-01-01 version of Amazon CloudSearch.
How can I migrate my applications built using the 2011-01-01 version of Amazon CloudSearch to the new version of Amazon CloudSearch?,"To use the new version of Amazon CloudSearch you need to recreate existing domains using the new version of Amazon CloudSearch and re-upload your data. For more information, see 
Migrating to the 2013-01-01 API
 in the Amazon CloudSearch Developer Guide."
Will AWS continue to support the 2011-02-01 version of Amazon CloudSearch?,Yes. AWS will continue support for the 2011-02-01 version of Amazon CloudSearch.
Can I create new search domains using the 2011-02-01 version of Amazon CloudSearch?,Current Amazon CloudSearch customers who have existing 2011-02-01 domains will be able to choose whether their new domains use the 2011-02-01 API or the new 2013-01-01 API. Search domains created by new customers will automatically be created with the 2013-01-01 API.
Can I take advantage of the free trial offer with the new version of Amazon CloudSearch?,"New customers will still be able to take advantage of the free trial offer available with Amazon CloudSearch. See the 
Amazon CloudSearch Free Trial
 page for details."
How do I get started with Amazon CloudSearch?,"To sign up for Amazon CloudSearch, click the 
Create Free Account
 button on the Amazon CloudSearch detail page and complete the sign-up process. You must have an Amazon Web Services account. If you do not already have one, you will be prompted to create an AWS account when you begin the Amazon CloudSearch sign-up process.
After you have signed up, select 
Amazon CloudSearch
 from the AWS Management Console. Using the Amazon CloudSearch console you can quickly create a search domain, configure your search fields, upload sample data, and send search queries to your search domain. You can also use the AWS SDKs and the CLI to perform these operations.
For more information, see the 
Getting Started
 tutorial in the 
Amazon CloudSearch Developer Guide
."
Do the AWS SDKs support Amazon CloudSearch?,"Yes, the AWS SDKs for Java, Ruby, Python, .Net, PHP, and Node.js provide support for CloudSearch. Using the AWS SDKs you can quickly create a search domain, configure your search fields, upload data, and send search queries to your search domain."
 Does the AWS CLI support Amazon CloudSearch?,"Yes, the AWS CLI provides support for CloudSearch. Using the AWS CLI you can quickly create a search domain, configure your search fields, upload data, and send search queries to your search domain."
Can I still use the Amazon CloudSearch CLTs?,"Yes, the Amazon CloudSearch CLTs will continue to work."
What is a search domain and how do I create one?,"A search domain is a data container and a set of services that make the data searchable. These services include:
A document service that allows you upload data to your domain for indexing.
A search service that allows you to perform search requests against your indexed data.
A configuration service for controlling your domain's behavior (including relevance ranking).
You can create, manage, and delete search domains using the AWS Management Console, AWS SDKs, or AWS CLI."
How do I upload documents to my search domain?,"You upload documents to your domain using the AWS Management Console, AWS SDKs, or AWS CLI."
Do my documents need to be in a particular format?,"To make your data searchable, you need to format your data in JSON or XML.  Each item that you want to be able to receive as a search result is represented as a document. Every document has a unique document ID and one or more fields that contain the data that you want to search and return in results. Amazon CloudSearch generates a search index from your document data according to the index fields configured for the domain. As your data changes, you submit updates to add or delete documents from your index."
How do I create document batches formatted for Amazon CloudSearch?,"To create document batches that describe your data, you create JSON or XML text files that specify:
The operation type: add or delete
A unique identifier
The actual fields and their data
The following example shows a single document batch formatted in JSON:
Note that numeric values such as the year are not enclosed in quotes, and that values in a multi-value field such as genres are listed in a JSON array.
To make this data available to Amazon CloudSearch, you can save it to a file and upload it using the AWS Management Console, AWS SDKs, or AWS CLI."
How do my documents get indexed?,Documents are automatically indexed when you upload them to your search domain. You can also explicitly re-index your documents when you make configuration changes by sending an IndexDocuments request.
When do I need to re-index my domain?,"Certain configuration options, such as adding a new index field or updating your stemming or stopword dictionaries, are not available until your domain is re-indexed. When you have made changes that require indexing, the domain’s status will indicate that it needs to be indexed. You can initiate indexing from the AWS Management Console, AWS SDKs, or AWS CLI."
How do I send search requests to my search domain?,"Every search domain has a REST-based search service with a unique URL (search endpoint) that accepts search requests for its document set. You can send search requests from the AWS Management Console, AWS SDKs, or AWS CLI."
Can a search domain span multiple Availability Zones?,"Yes. If you enable the Multi-AZ option, Amazon CloudSearch deploys additional instances in a second availability zone in the same Region. For more information, see 
Configuring Availability Options
 in the Amazon CloudSearch Developer Guide."
Can I move a search domain from one region to another?,"At this time, there is no way to automatically migrate a search domain from one region to another. You will need to create a new domain in the target region, configure the domain and upload your data, then delete the original domain."
How do I delete my search domain?,"To delete a search domain, click on Delete Domain button in the Amazon CloudSearch console. You can also delete domains through the AWS SDKs or AWS CLI."
How do I delete documents from my search domain?,"To delete documents you specify a delete operation in your batch upload that contains the ID of the document you want to remove.
You can submit data updates through the AWS Management Console, AWS SDKs, or AWS CLI."
How do I empty my search domain?,"If you wish to maintain your domain’s endpoints, you can send a delete for each document that is in your domain."
"Why is my domain in the ""Processing"" state?","A domain can be in one of three different states: “processing,” “active,” or “reindexing.” Normally, your domain will be in the “active” state, which indicates that no changes are currently being made, that the domain can be queried and updated, and that all previous changes are currently visible in the search results.
When a domain needs to be re-indexed, Amazon CloudSearch needs to rebuild the index entirely. However, the domain does not enter the “processing” state until you initiate reindexing. During this stage, the domain can still be queried and updated, but the configuration changes won't be visible in search results until indexing is completed, and the domain's status changes back to “active.”
You can also continue to upload document batches to your domain. However, if you submit a large volume of updates while your domain is in the “processing” state, it can increase the amount of time it takes for the updates to be applied to your search index. If this becomes an issue, slow down your update rate until the domain returns to the “active” state."
What are the best practices for bootstrapping data into CloudSearch?,"After you’ve launched your domain, the next step is loading your data into Amazon CloudSearch. You’ll likely need to upload a single large dataset, and then make smaller updates or additions as new data comes in. The following guidelines will help make bootstrapping your initial data into CloudSearch quick and easy.
1. Use the curl-v command line tool when preparing your script
During the upload of a dataset, the script you’ve written reads your data and uses it to create JSON or XML documents. We recommend preparing this script in advance, and using curl or another simple command line tool to see if you’re able to upload the documents that the script creates. The “-v” option in curl often provides more detailed information about syntax problems than the AWS SDK or Boto, which both suppress errors for production purposes. Curl displays more detailed error messages, which helps identify the sources of any issues.
2. Use the UTF-8 character code
Make sure that all data is formatted in the UTF-8 character code format, and that any bad Unicode characters have been removed before uploading to CloudSearch. Illegal characters will cause the document upload to fail.
3. Batch your documents
Batching your documents is perhaps the most important step in data bootstrapping. Submitting documents to CloudSearch individually is not only inefficient, but also leads to preventable errors.
A document batch is simply a collection of add and delete operations that represent the documents you want to add, update, or delete from your domain. Batches are described in either JSON or XML, and when you upload them to a domain, the data is indexed automatically, according to the domain's indexing options. Since you’re billed for the total number of document batches uploaded to your search domain, it’s more cost-effective to upload your data in batches of 5 MB, the maximum allowed per upload. You can also upload batches in parallel to reduce the amount of time it takes to upload your data.
 4. Pre-scale
It’s also important to pre-scale your data before uploading it to CloudSearch. Pre-scaling involves selecting the appropriate instance type for the amount of data you wish to upload.
Choosing an instance with enough capacity to handle the size of your upload can help prevent errors and a high replication count. Although replication can help decrease search response time, it doesn’t increase the size of the data pipe or address core problems in data uploads.
CloudSearch will automatically scale up to larger instances as you send more data. Still, pre-selecting the appropriate instance type saves time later in the bootstrapping process, as scaling from one instance to another tends to be a slower process. Below is a sample script to pre-scale the domain for boostrapping and to restore the instance type after data is loaded.
Pre-scale before bootstrapping:
Restore after data loading:"
What are some ways to avoid 504 errors?,"If you’re seeing 504 errors or high replication counts, try moving to larger instance type. For example, if you’re having problems with m3.large, move up to m3.xlarge. If you continue to get 504 errors even after pre-scaling, start batching the data and increase the delay between retries."
What are the best practices to accelerate domain configuration and re-indexing?,"When you change the configuration options of your search domain, you must rebuild your search index for those changes to take effect in search results. Rebuilding the index can take 30 to 60 minutes whether you make one configuration change at a time or several configuration changes at once. Even if your domain has only a small number of documents, re-indexing takes this time because of the processing and provisioning necessary to build the index and distribute it. Therefore, you should plan your configuration changes ahead of time, make all of your changes at once, and then re-index your domain. The same applies when setting up a new domain - plan your configuration before you set it up so that you can index only once and get up and running in the shortest time possible.
 Some domain changes require re-indexing while others just require re-deploying the existing index. Redeploying the domain takes 10 to 15 minutes compared to 30-60 minutes for re-indexing. During re-deployment, CloudSearch creates new nodes, deploys the index on them, and shuts down the old nodes. Your domain status changes to “Processing” during re-deployment. When re-indexing is needed, your domain status changes to “Needs Indexing,” followed by “Processing” once you have initiated indexing. Once the new index is created, your domain is re-deployed. The following table summarizes which changes require re-indexing followed by re-deployment and which changes require just re-deployment. Understanding this will help you better plan your configuration changes."
What search features does Amazon CloudSearch provide?,"Amazon CloudSearch provides features to index and search both structured data and plain text, including faceted search, free text search, Boolean search expressions, customizable relevance ranking, query time rank expressions, field weighting, searching and sorting of results using any field, and text processing options including tokenization, stopwords, stemming and synonyms. It also provides near real-time indexing for document updates. New features include:
Autocomplete suggestions
Highlighting
Geospatial search
New data types: date, double, 64 bit signed int, LatLon
Dynamic fields
Index field statistics 
Sloppy phrase search
Term boosting
Enhanced range searching for all field types
Search filters that don't affect relevance
Support for multiple query parsers: simple, structured, lucene, dismax"
Query parser configuration options,
What is faceting?,"Faceting allows you to categorize your search results into refinements on which the user can further search. For example, a user might search for ""umbrellas"", and facets allow you to group the results by price, such as $0-$10, $10-$20, $20-$40, and so on. Amazon CloudSearch also allows for result counts to be included in facets, so that each refinement has a count of the number of documents in that group. The example could then be: $0-$10 (4 items), $10-$20 (123 items), $20-$40 (57 items), and so on."
What languages does Amazon CloudSearch support?,"Amazon CloudSearch currently supports 34 languages: Arabic (ar), Armenian (hy), Basque (eu), Bulgarian (bg), Catalan (ca), simplified Chinese (zh-Simp), traditional Chinese (zh-Trad), Czech (cs), Danish (da), Dutch (nl), English (en), Finnish (fi), French (fr), Galician (gl), German (de), Greek (el), Hebrew (he), Hindi (hi), Hungarian (hu), Indonesian (id), Irish (ga), Italian (it), Japanese (ja), Korean (ko), Latvian (la), Norwegian (no), Persian (fa), Portuguese (pt), Romanian (ro), Russian (ru), Spanish (es), Swedish (sv), Thai (th), and Turkish (tr). In addition, Amazon CloudSearch supports a Multiple (mul) option for fields that contain mixed languages."
Does Amazon CloudSearch support geospatial search?,"Yes, Amazon CloudSearch has a native type to support latitude and longitude (latlon), so that you can easily implement geographically-based searching and sorting. For more information, see 
Searching and Ranking Results by Geographic Location
 in the Amazon CloudSearch Developer Guide."
How quickly will my uploaded documents become searchable?,Documents uploaded to a search domain typically become searchable within seconds to a few minutes.
How many search requests can I send to my search domain?,There is no intrinsic limit on the number of search requests that can be sent to a search domain.
What factors affect the latency of my search requests?,"Your search requests are typically processed within a few hundred milliseconds, frequently much faster. Latency is affected by many factors including the time it takes for your request and responses to travel between your own application and your search domain, the complexity of your search request, and how heavily you are using your search domain."
What makes one search request more complex than another?,"Amazon CloudSearch is designed to efficiently process a wide range of search requests very quickly. Search requests vary in complexity depending on the expressions that determine which documents match and additional criteria that determine how closely each document matches. Search requests that match a large number of documents take longer to process than those that match very few documents. Search requests that compute complex expressions take longer to process than those that rank using a simple criteria such as a single field. To help you understand the difference in complexity between Search requests, the time it took to process the request is returned as part of the response."
Where should I run my search application to minimize communication time with my search domain?,Applications hosted in the same AWS Region as your search domain will experience the fastest communication times.
What is a search instance?,"A search instance is a single search engine in 
the cloud
 that indexes documents and responds to search requests. It has a finite amount of RAM and CPU resources for indexing data and processing requests."
What is a search partition?,"A search partition is the portion of your data which fits on a single search instance. A search domain can have one or more search partitions, and the number of search partitions can change as your documents are indexed."
How does my search domain scale to meet my application needs?,"Search domains scale in two dimensions: data and traffic. As your data volume grows, you need more (or larger) Search instances to contain your indexed data, and your index is partitioned among the search instances. As your request volume or request complexity increases, each Search Partition must be replicated to provide additional CPU for that Search Partition. For example, if your data requires three search partitions, you will have 3 search instances in your search domain. As your traffic increases beyond the capacity of a single search instance, each partition is replicated to provide additional CPU capacity, adding an additional three search instances to your search domain. Further increases in traffic will result in additional replicas, to a maximum of 5, for each search partition."
How much data can I upload to my search domain?,"The number of partitions you need depends on your data and configuration, so the maximum data you can upload is the data set that when your search configuration is applied results in 10 search partitions. When you exceed your search partition limit, your domain will stop accepting uploads until you delete documents and re-index your domain. If you need more than 10 search partitions, please 
contact us
."
Do I need to select the number and type of search instances for my search domain?,"CloudSearch is a fully managed search service that automatically scales your search domain and selects the number and type of search instances. All search instances in a given search domain are of the same type and this type can change over time as your data or traffic grows.
You can also configure scaling options for an Amazon CloudSearch domain to:
Increase the upload capacity
Speed up search requests
Increase the search capacity
Improve fault tolerance"
What instance types does Amazon CloudSearch support?,"Amazon CloudSearch supports the following instance types:
Small Search Instance
Large Search Instance
Extra Large Search Instance
Double Extra Large Search Instance"
How do I find out the number and type of search instances in my search domain?,"You can find out the number and type of search instances in your search domain by using the AWS Management Console, AWS SDKs, or AWS CLI. The number and type of search instances change over time and automatically scale up and down according to your indexable data and search traffic."
How quickly does my search domain scale to accommodate changes in data and traffic?,"Search domains typically react to increases in traffic changes within minutes. Changes in data volume or a reduction in traffic might take longer but you can accelerate this process by invoking an IndexDocuments operation. If you are about to upload a large amount of data or expect a surge in query traffic, you can prescale your domain by setting the desired instance type and replication count. For more information, see 
Configuring Scaling Options
 in the Amazon CloudSearch Developer Guide."
Does Amazon CloudSearch support Multi-AZ deployments?,"Yes. Amazon CloudSearch supports Multi-AZ deployments. When you enable the Multi-AZ option, Amazon CloudSearch provisions and maintains extra instances for your search domain in a second Availability Zone to ensure high availability. Updates are automatically applied to the instances in both Availability Zones. Search traffic is distributed across all of the instances and the instances in either zone are capable of handling the full load in the event of a failure."
How does the new Multi-AZ feature work? Will my system experience any downtime in the event of a failure?,"When the Multi-AZ option is enabled, Amazon CloudSearch instances in either zone are capable of handling the full load in the event of a failure. If there's service disruption or the instances in one zone become degraded, Amazon CloudSearch routes all traffic to the other Availability Zone. Redundant instances are restored in a separate Availability Zone without any administrative intervention or disruption in service.
Some inflight queries might fail and will need to be retried. Updates sent to the search domain are stored durably and will not be lost in the event of a failure."
Can a search domain be deployed in more than 2 Availability Zones?,No. The maximum number of Availability Zones a domain can be deployed in is two.
Can I modify the Multi-AZ configuration on my search domain?,Yes. You can turn the Multi-AZ configuration on and off for your search domains. The service is not interrupted when this setting is changed.
Can I choose which Availability Zones my search domain is deployed in?,No. At this time Amazon CloudSearch automatically chooses an alternate Availability Zone in the same Region.
Can I choose the instance type my domain uses?,"Yes. With the latest release, Amazon CloudSearch enables you to specify the desired instance type for your domain. If necessary, Amazon CloudSearch will scale your domain up to a larger instance type, but will never scale back to a smaller instance type."
What is the fastest way to get my data into CloudSearch?,"By default, all domains start out on a small search instance. If you need to upload a large amount of data, you should prescale your domain to a larger instance type. For more information, see 
Bulk Uploads
 in the Amazon CloudSearch Developer Guide."
How do I know which instance type I should choose for my initial setup?,"For datasets of less than 1 GB of data or fewer than one million 1 KB documents, start with the default settings of a single small search instance. For larger data sets consider pre-warming the domain by setting the desired instance type. For data sets up to 8 GB, start with a large search instance. For datasets between 8 GB and 16 GB, start with an extra large search instance. For datasets between 16 GB and 32 GB, start with a double extra large search instance. 
Contact us
 if you need more upload capacity or have more than 500 GB to index."
 What additional security features are available with the new version of Amazon CloudSearch?,"With the latest release, Amazon CloudSearch now provides IAM integration for the configuration service and all search domain services. You can control access to specific Amazon CloudSearch actions and require request authentication for all requests. Requests are authenticated using Signature Version 4 signing."
How do I upload my data to Amazon CloudSearch securely?,You send us your data using a secure and encrypted SSL connection by using HTTPS instead of HTTP when you connect to Amazon CloudSearch.
My data is already encrypted. Can I just send you the encrypted data and the encryption key?,We do not support user-generated encryption keys. You will need to decrypt the data and upload it using HTTPS.
Do you support encrypted search results?,Yes. We support HTTPS for all Amazon CloudSearch requests.
How can I prevent specific users from accessing my search domain?,"Amazon CloudSearch supports IAM integration for the configuration service and all search domain services. You can grant users full access to Amazon CloudSearch, restrict their access to specific domains, and allow or deny access to specific actions."
How will I be charged and billed for my use of Amazon CloudSearch?,"There are no set-up fees or commitments to begin using the service. Following the end of the month, your credit card will automatically be charged for that month's usage. You can view your charges for the current billing period at any time on the AWS web site by logging into your Amazon Web Services account and clicking 
Account Activity
 under Your Web Services Account."
How much does it cost to use Amazon CloudSearch?,"There are no changes to the pricing structure for Amazon CloudSearch at this time. For detailed pricing information, see 
Amazon CloudSearch Pricing
."
Is a free trial available for Amazon CloudSearch?,"Yes, a free trial is available for new CloudSearch customers. For more information, see 
Amazon CloudSearch 30 Day Free Trial
."
How much does it cost to use the new version of Amazon CloudSearch?,"There are no changes to the pricing structure for Amazon CloudSearch at this time. See the 
Pricing
 page for more information."
Are there any cost savings to using the new version of Amazon CloudSearch?,The latest version of Amazon CloudSearch features advanced index compression and supports larger indexes on each instance type. This makes the new version of Amazon CloudSearch more efficient than the previous version and can result in significant cost savings.
Which Elasticsearch version does Amazon Elasticsearch Service support?,"Amazon Elasticsearch Service currently supports Elasticsearch versions 6.2, 6.0, 5.5, 5.3, 5.1, 2.3, and 1.5."
What is Amazon Elasticsearch Service?,"Amazon Elasticsearch Service is a managed service that makes it easy to deploy, operate, and scale Elasticsearch clusters in the AWS Cloud."
What is an Amazon Elasticsearch Service domain?,"Amazon Elasticsearch Service domains are Elasticsearch clusters created using the Amazon Elasticsearch Service console, CLI, or API. Each domain is an Elasticsearch cluster in the cloud with the 
           

             compute 
           
 and storage resources you specify. You can create and delete domains, define infrastructure attributes, and control access and security. You can run one or more Amazon Elasticsearch Service domains."
What does Amazon Elasticsearch Service manage on my behalf?,"Amazon Elasticsearch Service manages the work involved in setting up a domain, from provisioning infrastructure capacity in the network environment you request to installing the Elasticsearch software. Once your domain is running, Amazon Elasticsearch Service automates common administrative tasks, such as performing backups, monitoring instances and patching software. Amazon Elasticsearch Service integrates with Amazon CloudWatch to produce metrics that provide information about the state of the domains. Amazon Elasticsearch Service also offers options to modify your domain instance and storage settings to simplify the task of tailoring your domain based 
           

             to 
           
 your application needs."
Does Amazon Elasticsearch Service support the open source Elasticsearch APIs?,"Amazon Elasticsearch Service supports most of the commonly used Elasticsearch APIs, so the code, applications, and popular tools that you're already using with your current Elasticsearch environments work seamlessly. For a full list of supported Elasticsearch operations, see our 
documentation
.
Return to Top >>"
Can I create and modify my Amazon Elasticsearch Service domain through the Amazon Elasticsearch Service console?,"Yes. You can create a new Amazon Elasticsearch Service domain with the Domain Creation Wizard in the console with just a few clicks. While creating a new domain you can specify the number of instances, instance types, and EBS volumes you want allocated to your domain. You can also modify or delete existing Amazon Elasticsearch Service domains using the console."
Does Amazon Elasticsearch Service support Amazon VPC?,"Yes, Amazon Elasticsearch Service is integrated with Amazon VPC. When choosing VPC access, IP addresses from your VPC are attached to your Amazon Elasticsearch Service domain and all network traffic stays within the AWS network and is not accessible to the Internet. Moreover, you can use security groups and IAM policies to restrict access to your Amazon Elasticsearch Service domains."
Can I use CloudFormation Templates to provision Amazon Elasticsearch Service domains?,"Yes. 
AWS CloudFormation
 supports Amazon Elasticsearch Service. For more information, see the 
CloudFormation Template Reference
 documentation."
Does Amazon Elasticsearch Service support configuring dedicated master nodes?,"Yes. You can configure dedicated master nodes for your domains. When choosing a dedicated master configuration, you can specify the instance type and instance count."
Can I create multiple Elasticsearch indices within a single Amazon Elasticsearch Service domain?,Yes. You can create multiple Elasticsearch indices within the same Amazon Elasticsearch Service domain. Elasticsearch automatically distributes the indices and any associated replicas between the instances allocated to the domain.
How do I ingest data into my Amazon Elasticsearch Service domain?,"Amazon Elasticsearch Service supports three options for data ingestion:
For large data volumes, we recommend Amazon Kinesis Firehose, a fully managed service that automatically scales to match the throughput of your data and requires no ongoing administration. It can also transform, batch and compress the data before loading it.
Amazon Elasticsearch Service supports integration with Logstash. You can configure your Amazon Elasticsearch Service domain as the data store for all logs arriving from your Logstash implementation.
You can use native Elasticsearch APIs, such as the index and bulk APIs, to load data into your domain."
Does Amazon Elasticsearch Service support integration with Logstash?,"Yes. Amazon Elasticsearch Service supports integration with Logstash. You can set up your Amazon Elasticsearch Service domain as the backend store for all logs coming through your Logstash implementation. You can set up access control on your Amazon Elasticsearch Service domain to either use request signing to authenticate calls from your Logstash implementation, or use resource based IAM policies to include IP addresses of instances running your Logstash implementation."
Does Amazon Elasticsearch Service support integration with Kibana?,Yes. Amazon Elasticsearch Service includes a built-in Kibana install that is deployed with your Amazon Elasticsearch Service domain.
Can I create custom reports with the Kibana installation included with Amazon Elasticsearch Service?,"Yes. Kibana supports creating and saving custom reports through the user interface. For more information on using Kibana, refer to 
Kibana documentation
."
What storage options are available with Amazon Elasticsearch Service?,"You can choose between local on-instance storage or EBS volumes. During domain creation, if you select EBS storage, you can increase and decrease the size of the storage volume as necessary."
What types of EBS volumes does Amazon Elasticsearch Service support?,"You can choose between Magnetic, General Purpose, and Provisioned IOPS EBS volumes."
Q: Is there a limit on the amount of EBS storage that can be allocated to an Amazon Elasticsearch Service domain?,"Yes. Amazon Elasticsearch Service supports one EBS volume (max size of 1.5 TB) per instance associated with a domain. With the default maximum of 20 data nodes allowed per Amazon Elasticsearch Service domain, you can allocate about 30 TB of EBS storage to a single domain. You can request a service limit increase up to 100 instances per domain by creating a case with the 
AWS Support Center
. With 100 instances, you can allocate about 150 TB of EBS storage to a single domain.
Return to Top >>"
Can programs running on servers in my own data center access my Amazon Elasticsearch Service domains?,"Yes. The programs with public Internet access can access Amazon Elasticsearch Service domains through a public endpoint. If your data center is already connected to Amazon VPC through Direct Connect or SSH tunneling, you can also use VPC access. In both cases, you can configure IAM policies and security groups to allow programs running on servers outside of AWS to access your Amazon Elasticsearch Service domains. 
Click here
 for more information about signed requests."
How can I migrate data from my existing Elasticsearch cluster to a new Amazon Elasticsearch Service domain?,"To migrate data from an existing Elasticsearch cluster you should create a snapshot of an existing Elasticsearch cluster, and store the snapshot in your Amazon S3 bucket. Then you can create a new Amazon Elasticsearch Service domain and load data from the snapshot into the newly created Amazon Elasticsearch Service domain using the Elasticsearch restore API."
How can I scale an Amazon Elasticsearch Service domain?,"Amazon Elasticsearch Service allows you to control the scaling of your Amazon Elasticsearch Service domains using the console, API, and CLI. You can scale your Amazon Elasticsearch Service domain by adding, removing, or modifying instances or storage volumes depending on your application needs. Amazon Elasticsearch Service is integrated with Amazon CloudWatch to provide metrics about the state of your Amazon Elasticsearch Service domains to enable you to make appropriate scaling decisions for your domains."
Does scaling my Amazon Elasticsearch Service domain require downtime?,"No. Scaling your Amazon Elasticsearch Service domain by adding or modifying instances, and storage volumes is an online operation that does not require any downtime."
What options does Amazon Elasticsearch Service provide for node failures?,"Amazon Elasticsearch Service automatically detects node failures and replaces the node. The service will acquire new instances, and will then redirect Elasticsearch requests and document updates to the new instances. In the event that the node cannot be replaced, customers will be able to use any snapshots they have of their cluster to restart the domain with preloaded data."
Does Amazon Elasticsearch Service support cross-zone replication?,"Yes. Customers can enable Zone Awareness for their Amazon Elasticsearch Service domains either at domain creation time or by modifying a live domain. When Zone Awareness is enabled, Amazon Elasticsearch Service will distribute the instances supporting the domain across two different Availability Zones. Then, if replication is enabled in the Elasticsearch engine, Elasticsearch will allocate replicas of the domain across these different instances enabling cross-zone replication."
Does Amazon Elasticsearch Service expose any performance metrics through Amazon CloudWatch?,"Yes. Amazon Elasticsearch Service exposes several performance metrics through Amazon CloudWatch including number of nodes, cluster health, searchable documents, EBS metrics (if applicable), CPU, memory and disk utilization for data and master nodes. Please refer to the service documentation for a full listing of available CloudWatch metrics."
I wish to perform security analysis or operational troubleshooting of my Amazon Elasticsearch Service deployment. Can I get a history of all the Amazon Elasticsearch Service API calls made on my account?,"Yes. AWS CloudTrail is a web service that records AWS API calls for your account and delivers log files to you. The AWS API call history produced by AWS CloudTrail enables security analysis, resource change tracking, and compliance auditing. Learn more about AWS CloudTrail at the 
AWS CloudTrail detail page
, and turn it on via 
CloudTrail's AWS Management Console home page
."
What is a snapshot?,A snapshot is a copy of your Amazon Elasticsearch Service domain at a moment in time.
Why would I need snapshots?,"Creating snapshots can be useful in case of data loss caused by node failure, as well as the unlikely event of a hardware failure. You can use snapshots to recover your Amazon Elasticsearch Service domain with preloaded data or to create a new Amazon Elasticsearch Service domain with preloaded data. Another common reason to use backups is for archiving purposes. Snapshots are stored in Amazon S3."
Does Amazon Elasticsearch Service provide automated snapshots?,"Yes. By default, Amazon Elasticsearch Service will automatically create daily snapshots of each Amazon Elasticsearch Service domain. The daily snapshots are setup to occur between midnight and 1AM UTC. Customers will also be able to modify the timing of the automated snapshot to better suit their needs."
Can I change the default settings for the automated daily snapshot provided by Amazon Elasticsearch Service?,Yes. You will be able to change the timing of the automated daily snapshot to suit your application schedule.
How long are the automated daily snapshots stored by Amazon Elasticsearch Service?,Amazon Elasticsearch Service will retain the last 14 days worth of automated daily snapshots.
Is there a charge for the automated daily snapshots?,There is no additional charge for the automated daily snapshots. The snapshots are stored for free in an Amazon Elasticsearch Service S3 bucket and will be made available for node recovery purposes.
Can I create additional snapshots of my Amazon Elasticsearch Service domains as needed?,Yes. You can use the Elasticsearch snapshot API to create additional manual snapshots in addition to the daily-automated snapshots created by Amazon Elasticsearch Service. The manual snapshots are stored in your S3 bucket and will incur relevant Amazon S3 usage charges.
Can snapshots created by the manual snapshot process be used to recover a domain in the event of a failure?,Yes. Customers can create a new Amazon Elasticsearch Service domain and load data from the snapshot into the newly created Amazon Elasticsearch Service domain using the Elasticsearch restore API.
What happens to my snapshots when I delete my Amazon Elasticsearch Service domain?,"The daily snapshots retained by Amazon Elasticsearch Service will be deleted as part of domain deletion. Before deleting a domain, you should consider creating a snapshot of the domain in your own S3 buckets using the manual snapshot process. The snapshots stored in your S3 bucket will not be affected if you delete your Amazon Elasticsearch Service domain."
What types of Elasticsearch logs are exposed by Amazon Elasticsearch Service?,"Amazon Elasticsearch Service exposes three Elasticsearch logs through Amazon CloudWatch Logs: error logs, search slow logs, and index slow logs. These logs are useful for troubleshooting performance and stability issues with one’s domain."
What are slow logs?,"Slow logs are log files that help track the performance of various stages in an operation. Elasticsearch exposes two kinds of slow logs:
Index slow Logs – These logs provide insights into the indexing process and can be used to fine-tune the index setup.
Search slow Logs – These logs provide insights into how fast or slow queries and fetches are performing. These logs help fine tune the performance of any kind of search operation on Elasticsearch.
For complete details on Elasticsearch slow logs, please refer to 
Elasticsearch documentation
."
How can I enable slow logs on Amazon Elasticsearch Service?,"Slows logs can be enabled via the click of a button from the Console or via our CLI and APIs. For more details please refer to our 
documentation
."
Can I only enable slow logs for specific indices?,"Yes. You can update the settings for a specific index to enable or disable slow logs for it. For more details refer to our 
documentation
."
Does turning on slow logs in Amazon Elasticsearch Service automatically enable logging for all indexes?,"No. Turning on slow logs in Amazon Elasticsearch Service enables the option to publish the generated logs to Amazon CloudWatch Logs for indices in the given domain. However, in order to generate the logs you have to update the settings for one or more indices to start the logging process. For more details on setting the index configuration for enabling slow logs, please refer to our 
documentation
."
"If I turn off the slow logs in Amazon Elasticsearch Service, does it mean that log files are no longer being generated?","No. The generation of log files are dependent on the index settings. To turn off generation of the log files you have to update the index configuration. For more details on setting the index configuration for enabling slow logs, see our 
documentation
."
Can I change the granularity of logging?,"You can only change the granularity of logging for slow logs. Elasticsearch exposes multiple levels of logging for slow logs. You need to set the appropriate level in the configuration of your index. For more details on setting the index configuration for enabling slow logs, please refer to 
Elasticsearch documentation
."
Will enabling slow logs or error logs cost me anything?,"When slow logs or error logs are enabled, Amazon Elasticsearch Service starts publishing the generated logs to CloudWatch Logs. Amazon Elasticsearch Service does not charge anything for enabling the logs. However, standard 
CloudWatch charges
 will apply."
Is there any limit on the size of each log entry?,"Yes. Each log entry made into CloudWatch will be limited to 255,000 characters. If your log entry is bigger than that, it will be truncated to 255,000 characters."
What is the recommended best practice for using slow logs?,"Slow logs are only needed when you want to troubleshoot your indexes or fine-tune performance. The recommended approach is to only enable logging for those indexes for which you need additional performance insights. Also, once the investigation is done, you should turn off logging so that you don’t incur any additional costs on account of it. For more details, see our 
documentation
."
How can I consume logs from CloudWatch Logs?,"CloudWatch offers multiple ways to consume logs. You can 
view log data
, 
export it to S3
, or 
process it in real time
. To learn more, see the 
CloudWatch Logs developer guide
."
Are slow logs available for all versions of Elasticsearch supported by Amazon Elasticsearch Service?,"Yes. slow logs can be enabled for all versions of Elasticsearch supported by Amazon Elasticsearch Service. However, there are slight differences in the way log settings can be specified for each version of Elasticsearch. Please refer to our 
documentation
 for more details."
Will the cluster have any down time when logging is turned on or off?,"No. There will not be any down-time. Every time the log status is updated, we will deploy a new cluster in the background and replace the existing cluster with the new one. This process will not cause any down time. However, since a new cluster is deployed the update to the log status will not be instantaneous."
What kinds of error logs are exposed by Amazon Elasticsearch Service?,"Elasticsearch uses 
Apache Log4j 2
 and its built-in log levels (from least to most severe) of TRACE, DEBUG, INFO, WARN, ERROR, and FATAL. If you enable application logs, Amazon Elasticsearch Service publishes log lines of WARN, ERROR, and FATAL to CloudWatch. Less severe levels (INFO, DEBUG and TRACE) are not available."
How can I enable error logs on Amazon Elasticsearch Service?,"Error logs can be enabled from the AWS console or programmatically from our CLI and APIs. For more details, please refer to our 
documentation
."
Can I enable error logs for only specific indices?,"No, error logs are exposed for the entire domain. That is, once enabled, log entries from all indices in the domain will be made available."
Are error logs available for all versions of Elasticsearch supported by Amazon Elasticsearch Service?,"No, error logs are available only for Elasticsearch versions 5.x and above.
Return to Top >>"
How can I secure my Amazon Elasticsearch Service domain?,"If you use VPC to secure your applications, data, and network traffic, you can set up VPC access for Amazon Elasticsearch Service, which allows you to control network access using your VPC security groups. You can also use IAM-based policies to provide fine-grained access control to which IAM roles can perform administrative tasks, use the Elasticsearch APIS and have access to the resources in the domain down to the index-level.
If you want to make your Amazon Elasticsearch Service domain accessible from the Internet, you can specify public access. With public access, you can control access to the endpoint by IP address and require authentication using IAM roles. IAM policies can control access to Amazon Elasticsearch Service domains and sub resources like indices within the domains.
With Amazon Cognito, you can also allow your end-users to log-in to Kibana through enterprise identity providers such as Microsoft Active Directory using SAML 2.0, and through social identity providers such as Google, Facebook, and Amazon.  You can also set up a secure, scalable, and simplified sign-up experience using Amazon Cognito User Pools. Once you sign-in, Amazon Cognito establishes a session using the appropriate AWS Identity and Access Management (IAM) role, which provides access to the Amazon Elasticsearch Service domain.
IAM policies can also be set up to control access to the management API for operations such as creating and scaling clusters and Elasticsearch API for operations like uploading documents and executing Elasticsearch requests."
Can I encrypt my data at rest while using Amazon Elasticsearch Service?,"Amazon Elasticsearch Service provides an option that allows you to encrypt your data using keys you manage through 
AWS Key Management Service (KMS)
. If enabled, all of your data stored at rest in the underlying storage systems are encrypted, including primary and replica indices, log files, memory swap files, and automated S3 snapshots. Amazon Elasticsearch Service handles encryption and decryption seamlessly, so you don’t have to modify your application to access your data. You can choose to enable encryption when you create new domains via the AWS Management Console or API. Amazon Elasticsearch Service can create a KMS master key for you, or you can choose one of your own. Encryption at rest supports both Amazon Elastic Block Store (EBS) and instance storage.
For more information about the use of AWS KMS with Amazon Elasticsearch Service, see the 
Amazon Elasticsearch Service Developer Guide
. To learn more about AWS KMS, visit the 
web page
."
How can I set up the VPC access for Amazon Elasticsearch Service?,"You configure VPC access when creating an Amazon Elasticsearch Service domain. The VPC access can be set up via a few clicks in the console or via our CLI and APIs. For more details, see the 
Amazon Elasticsearch Service developer guide
."
"If I set up VPC access for my Amazon Elasticsearch Service domain, how can I access Kibana?","When VPC access is enabled, the endpoint for Amazon Elasticsearch Service is only accessible within the customer VPC. To use your laptop to access Kibana from outside the VPC, you need to connect the laptop to the VPC using VPN or VPC Direct Connect.
Return to Top >>
On-Demand Instance Pricing"
How will I be charged and billed for my use of Amazon Elasticsearch Service?,"You pay only for what you use, and there are no minimum or setup fees. You are billed based on:
Amazon Elasticsearch Service instance hours – Based on the class (e.g. Standard Small, Large, Extra Large) of the Amazon Elasticsearch Service instance consumed. Partial Amazon Elasticsearch Service instance hours consumed are billed as full hours.
Storage (per GB per month) – Amazon EBS Storage capacity you have provisioned to your Amazon Elasticsearch Service instance. If you scale your provisioned storage capacity within the month, your bill will be pro-rated.
Provisioned IOPS per month – Amazon EBS Provisioned IOPS rate, regardless of IOPS consumed (for Amazon Elasticsearch Service Provisioned IOPS (SSD) Storage only).
Data transfer – Regular AWS data transfer charges apply.
Please refer to the Amazon Elasticsearch Service 
pricing page
 for detailed pricing information."
When does billing of my Amazon Elasticsearch Service domain begin and end?,"Billing commences for an Amazon Elasticsearch Service instance as soon as the instance is available. Billing continues until the Amazon Elasticsearch Service instance terminates, which would occur upon deletion or in the event of instance failure."
What defines billable instance hours for Amazon Elasticsearch Service?,"Amazon Elasticsearch Service instance hours are billed for each hour your instance is running in an available state. If you no longer wish to be charged for your Amazon Elasticsearch Service instance, you must delete the domain to avoid being billed for additional instance hours. Partial Amazon Elasticsearch Service instance hours consumed are billed as full hours.
Reserved Instance Pricing"
What is a Reserved Instance (RI)?,"Amazon Elasticsearch Service Reserved Instances give you the option to reserve an instance for a one- or three-year term, and in turn receive significant savings compared to the On-Demand Instance pricing."
How are Reserved Instances different from On-Demand Instances?,"Functionally, Reserved Instances and On-Demand Instances are exactly the same. The only difference is how your instance(s) are billed. With Reserved Instances, you purchase a one- or three-year reservation and receive a lower effective hourly usage rate (compared to On-Demand Instances) for the duration of the term. Unless you purchase Reserved Instances in a Region, all instances in that Region are billed at On-Demand Instance hourly rates."
What are the payment options for Reserved Instances?,"Three options are available:
No Upfront Reserved Instances (NURI) – NURIs offer significant savings compared to On-Demand Instance prices. You pay nothing upfront, but commit to paying for the Reserved Instance over the course of the one- or three-year term.
Partial Upfront Reserved Instances (PURI) – PURIs offer higher savings than NURIs. You pay for a portion of the total cost upfront, and the remainder over the course of the term. This option balances payments between upfront and hourly.
All Upfront Reserved Instances (AURI) – AURIs offer the highest savings of all of the Reserved Instance payment options. You pay for the entire reservation with one upfront payment, and pay nothing on an hourly basis."
How do I purchase Reserved Instances?,"You purchase Reserved Instances in the ""Reserved Instance"" section of the AWS Management Console for Amazon Elasticsearch Service. Alternatively, you can use the Amazon Elasticsearch Service API or AWS Command Line Interface to list and purchase Reserved Instances.
Once you purchase a Reserved Instance, you can use it just like an On-Demand Instance. As long as the purchased reservation is active, Amazon Elasticsearch Service applies the reduced hourly rate to it."
Are Reserved Instances specific to an Availability Zone?,"Amazon Elasticsearch Service Reserved Instances are purchased for a Region rather than for a specific Availability Zone. After you purchase a Reserved Instance for a Region, the discount applies to matching usage in any Availability Zone within that Region."
How many Reserved Instances can I purchase?,"You can procure up to 100 Reserved Instances in a single purchase. If you need more Reserved Instances, you need to place more purchase requests."
Do Reserved Instances include a capacity reservation?,"Amazon Elasticsearch Service Reserved Instances are purchased for a Region rather than for a specific Availability Zone. Hence, they are not capacity reservations. Even if capacity is limited in one Availability Zone, Reserved Instances can still be purchased in the Region. The discount applies to matching usage in any Availability Zone within that Region."
What if I have an existing On-Demand Instance that I’d like to convert to a Reserved Instance?,"Simply purchase a Reserved Instance of the same type as the existing On-Demand Instance. If the Reserved Instance purchase succeeds, Amazon Elasticsearch Service automatically applies the new hourly usage charge for the duration of your reservation."
"If I sign up for a Reserved Instance, when does the term begin? What happens to my Reserved Instance when the term ends?","Pricing changes and the reservation term associated with your Reserved Instance become active after your request is received and the payment authorization is processed. If the one-time payment (if applicable) or new hourly rate (if applicable) cannot be successfully authorized by the next billing period, the discounted price does not take effect and your term does not begin. You can follow the status of your reservation using the console, API, or CLI. For more details, refer our 
documentation
.
When your Reserved Instance term expires, your Reserved Instance reverts to the appropriate On-Demand Instance hourly usage rate for your instance class and Region."
How do I control which instances are billed at the Reserved Instance rate?,"When computing your bill, our system automatically applies your reservation(s) such that all eligible instances are charged at the lower hourly Reserved Instance rate. Amazon Elasticsearch Service does not distinguish between On-Demand and Reserved Instances while operating Elasticsearch Service domains."
"If I scale my Reserved Instance up or down, what happens to my reservation?","Each Reserved Instance is associated with the instance type and Region that you picked for it. If you change the instance type in the Region where you have the Reserved Instance, you will not receive discounted pricing. You must ensure that your reservation matches the instance type you plan to use. For more details, please refer to 
Amazon Elasticsearch Service Reserved Instance Documentation
."
Can I move a Reserved Instance from one Region or Availability Zone to another?,"Each Reserved Instance is associated with a specific Region, which is fixed for the lifetime of the reservation and cannot be changed. Each Reserved Instance can, however, be used in any of the Availability Zones within the associated Region."
"Are Reserved Instances applicable if I turn on zone awareness, which involves multi-Availability Zone deployments?",A Reserved Instance is for a Region and can be used in any of the Availability Zones in that Region.
Are Reserved Instances available for both Master nodes and Data nodes?,Yes. Amazon Elasticsearch Service does not differentiate between Master and Data nodes when applying Reserved Instance discounts.
Can I cancel a Reserved Instance?,"No, you cannot cancel your Reserved Instances, and the one-time payment (if applicable) and discounted hourly usage rate (if applicable) are not refundable. Also, you cannot transfer the Reserved Instance to another account. You must pay for every hour during your Reserved Instance’s term, regardless of your usage."
"If I purchase a Reserved Instance from a payer (master) account, is it accessible to all the member accounts?","Yes. Reserved Instance pricing and application follows the policies defined for consolidated billing on AWS. More details can be found 
here
."
"If AWS reduces prices of On-Demand Instances for Amazon Elasticsearch Service, will the amount I pay for my current Reserved Instances change?",No. The price you pay for already-purchased Reserved Instances does not change for the term of the reservation.
Can I sell my Reserved Instances on the Reserved Instance Marketplace?,No. Reserved Instances purchased on Amazon Elasticsearch Service cannot be sold on the Reserved Instance Marketplace.
,"What is a Domain Name System (DNS) Service?
DNS
 is a globally distributed service that translates human readable names like 
www.example.com 
into the numeric IP addresses like 
192.0.2.1
 that computers use to connect to each other. The Internet’s DNS system works much like a phone book by managing the mapping between names and numbers. For DNS, the names are domain names 
(www.example.com)
 that are easy for people to remember and the numbers are IP addresses 
(192.0.2.1)
 that specify the location of computers on the Internet. DNS servers translate requests for names into IP addresses, controlling which server an end user will reach when they type a domain name into their web browser. These requests are called ""queries."""
What is Amazon Route 53?,"Amazon Route 53 provides highly available and scalable Domain Name System (DNS), domain name registration, and health-checking web services. It is designed to give developers and businesses an extremely reliable and cost effective way to route end users to Internet applications by translating names like 
example.com
 into the numeric IP addresses, such as 
192.0.2.1
, that computers use to connect to each other. You can combine your DNS with health-checking services to route traffic to healthy endpoints or to independently monitor and/or alarm on endpoints. You can also purchase and manage domain names such as 
example.com 
and automatically configure DNS settings for your domains. Route 53 effectively connects user requests to infrastructure running in AWS – such as Amazon EC2 instances, Elastic Load Balancing load balancers, or Amazon S3 buckets – and can also be used to route users to infrastructure outside of AWS."
What can I do with Amazon Route 53?,"With Amazon Route 53, you can create and manage your public DNS records. Like a phone book, Route 53 lets you manage the IP addresses listed for your domain names in the Internet’s DNS phone book. Route 53 also answers requests to translate specific domain names like into their corresponding IP addresses like 
192.0.2.1
. You can use Route 53 to create DNS records for a new domain or transfer DNS records for an existing domain. The simple, standards-based REST API for Route 53 allows you to easily create, update and manage DNS records. Route 53 additionally offers health checks to monitor the health and performance of your application as well as your web servers and other resources. You can also register new domain names or transfer 
           

             in 
           
 existing domain names to be managed by Route 53."
How do I get started with Amazon Route 53? ,"Amazon Route 53 has a simple web service interface that lets you get started in minutes. Your DNS records are organized into “hosted zones” that you configure with the AWS Management Console or Route 53’s API. To use Route 53, you simply:
Subscribe to the service by clicking on the sign-up button on the 
service page
.
If you already have a domain name: 
            
Use the AWS Management Console or the 
CreateHostedZone
 API to create a hosted zone that can store DNS records for your domain. Upon creating the hosted zone, you receive four Route 53 name servers across four different Top-Level Domains (TLDs) to help ensure a high level of availability.
Additionally, you can transfer your domain name to Route 53’s management via either the AWS Management Console or the API.
If you don't already have a domain name: 
            
Use the AWS Management Console or the API to register your new domain name.
Route 53 automatically creates a hosted zone that stores DNS records for your domain. You also receive four Route 53 name servers across four different Top-Level Domains (TLDs) to help ensure a high level of availability.
Your hosted zone will be initially populated with a basic set of DNS records, including four virtual name servers that will answer queries for your domain. You can add, delete or change records in this set by using the AWS Management Console or by calling the 
ChangeResourceRecordSet

              API . 
            
 A list of supported DNS records is available 
here
.
If your domain name is not managed by Route 53, you will need to inform the registrar with whom you registered your domain name to update the name servers for your domain to the ones associated with your hosted zone. If your domain name is managed by Route 53 already, your domain name will be automatically associated with the name servers hosting your zone."
How does Amazon Route 53 provide high availability and low latency?,"Route 53 is built using AWS’s highly available and reliable infrastructure. The globally distributed nature of our DNS servers helps ensure a consistent ability to route your end users to your application by circumventing any internet or network related issues. Route 53 is designed to provide the level of dependability required by important applications. Using a global anycast network of DNS servers around the world, Route 53 is designed to automatically answer queries from the optimal location depending on network conditions. As a result, the service offers low query latency for your end users."
What are the DNS server names for the Amazon Route 53 service?,"To provide you with a highly available service, each Amazon Route 53 hosted zone is served by its own set of virtual DNS servers. The DNS server names for each hosted zone are thus assigned by the system when that hosted zone is created."
What is the difference between a Domain and a Hosted Zone?,"A domain is a general DNS concept. Domain names are easily recognizable names for numerically addressed Internet resources. For example, 
amazon.com 
is a domain. A hosted zone is an Amazon Route 53 concept. A hosted zone is analogous to a traditional DNS zone file; it represents a collection of records that can be managed together, belonging to a single parent domain name. All resource record sets within a hosted zone must have the hosted zone’s domain name as a suffix. For example, the 
amazon.com 
hosted zone may contain records named 
www.amazon.com
, and 
www.aws.amazon.com
, but not a record named 
www.amazon.ca
. You can use the Route 53 Management Console or API to create, inspect, modify, and delete hosted zones. You can also use the Management Console or API to register new domain names and transfer existing domain names into Route 53’s management."
What is the price of Amazon Route 53?,
"Amazon Route 53 charges are based on actual usage of the service for Hosted Zones, Queries, Health Checks, and Domain Names. For full details, see the ","Amazon Route 53 pricing page
.
You pay only for what you use. There are no minimum fees, no minimum usage commitments, and no overage charges. You can estimate your monthly bill using the 
AWS Simple Monthly Calculator
."
What types of access controls can I set for the management of my Domains on Amazon Route 53?,"You can control management access to your Amazon Route 53 hosted zone by using the AWS Identity and Access Management (IAM) service. AWS IAM allows you to control who in your organization can make changes to your DNS records by creating multiple users and managing the permissions for each of these users within your AWS Account. Learn more about AWS IAM 
here
."
"I have subscribed for Amazon Route 53 but when I try to use the service it says ""The AWS Access Key ID needs a subscription for the service""","When you sign up for a new AWS service, it can take up to 24 hours in some cases to complete activation, during which time you cannot sign up for the service again. If you've been waiting longer than 24 hours without receiving an email confirming activation, this could indicate a problem with your account or the authorization of your payment details. Please 
contact AWS Customer Service
 for help."
Does Amazon Route 53 offer a Service Level Agreement (SLA)?,"Yes. The Amazon Route 53 SLA provides for a service credit if a customer’s monthly uptime percentage is below our service commitment in any billing cycle. More information can be found 
here
."
When is my hosted zone charged?,Hosted zones are billed once when they are created and then on the first day of each month.
Why do I see two charges for the same hosted zone in the same month?,"Hosted zones have a grace period of 12 hours--if you delete a hosted zone within 12 hours after you create it, we don't charge you for the hosted zone. After the grace period ends, we immediately charge the standard monthly fee for a hosted zone. If you create a hosted zone on the last day of the month (for example, January 31st), the charge for January might appear on the February invoice, along with the charge for February."
Q. Does Amazon Route 53 provide query logging capability?,"You can configure Amazon Route 53 to log information about the queries that Amazon Route 53 receives including date-time stamp, domain name, query type, location etc. When you configure query logging, Amazon Route 53 starts to send logs to CloudWatch Logs. You use CloudWatch Logs tools to access the query logs; For more information please see our 
documentation
."
Does Amazon Route 53 use an anycast network?,"Yes. Anycast is a networking and routing technology that helps your end users’ DNS queries get answered from the optimal Route 53 location given network conditions. As a result, your users get high availability and improved performance with Route 53."
Is there a limit to the number of hosted zones I can manage using Amazon Route 53?,"Each Amazon Route 53 account is limited to a maximum of 500 hosted zones and 10,000 resource record sets per hosted zone. Complete our 
request for a higher limit
 and we will respond to your request within two business days."
How can I import a zone into Route 53?,"Route 53 supports importing standard DNS zone files which can be exported from many DNS providers as well as standard DNS server software such as BIND. For newly-created hosted zones, as well as existing hosted zones that are empty except for the default NS and SOA records, you can paste your zone file directly into the Route 53 console, and Route 53 automatically creates the records in your hosted zone. To get started with zone file import, read our walkthrough in the 
Amazon Route 53 Developer Guide
."
Can I create multiple hosted zones for the same domain name? ,"Yes. Creating multiple hosted zones allows you to verify your DNS setting in a “test” environment, and then replicate those settings on a “production” hosted zone. For example, hosted zone Z1234 might be your test version of 
example.com
, hosted on name servers ns-1, ns-2, ns-3, and ns-4. Similarly, hosted zone Z5678 might be your production version of 
example.com
, hosted on ns-5, ns-6, ns-7, and ns-8. Since each hosted zone has a virtual set of name servers associated with that zone, Route 53 will answer DNS queries for example.com differently depending on which name server you send the DNS query to."
Does Amazon Route 53 also provide website hosting? ,"No. Amazon Route 53 is an authoritative DNS service and does not provide 
website hosting
. However, you can use Amazon Simple Storage Service (Amazon S3) to host a static website. To host a dynamic website or other web applications, you can use Amazon Elastic Compute Cloud (Amazon EC2), which provides flexibility, control, and significant cost savings over traditional 
web hosting
 solutions. Learn more about Amazon EC2 
here
. For both static and dynamic websites, you can provide low latency delivery to your global end users with Amazon CloudFront. Learn more about Amazon CloudFront 
here
."
Which DNS record types does Amazon Route 53 support? ,"Amazon Route 53 currently supports the following DNS record types:
A (address record)
AAAA (IPv6 address record)
CNAME (canonical name record)
CAA (certification authority authorization)
MX (mail exchange record)
NAPTR (name authority pointer record)
NS (name server record)
PTR (pointer record)
SOA (start of authority record)
SPF (sender policy framework)
SRV (service locator)
TXT (text record)
Additionally, Amazon Route 53 offers ‘Alias’ records (an Amazon Route 53-specific virtual record). Alias records are used to map resource record sets in your hosted zone to Amazon Elastic Load Balancing load balancers, Amazon CloudFront distributions, AWS Elastic Beanstalk environments, or Amazon S3 buckets that are configured as websites. Alias records work like a CNAME record in that you can map one DNS name (example.com) to another ‘target’ DNS name (elb1234.elb.amazonaws.com). They differ from a CNAME record in that they are not visible to resolvers. Resolvers only see the A record and the resulting IP address of the target record.
We anticipate adding additional record types in the future."
"Does Amazon Route 53 support wildcard entries? If so, what record types support them?","Yes. To make it even easier for you to configure DNS settings for your domain, Amazon Route 53 supports wildcard entries for all record types, except NS records. A wildcard entry is a record in a DNS zone that will match requests for any domain name based on the configuration you set. For example, a wildcard DNS record such as 
*.example.com
 will match queries for 
www.example.com
 and 
subdomain.example.com
."
What is the default TTL for the various record types and can I change these values?,The time for which a DNS resolver caches a response is set by a value called the time to live (TTL) associated with every record. Amazon Route 53 does not have a default TTL for any record type. You must always specify a TTL for each record so that caching DNS resolvers can cache your DNS records to the length of time specified through the TTL.
Can I use 'Alias records with my sub-domains?,"Yes. You can also use Alias records to map your sub-domains (
www.example.com
, 
pictures.example.com
, etc.) to your ELB load balancers, CloudFront distributions, or S3 website buckets."
Are changes to resource record sets transactional?,"Yes. A transactional change helps ensure that the change is consistent, reliable, and independent of other changes. Amazon Route 53 has been designed so that changes complete entirely on any individual DNS server, or not at all. This helps ensure your DNS queries are always answered consistently, which is important when making changes such as flipping between destination servers. When using the API, each call to 
ChangeResourceRecordSets
 returns an identifier that can be used to track the status of the change. Once the status is reported as 
INSYNC
, your change has been performed on all of the Route 53 DNS servers."
Can I associate multiple IP addresses with a single record?,Yes. Associating multiple IP addresses with a single record is often used for balancing the load of geographically-distributed web servers. Amazon Route 53 allows you to list multiple IP addresses for an A record and responds to DNS requests with the list of all configured IP addresses.
How quickly will changes I make to my DNS settings on Amazon Route 53 propagate globally? ,"Amazon Route 53 is designed to propagate updates you make to your DNS records to its world-wide network of authoritative DNS servers within 60 seconds under normal conditions. A change is successfully propagated world-wide when the API call returns an 
INSYNC 
status listing.
Note that caching DNS resolvers are outside the control of the Amazon Route 53 service and will cache your resource record sets according to their time to live (TTL). The 
INSYNC 
or 
PENDING 
status of a change refers only to the state of Route 53’s authoritative DNS servers."
Can I see a history of my changes and other operations on my Route 53 resources?,"Yes, via AWS CloudTrail you can record and log the API call history for Route 53. Please reference the 
CloudTrail product page
 to get started."
Can I use AWS CloudTrail logs to roll back changes to my hosted zones? ,"No. We recommend that you do not use CloudTrail logs to roll back changes to your hosted zones, because reconstruction of your zone change history using your CloudTrail logs may be incomplete.
Your AWS CloudTrail logs can be used for the purposes of security analysis, resource change tracking, and compliance auditing."
Does Amazon Route 53 support DNSSEC?,Amazon Route 53 does not support DNSSEC for DNS at this time. But Amazon Route 53 allows DNSSEC on domain registration.
Does Amazon Route 53 support IPv6?,Yes. Amazon Route 53 supports both forward (AAAA) and reverse (PTR) IPv6 records. The Amazon Route 53 service itself is also available over IPv6. Recursive DNS resolvers on IPv6 networks can use either IPv4 or IPv6 transport in order to submit DNS queries to Amazon Route 53. Amazon Route 53 health checks also support monitoring of endpoints using the IPv6 protocol.
Can I point my zone apex (example.com versus www.example.com) at my Elastic Load Balancer?,"Yes. Amazon Route 53 offers a special type of record called an ‘Alias’ record that lets you map your zone apex (
example.com
) DNS name to your ELB DNS name (i.e. 
elb1234.elb.amazonaws.com"
"). IP addresses associated with Amazon Elastic Load Balancers can change at any time due to scaling up, scaling down, or software updates. Route 53 responds to each request for an Alias record with one or more IP addresses for the load balancer. Queries to Alias records that are mapped to ELB load balancers are free. These queries are listed as “Intra-AWS-DNS-Queries” on the Amazon Route 53 usage report.",
Can I point my zone apex (example.com versus www.example.com) at my website hosted on Amazon S3? ,"Yes. Amazon Route 53 offers a special type of record called an ‘Alias’ record that lets you map your zone apex (
example.com
) DNS name to your Amazon S3 website bucket (i.e. 
example.com.s3-website-us-west-2.amazonaws.com"
"). IP addresses associated with Amazon S3 website endpoints can change at any time due to scaling up, scaling down, or software updates. Route 53 responds to each request for an Alias record with one IP address for the bucket. Route 53 doesn't charge for queries to Alias records that are mapped to an S3 bucket that is configured as a website. These queries are listed as “Intra-AWS-DNS-Queries” on the Amazon Route 53 usage report.",
Can I point my zone apex (example.com versus www.example.com) at my Amazon CloudFront distribution? ,"Yes. Amazon Route 53 offers a special type of record called an ‘Alias’ record that lets you map your zone apex (
example.com
) DNS name to your Amazon CloudFront distribution (for example, 
d123.cloudfront.net"
"). IP addresses associated with Amazon CloudFront endpoints vary based on your end user’s location (in order to direct the end user to the nearest CloudFront edge location) and can change at any time due to scaling up, scaling down, or software updates. Route 53 responds to each request for an Alias record with the IP address(es) for the distribution. Route 53 doesn't charge for queries to Alias records that are mapped to a CloudFront distribution. These queries are listed as “Intra-AWS-DNS-Queries” on the Amazon Route 53 usage report.",
Can I point my zone apex (example.com versus www.example.com) at my AWS Elastic Beanstalk environment? ,"Yes. Amazon Route 53 offers a special type of record called an ‘Alias’ record that lets you map your zone apex (
example.com
) DNS name to your AWS Elastic Beanstalk DNS name (i.e. 
example.elasticbeanstalk.com"
"). IP addresses associated with AWS Elastic Beanstalk environments can change at any time due to scaling up, scaling down, or software updates. Route 53 responds to each request for an Alias record with one or more IP addresses for the environment. Queries to Alias records that are mapped to AWS Elastic Beanstalk environments are free. These queries are listed as “Intra-AWS-DNS-Queries” on the Amazon Route 53 usage report.",
How can I use Amazon Route 53 with Amazon Simple Storage Service (Amazon S3) and Amazon CloudFront? ,"For websites delivered via Amazon CloudFront or static websites hosted on Amazon S3, you can use the Amazon Route 53 service to create an Alias record for your domain which points to the CloudFront distribution or S3 website bucket. For S3 buckets not configured to host static websites, you can create a CNAME record for your domain and the S3 bucket name. In all cases, note that you will also need to configure your S3 bucket or your CloudFront distribution respectively with the alternate domain name entry to completely establish the alias between your domain name and the AWS domain name for your bucket or distribution.
For CloudFront distributions and S3 buckets configured to host static websites, we recommend creating an ‘Alias’ record that maps to your CloudFront distribution or S3 website bucket, instead of using CNAMEs. Alias records have two advantages: first, unlike CNAMEs, you can create an Alias record for your zone apex (e.g. example.com, instead of www.example.com), and second, queries to Alias records are free of charge."
Q. Why does the DNS Query Test Tool return a response different than the dig or nslookup commands?,"When resource record sets are changed in Amazon Route 53, the service propagates updates you make to your DNS records to its world-wide network of authoritative DNS servers. If you test the record before propagation is complete, you may see an old value when you use the dig or nslookup utilities. Additionally, DNS resolvers on the internet are outside the control of the Amazon Route 53 service and will cache your resource record sets according to their time to live (TTL), which means a dig/nslookup command might return a cached value. You should also make sure that your domain name registrar is using the name servers in your Amazon Route 53 hosted zone. If not, Amazon Route 53 will not be authoritative for queries to your domain."
Does Amazon Route 53 support Weighted Round Robin (WRR)?,"Yes. Weighted Round Robin allows you to assign weights to resource record sets in order to specify the frequency with which different responses are served. You may want to use this capability to do A/B testing, sending a small portion of traffic to a server on which you’ve made a software change. For instance, suppose you have two 
           

             record sets 
           
 associated with one DNS name—one with weight 3 and one with weight 1. In this case, 75% of the time Route 53 will return the record set with weight 3 and 25% of the time Route 53 will return the record set with weight 1. Weights can be any number between 0 and 255."
What is Amazon Route 53's Latency Based Routing (LBR) feature?,"LBR (Latency Based Routing) is a new feature for Amazon Route 53 that helps you improve your application’s performance for a global audience. You can run applications in multiple AWS regions and Amazon Route 53, using dozens of edge locations worldwide, will route end users to the AWS region that provides the lowest latency."
How do I get started using Amazon Route 53's Latency Based Routing (LBR) feature?,"You can start using Amazon Route 53’s new LBR feature quickly and easily by using either the AWS Management Console or a simple API. You simply create a record set that includes the IP addresses or ELB names of various AWS endpoints and mark that record set as an LBR-enabled Record Set, much like you mark a record set as a Weighted Record Set. Amazon Route 53 takes care of the rest - determining the best endpoint for each request and routing end users accordingly, much like Amazon CloudFront, Amazon’s global content delivery service, does. You can learn more about how to use Latency Based Routing in the 
Amazon Route 53 Developer Guide
."
What is the price for Amazon Route 53's Latency Based Routing (LBR) feature?,"Like all AWS services, there are no upfront fees or 
           

             long term 
           
 commitments to use Amazon Route 53 and LBR. Customers simply pay for the hosted zones and queries they actually use. Please visit the 
Amazon Route 53 pricing page
 for details on pricing for Latency Based Routing queries."
What is Amazon Route 53's Geo DNS feature?,"Route 53 Geo DNS lets you balance load by directing requests to specific endpoints based on the geographic location from which the request originates. Geo DNS makes it possible to customize localized content, such as presenting detail pages in the right language or restricting distribution of content to only the markets you have licensed. Geo DNS also lets you balance load across endpoints in a predictable, easy-to-manage way, ensuring that each end-user location is consistently routed to the same endpoint. Geo DNS provides three levels of geographic granularity: continent, country, and state, and Geo DNS also provides a global record which is served in cases where an end user’s location doesn’t match any of the specific Geo DNS records you have created. You can also combine Geo DNS with other routing types, such as Latency Based Routing and DNS Failover, to enable a variety of low-latency and fault-tolerant architectures. For information on how to configure various routing types, please see the 
Amazon Route 53 documentation
."
How do I get started using Amazon Route 53's Geo DNS feature?,"You can start using Amazon Route 53’s Geo DNS feature quickly and easily by using either the AWS Management Console or the Route 53 API. You simply create a 
           

             record set 
           
 and specify the applicable values for that type of record set, mark that record set as a Geo DNS-enabled Record Set, and select the geographic region (global, continent, country, or state) that you want the record to apply to. You can learn more about how to use Geo DNS in the 
Amazon Route 53 Developer Guide
."
"When using Geo DNS, do I need a ""global"" record? When would Route 53 return this record?","Yes, we strongly recommend that you configure a global record, to ensure that Route 53 can provide a response to DNS queries from all possible locations—even if you have created specific records for each continent, country, or state where you expect your end users will be located. Route 53 will return the value contained in your global record in the following cases:
The DNS query comes from an IP address not recognized by Route 53’s Geo IP database.
The DNS query comes from a location not included in any of the specific Geo DNS records you have created."
Can I have a Geo DNS record for a continent and different Geo DNS records for countries within that continent? Or a Geo DNS record for a country and Geo DNS records for states within that country?,"Yes, you can have Geo DNS records for overlapping geographic regions (e.g., a continent and countries within that continent, or a country and states within that country). For each end user’s location, Route 53 will return the most specific Geo DNS record that includes that location. In other words, for a given end user’s location, Route 53 will first return a state record; if no state record is found, Route 53 will return a country record; if no country record is found, Route 53 will return a continent record; and finally, if no continent record is found, Route 53 will return the global record."
What is the price for Route 53's Geo DNS feature?,"Like all AWS services, there are no upfront fees or 
           

             long term 
           
 commitments to use Amazon Route 53 and Geo DNS. Customers simply pay for the hosted zones and queries they actually use. Please visit the 
Amazon Route 53 pricing page
 for details on pricing for Geo DNS queries."
What is the difference between Latency Based Routing and Geo DNS? ,"Geo DNS bases routing decisions on the geographic location of the requests. In some cases, geography is a good proxy for latency; but there are certainly situations where it is not. LatencyBased Routing utilizes latency measurements between viewer networks and AWS datacenters. These measurements are used to determine which endpoint to direct users toward.
If your goal is to minimize end-user latency, we recommend using Latency Based Routing. If you have compliance, localization requirements, or other use cases that require stable routing from a specific geography to a specific endpoint, we recommend using Geo DNS."
Does Amazon Route 53 support multiple values in response to DNS queries?,"Route 53 now supports multivalue answers in response to DNS queries. While not a substitute for a load balancer, the ability to return multiple health-checkable IP addresses in response to DNS queries is a way to use DNS to improve availability and load balancing. If you want to route traffic randomly to multiple resources, such as web servers, you can create one multivalue answer record for each resource and, optionally, associate an Amazon Route 53 health check with each record. Amazon Route 53 supports up to eight healthy records in response to each DNS query."
What is Amazon Route 53 Traffic Flow?,"Amazon Route 53 Traffic Flow is an easy-to-use and cost-effective global traffic management service. With Amazon Route 53 Traffic Flow, you can improve the performance and availability of your application for your end users by running multiple endpoints around the world, using Amazon Route 53 Traffic Flow to connect your users to the best endpoint based on latency, geography, and endpoint health. Amazon Route 53 Traffic Flow makes it easy for developers to create policies that route traffic based on the constraints they care most about, including latency, endpoint health, load, 
           

              geoproximity 
            
 and geography. Customers can customize these templates or build policies from scratch using a simple visual policy builder in the AWS Management Console."
What is the difference between a traffic policy and a policy record?,"A
 traffic policy
 is the set of rules that you define to route end users’ requests to one of your application’s endpoints. You can create a traffic policy using the visual policy builder in the Amazon Route 53 Traffic Flow section of the Amazon Route 53 console. You can also create traffic policies as JSON-formatted text files and upload these policies using the Route 53 API, the AWS CLI, or the various AWS SDKs.
By itself, a traffic policy doesn’t affect how end users are routed to your application because it isn’t yet associated with your application’s DNS name (such as 
www.example.com
). To start using Amazon Route 53 Traffic Flow to route traffic to your application using the traffic policy you’ve created, you create a 
policy record
 which associates the traffic policy with the appropriate DNS name within an Amazon Route 53 hosted zone that you own. For example, if you want to use a traffic policy that you’ve named 
my-first-traffic-policy
 to manage traffic for your application at 
www.example.com
, you will create a policy record for
 www.example.com
 within your hosted zone 
example.com
 and choose 
my-first-traffic-policy
 as the traffic policy.
Policy records are visible in both the Amazon Route 53 Traffic Flow and Amazon Route 53 Hosted Zone sections of the Amazon Route 53 console."
"Can I use the same policy to manage 
            ","routing 
            
 for more than one DNS name?
Yes. You can reuse a policy to manage more than one DNS name in one of two ways. First, you can create additional policy records using the policy. Note that there is an additional charge for using this 
           

             method, 
           
 because you are billed for each policy record that you create.
The second method is to create one policy record using the policy, and then for each additional DNS name that you want to manage using the policy, you create a standard CNAME record pointing at the DNS name of the policy record that you created. For example, if you create a policy record for 
example.com
, you can then create DNS records for 
www.example.com
, 
blog.example.com
, and 
www.example.net
 with a CNAME value of 
example.com
 for each record. Note that this method is not possible for records at the zone apex, such as 
example.net
, 
example.org
, or 
example.co.uk
 (without www or another subdomain in front of the domain name). For records at the zone apex, you must create a policy record using your traffic policy."
Can I create an Alias record pointing to a DNS name that is managed by a traffic policy?,"No, it is not possible to create an Alias record pointing to a DNS name that is being managed by a traffic policy."
Is there a charge for traffic policies that don’t have a policy record?,No. We only charge for policy records; there is no charge for creating the traffic policy itself.
How am I billed for using Amazon Route 53 Traffic Flow?,"You are billed per policy record. A policy record represents the application of a Traffic Flow policy to a specific DNS name (such as 
www.example.com
)
in order to use the traffic policy to manage how requests for that DNS name are answered. Billing is monthly and is prorated for partial months. There is no charge for traffic policies that are not associated with a DNS name via a policy record. For details on pricing, see the 
Amazon Route 53 pricing page
."
What are the advanced query types supported in Amazon Route 53 Traffic Flow?,"Traffic Flow supports all Amazon Route 53 DNS Routing policies including latency, endpoint health, 
           

             multivalue 
           
 answers, weighted round robin, and 
           

             geo 
           
. In addition to these, Traffic Flow also supports 
           

             geoproximity 
           
 based routing with traffic biasing."
"How does a traffic policy using 
            ","geoproximity 
            
 rule route DNS traffic? 
When you create a traffic flow policy, you can specify either an AWS region (if you're using AWS resources) or the latitude and longitude for each endpoint. For example, suppose you have EC2 instances in the AWS US East (Ohio) region and in the US West (Oregon) region. When 
           

             an user 
           
 in Seattle visits your website, 
           

             geoproximity 
           
 routing will route the DNS query to the EC2 instances in the US West (Oregon) region because it's closer geographically. For more information please see the documentation on 

              geoproximity 
            
 routing
."
"Q. How does 
            ","geoproximity 
            
 bias of an endpoint 
            

              affect 
            
 DNS 
            
 traffic routing to other endpoints?
Changing 
           

             geoproximity 
           
 bias value on an endpoint either increases or decreases the value of the calculated distance relative to the other endpoints. However, the bias does not accurately predict the load factor but rather changes the sphere of influence. The amount of traffic shifting depends on how much queries are generated within the geographical sphere of influence of an endpoint. For more information please refer to our 
documentation
."
Can I use bias for other Traffic Flow rules?,"As of today, bias can only be applied to 
           

             geoproximity 
           
 rules."
What is Private DNS?,Private DNS is a Route 53 feature that lets you have authoritative DNS within your VPCs without exposing your DNS records (including the name of the resource and its IP address(es) to the Internet.
Can I use Amazon Route 53 to manage my organization’s private IP addresses?,"Yes, you can manage private IP addresses within Virtual Private Clouds (VPCs) using Amazon Route 53’s Private DNS feature. With Private DNS, you can create a private hosted zone, and Route 53 will only return these records when queried from within the VPC(s) that you have associated with your private hosted zone. For more details, see the 
Amazon Route 53 Documentation
."
How do I set up Private DNS?,"You can set up Private DNS by creating a hosted zone in Route 53, selecting the option to make the hosted zone “private”, and associating the hosted zone with one of your VPCs. After creating the hosted zone, you can associate it with additional VPCs. See the 
Amazon Route 53 Documentation
 for full details on how to configure Private DNS."
Do I need connectivity to the outside Internet in order to use Private DNS?,"You can resolve internal DNS names from resources within your VPC that do not have Internet connectivity. However, to update the configuration for your Private DNS hosted zone, you need Internet connectivity to access the Route 53 API endpoint, which is outside of VPC."
Can I still use Private DNS if I’m not using VPC?,"No. Route 53 Private DNS uses VPC to manage visibility and provide DNS resolution for private DNS hosted zones. To take advantage of Route 53 Private DNS, you must configure a VPC and migrate your resources into it."
Can I use the same private Route 53 hosted zone for multiple VPCs?,"Yes, you can associate multiple VPCs with a single hosted zone."
Q.,"Can I associate VPCs and private hosted zones that I created under different AWS accounts?
Yes, you can associate VPCs belonging to different accounts with a single hosted zone. You can see more details 
here
."
Will Private DNS work across AWS regions?,"Yes. DNS answers will be available within every VPC that you associate with the private hosted zone. Note that you will need to ensure that the VPCs in each region have connectivity with each other in order for resources in one region to be able to reach resources in another region. Route 53 Private DNS is supported today in the US East (Northern Virginia), US West (Northern California), US West (Oregon), Asia Pacific (Mumbai), Asia Pacific (Seoul), Asia Pacific (Singapore), Asia Pacific (Sydney), Asia Pacific (Tokyo), EU (Frankfurt), EU (Ireland), and South America (Sao Paulo) regions."
Can I configure DNS Failover for Private DNS hosted zones?,"Yes, it is possible to configure DNS Failover by associating health checks with resource record sets within a Private DNS hosted zone. If your endpoints are within a Virtual Private Cloud (VPC), you have several options to configure health checks against these endpoints. If the endpoints have public IP addresses, then you can create a standard health check against the public IP address of each endpoint. If your endpoints only have private IP addresses, then you cannot create standard health checks against these endpoints. However, you can create metric based health checks, which function like standard Amazon Route 53 health checks except that they use an existing Amazon CloudWatch metric as the source of endpoint health information instead of making requests against the endpoint from external locations."
Can I use Private DNS to block domains and DNS names that I don’t want to be reached from within my VPC?,"Yes, you can block domains and specific DNS names by creating these names in one or more Private DNS hosted zones and pointing these names to your own server (or another location that you manage)."
What is DNS Failover?,"DNS Failover consists of two components: health checks and failover. Health checks are automated requests sent over the Internet to your application to verify that your application is reachable, available, and functional. You can configure the health checks to be similar to the typical requests made by your users, such as requesting a web page from a specific URL. With DNS failover, Route 53 only returns answers for resources that are healthy and reachable from the outside world, so that your end users are routed away from a failed or unhealthy part of your application."
How do I get started with DNS Failover?,"Visit the 
Amazon Route 53 Developer Guide
 for details on getting started. You can also configure DNS Failover from within the Route 53 Console."
Does DNS Failover support Elastic Load Balancers (ELBs) as endpoints?,"Yes, you can configure DNS Failover for Elastic Load Balancers (ELBs). To enable DNS Failover for an ELB endpoint, create an Alias record pointing to the ELB and set the “Evaluate Target Health” parameter to true. Route 53 creates and manages the health checks for your ELB automatically. You do not need to create your own Route 53 health check of the ELB. You also do not need to associate your resource record set for the ELB with your own health check, because Route 53 automatically associates it with the health checks that Route 53 manages on your behalf. The ELB health check will also inherit the health of your backend instances behind that ELB. For more details on using DNS Failover with ELB endpoints, please consult the 
Route 53 Developer Guide
."
Can I configure a backup site to be used only when a health check fails?,"Yes, you can use DNS Failover to maintain a backup site (for example, a static site running on an Amazon S3 website bucket) and fail over to this site in the event that your primary site becomes unreachable."
What DNS record types can I associate with Route 53 health checks?,You can associate any record type supported by Route 53 except SOA and NS records.
Can I health check an endpoint if I don’t know its IP address?,"Yes. You can configure DNS Failover for Elastic Load Balancers and Amazon S3 website buckets via the Amazon Route 53 Console without needing to create a health check of your own. For these endpoint types, Route 53 automatically creates and manages health checks on your behalf which are used when you create an Alias record pointing to the ELB or S3 website bucket and enable the ""Evaluate Target Health"" parameter on the Alias record.
For all other endpoints, you can specify either the DNS name (e.g. www.example.com) or the IP address of the endpoint when you create a health check for that endpoint."
One of my endpoints is outside AWS. Can I set up DNS Failover on this endpoint?,"Yes. Just like you can create a Route 53 resource record that points to an address outside AWS, you can set up health checks for parts of your application running outside AWS, and you can fail over to any endpoint that you choose, regardless of location. For example, you may have a legacy application running in a datacenter outside AWS and a backup instance of that application running within AWS. You can set up health checks of your legacy application running outside AWS, and if the application fails the health checks, you can fail over automatically to the backup instance in AWS."
"If failover occurs and I have multiple healthy endpoints remaining, will Route 53 consider the load on my healthy endpoints when determining where to send traffic from the failed endpoint?","No, Route 53 does not make routing decisions based on the load or available traffic capacity of your endpoints. You will need to ensure that you have available capacity at your other endpoints, or the ability to scale at those endpoints, in order to handle the traffic that had been flowing to your failed endpoint."
How many consecutive health check observations does an endpoint need to fail to be considered “failed”?,"The default is a threshold of three health check observations: when an endpoint has failed three consecutive observations, Route 53 will consider it failed. However, Route 53 will continue to perform health check observations on the endpoint and will resume sending traffic to it once it passes three consecutive observations. You can change this threshold to any value between 1 and 10 observations. For more details, 
see the Amazon Route 53 Developer Guide
."
"When my failed endpoint becomes healthy again, how is the DNS failover reversed?","After a failed endpoint passes the number of consecutive health check observations that you specify when creating the health check (the default threshold is three observations), Route 53 will restore its DNS records automatically, and traffic to that endpoint will resume with no action required on your part."
What is the interval between health check observations?,"By default, health check observations are conducted at an interval of 30 seconds. You can optionally select a fast interval of 10 seconds between observations.
By checking three times more often, fast interval health checks enable Route 53 to confirm more quickly that an endpoint has failed, shortening the time required for DNS failover to redirect traffic in response to the endpoint’s failure.
Fast interval health checks also generate three times the number of requests to your endpoint, which may be a consideration if your endpoint has a limited capacity to serve web traffic. Visit the 
Route 53 pricing page
 for details on pricing for fast interval health checks and other optional health check features. For more details, see the 
Amazon Route 53 Developer Guide
."
"How much load should I expect a health check to generate on my endpoint (for example, a web server)?","Each health check is conducted from multiple locations around the world. The number and set of locations is configurable; you can modify the number of locations from which each of your health checks is conducted using the Amazon Route 53 console or API. Each location checks the endpoint independently at the interval that you select: the default interval of 30 seconds, or an optional fast interval of 10 seconds. Based on the current default number of health checking locations, you should expect your endpoint to receive one request every 2-3 seconds on average for standard interval health checks and one or more requests per second for fast-interval health checks."
Do Route 53 health checks follow HTTP redirects?,"No. Route 53 health checks consider an HTTP 3xx code to be a successful response, so they don’t follow the redirect. This may cause unexpected results for string-matching health checks. The health check searches for the specified string in the body of the redirect. Because the health check doesn’t follow the redirect, it never sends a request to the location that the redirect points to and never gets a response from that location. For string matching health checks, we recommend that you avoid pointing the health check at a location that returns an HTTP redirect."
What is the sequence of events when failover happens?,"In simplest terms, the following events will take place if a health check fails and failover occurs:
Route 53 conducts a health check of your application. In this example, your application fails three consecutive health checks, triggering the following events.
Route 53 disables the resource records for the failed endpoint and no longer serves these records. This is the failover step, which causes traffic to begin being routed to your healthy endpoint(s) instead of your failed endpoint."
Do I need to adjust the TTL for my records in order to use DNS Failover?,"The time for which a DNS resolver caches a response is set by a value called the time to live (TTL) associated with every record. We recommend a TTL of 60 seconds or less when using DNS Failover, to minimize the amount of time it takes for traffic to stop being routed to your failed endpoint. In order to configure DNS Failover for ELB and S3 Website endpoints, you need to use Alias records which have fixed TTL of 60 seconds; for these endpoint types, you do not need to adjust TTLs in order to use DNS Failover."
What happens if all of my endpoints are unhealthy?,"Route 53 can only fail over to an endpoint that is healthy. If there are no healthy endpoints remaining in a resource record set, Route 53 will behave as if all health checks are passing."
Can I use DNS Failover without using Latency Based Routing (LBR)?,"Yes. You can configure DNS Failover without using LBR. In particular, you can use DNS failover to configure a simple failover scenario where Route 53 monitors your primary website and fails over to a backup site in the event that your primary site is unavailable."
Can I configure a health check on a site accessible only via HTTPS?,"Yes. Route 53 supports health checks over HTTPS, HTTP or TCP."
Do HTTPS health checks validate the endpoint’s SSL certificate?,"No, HTTPS health checks test whether it’s possible to connect with the endpoint over SSL and whether the endpoint returns a valid HTTP response code. However, they do not validate the SSL certificate returned by the endpoint."
Do HTTPS health checks support Server Name Indication (SNI)?,"Yes, HTTPS health checks support SNI."
How can I use health checks to verify that my web server is returning the correct content?,"You can use Route 53 health checks to check for the presence of a designated string in a server response by selecting the “Enable String Matching” option. This option can be used to check a web server to verify that the HTML it serves contains an expected string. Or, you can create a dedicated status page and use it to check the health of the server from an internal or operational perspective. For more details, see the 
Amazon Route 53 Developer Guide
."
How do I see the status of a health check that I’ve created?,"You can view the current status of a health check, as well as details on why it has failed, in the Amazon Route 53 console and via the Route 53 API.
Additionally, each health check’s results are published as Amazon CloudWatch metrics showing the endpoint’s health and, optionally, the latency of the endpoint’s response. You can view a graph of the Amazon CloudWatch metric in the health checks tab of the Amazon Route 53 console to see the current and historical status of the health check. You can also create Amazon CloudWatch alarms on the metric in order to send notifications if the status of the health check changes.
The Amazon CloudWatch metrics for all of your Amazon Route 53 health checks are also visible in the Amazon CloudWatch console. Each Amazon CloudWatch metric contains the Health Check ID (for example, 01beb6a3-e1c2-4a2b-a0b7-7031e9060a6a) which you can use to identify which health check the metric is tracking."
How can I measure the performance of my application’s endpoints using Amazon Route 53?,"Amazon Route 53 health checks include an optional latency measurement feature which provides data on how long it takes your endpoint to respond to a request. When you enable the latency measurement feature, the Amazon Route 53 health check will generate additional Amazon CloudWatch metrics showing the time required for Amazon Route 53’s health checkers to establish a connection and to begin receiving data. Amazon Route 53 provides a separate set of latency metrics for each AWS region where Amazon Route 53 health checks are conducted."
How can I be notified if one of my endpoints starts failing its health check?,"Because each Route 53 health check publishes its results as a CloudWatch metric, you can configure the full range of CloudWatch notifications and automated actions which can be triggered when the health check value changes beyond a threshold that you specify. First, in either the Route 53 or CloudWatch console, configure a CloudWatch alarm on the health check metric. Then add a notification action and specify the email or SNS topic that you want to publish your notification to. Please consult the 
Route 53 Developer Guide
 for full details."
"I created an alarm for my health check, but I need to re-send the confirmation email for the alarm's SNS topic. How can I re-send this email?","Confirmation emails can be re-sent from the SNS console. To find the name of the SNS topic associated with the alarm, click the alarm name within the Route 53 console and looking in the box labeled ""Send notification to.""
Within the SNS console, expand the list of topics, and select the topic from your alarm. Open the ""Create Subscription"" box and select Email for protocol and enter the desired email address. Clicking ""Subscribe"" will re-send the confirmation email."
I’m using DNS Failover with Elastic Load Balancers (ELBs) as endpoints. How can I see the status of these endpoints?,"The recommended method for setting up DNS Failover with ELB endpoints is to use Alias records with the ""Evaluate Target Health"" option. Because you don't create your own health checks for ELB endpoints when using this option, there are no specific CloudWatch metrics generated by Route 53 for these endpoints.
You can get metrics on the health of your load balancer in two ways. First, Elastic Load Balancing publishes metrics that indicate the health of the load balancer and the number of healthy instances behind it. For details on configuring CloudWatch metrics for ELB, consult the 
ELB developer guide
. Second, you can create your own health check against the CNAME provided by the ELB, e.g. elb-example-123456678.us-west-2.elb.amazonaws.com. You won’t use this health check for DNS Failover itself (because the “Evaluate Target Health” option provides DNS Failover for you), but you can view the CloudWatch metrics for this health check and create alarms to be notified if the health check fails.
For complete details on using DNS Failover with ELB endpoints, please consult the 
Route 53 Developer Guide
."
"For Alias records pointing to Amazon S3 Website buckets, what is being health checked when I set Evaluate Target Health to “true”?","Amazon Route 53 performs health checks of the Amazon S3 service itself in each AWS region. When you enable Evaluate Target Health on an Alias record pointing to an Amazon S3 Website bucket, Amazon Route 53 will take into account the health of the Amazon S3 service in the AWS region where your bucket is located. Amazon Route 53 does not check whether a specific bucket exists or contains valid website content; Amazon Route 53 will only fail over to another location if the Amazon S3 service itself is unavailable in the AWS region where your bucket is located."
What is the cost to use CloudWatch metrics for my Route 53 health checks?,CloudWatch metrics for Route 53 health checks are available free of charge.
"Can I configure DNS Failover based on internal health metrics, such as CPU load, network, or memory?","Yes. Amazon Route 53’s metric based health checks let you perform DNS failover based on any metric that is available within Amazon CloudWatch, including AWS-provided metrics and custom metrics from your own application. When you create a metric based health check within Amazon Route 53, the health check becomes unhealthy whenever its associated Amazon CloudWatch metric enters an alarm state.
Metric based health checks are useful to enable DNS failover for endpoints that cannot be reached by a standard Amazon Route 53 health check, such as instances within a Virtual Private Cloud (VPC) that only have private IP addresses. Using Amazon Route 53’s calculated health check feature, you can also accomplish more sophisticated failover scenarios by combining the results of metric based health checks with the results of standard Amazon Route 53 health checks, which make requests against an endpoint from a network of checkers around the world. For example, you can create a configuration which fails away from an endpoint if either its public-facing web page is unavailable, or if internal metrics such as CPU load, network in/out, or disk reads show that the server itself is unhealthy."
My web server is receiving requests from a Route 53 health check that I did not create. How can I stop these requests?,"Occasionally, Amazon Route 53 customers create health checks that specify an IP address or domain name that does not belong to them. If your web server is getting unwanted HTTP(s) requests that you have traced to Amazon Route 53 health checks, please provide information on the unwanted health check 
using this form
, and we will work with our customer to fix the problem."
"If I specify a domain name as my health check target, will Amazon Route 53 check over IPv4 or IPv6?","If you specify a domain name as the endpoint of an Amazon Route 53 health check, Amazon Route 53 will look up the IPv4 address of that domain name and will connect to the endpoint using IPv4. Amazon Route 53 will not attempt to look up the IPv6 address for an endpoint that is specified by domain name. If you want to perform a health check over IPv6 instead of IPv4, select ""IP address"" instead of ""domain name"" as your endpoint type, and enter the IPv6 address in the “IP address” field."
Where can I find the IPv6 address ranges for Amazon Route 53’s DNS servers and health checkers?,"AWS now publishes its current IP address ranges in JSON format. To view the current ranges, download the .json file using the following link. If you access this file programmatically, ensure that the application downloads the file only after successfully verifying the TLS certificate that is returned by the AWS server.
Download: 
ip-ranges.json
To find IP ranges for Route 53 servers, search for the following values in the ""service"" field:
Route 53 DNS servers: Search for ""ROUTE53""
Route 53 health checkers: Search for ""ROUTE53_HEALTHCHECKS""
For more information, see 
AWS IP Address Ranges
 in the Amazon Web Services General Reference.
Please note that the IPv6 ranges may not yet appear in this file. For reference, the IPv6 ranges for Amazon Route 53 health checkers are as follows:
2600:1f1c:7ff:f800::/53
 2a05:d018:fff:f800::/53
 2600:1f1e:7ff:f800::/53
 2600:1f1c:fff:f800::/53
 2600:1f18:3fff:f800::/53
 2600:1f14:7ff:f800::/53
 2600:1f14:fff:f800::/53
 2406:da14:7ff:f800::/53
 2406:da14:fff:f800::/53
 2406:da18:7ff:f800::/53
 2406:da1c:7ff:f800::/53
 2406:da1c:fff:f800::/53
 2406:da18:fff:f800::/53
 2600:1f18:7fff:f800::/53
 2a05:d018:7ff:f800::/53
 2600:1f1e:fff:f800::/53
 2620:107:300f::36b7:ff80/122
 2a01:578:3::36e4:1000/122
 2804:800:ff00::36e8:2840/122
 2620:107:300f::36f1:2040/122
 2406:da00:ff00::36f3:1fc0/122
 2620:108:700f::36f4:34c0/122
 2620:108:700f::36f5:a800/122
 2400:6700:ff00::36f8:dc00/122
 2400:6700:ff00::36fa:fdc0/122
 2400:6500:ff00::36fb:1f80/122
 2403:b300:ff00::36fc:4f80/122
 2403:b300:ff00::36fc:fec0/122
 2400:6500:ff00::36ff:fec0/122
 2406:da00:ff00::6b17:ff00/122
 2a01:578:3::b022:9fc0/122
 2804:800:ff00::b147:cf80/122"
Can I register domain names with Amazon Route 53?,"Yes. You can use the AWS Management Console or API to register new domain names with Route 53. You can also request to transfer in existing domain names from other registrars to be managed by Route 53. Domain name registration services are provided under our 
Domain Name Registration Agreement
."
What Top Level Domains (“TLDs”) do you offer?,"Route 53 offers a wide selection of both generic Top Level Domains (“gTLDs”: for example, .com and .net) and country-code Top Level Domains (“ccTLDs”: for example, .de and .fr). For the complete list, please see the 
Route 53 Domain Registration Price List
."
How can I register a domain name with Route 53?,"To get started, log into your account and click on “Domains”. Then, click the big blue “Register Domain” button and complete the registration process."
How long does it take to register a domain name?,"Depending on the TLD you’ve selected, registration can take from a few minutes to several hours. Once the domain is successfully registered, it will show up in your account."
How long is my domain name registered for?,"The initial registration period is typically one year, although the registries for some top-level domains (TLDs) have longer registration periods. When you register a domain with Amazon Route 53 or you transfer domain registration to Amazon Route 53, we configure the domain to renew automatically. For more information, see 
Renewing Registration for a Domain
 in the Amazon Route 53 Developer Guide."
What information do I need to provide to register a domain name?,"In order to register a domain name, you need to provide contact information for the registrant of the domain, including name, address, phone number, and email address. If the administrative and technical contacts are different, you need to provide that contact information, too."
Why do I need to provide personal information to register a domain?,"ICANN, the governing body for domain registration, requires that registrars provide contact information, including name, address, and phone number, for every domain name registration, and that registrars make this information publicly available via a Whois database. For domain names that you register as an individual (i.e., not as a company or organization), Route 53 provides privacy protection, which hides your personal phone number, email address, and physical address, free of charge. Instead, the Whois contains the registrar’s name and mailing address, along with a registrar-generated forwarding email address that third parties may use if they wish to contact you."
Does Route 53 offer privacy protection for domain names I have registered?,"Yes, Route 53 provides privacy protection at no additional charge. The privacy protection hides your phone number, email address, and physical address. Your first and last name will be hidden if the TLD registry and registrar allow it. When you enable privacy protection, a Whois query for the domain will contain the registrar’s mailing address in place of your physical address, and the registrar’s name in place of your name (if allowed). Your email address will be a registrar-generated forwarding email address that third parties may use if they wish to contact you. Domain names registered by companies or organizations are eligible for privacy protection if the TLD registry and registrar allow it."
Where can I find the requirements for specific TLDs?,"For a list of TLDs please see the 
price list
 and for the specific registration requirements for each, please see the 
Amazon Route 53 Developer Guide
 and our 
Domain Name Registration Agreement
."
What name servers are used to register my domain name?,"When your domain name is created we automatically associate your domain with four unique Route 53 name servers, known as a delegation set. You can view the delegation set for your domain in the Amazon Route 53 console. They're listed in the hosted zone that we create for you automatically when you register a domain.
By default, Route 53 will assign a new, unique delegation set for each hosted zone you create. However, you can also use the Route 53 API to create a “reusable delegation set”, which you can then apply to multiple hosted zones that you create. For customers with large numbers of domain names, reusable delegation sets make migration to Route 53 simple, because you can instruct your domain name registrar to use the same delegation set for all your domains managed by Route 53. This feature also makes it possible for you to create “white label” name server addresses such as ns1.example.com, ns2.example.com, etc., which you can point to your Route 53 name servers. You can then use your “white label” name server addresses as the authoritative name servers for as many of your domain names as desired. For more details, see the 
Amazon Route 53 documentation
."
Will I be charged for my name servers?,"You will be charged for the hosted zone that Route 53 creates for your domain name, as well as for the DNS queries against this hosted zone that Route 53 serves on your behalf. If you do not wish to be charged for Route 53’s DNS service, you can delete your Route 53 hosted zone. Please note that some TLDs require you to have valid name servers as part of your domain name registration. For a domain name under one of these TLDs, you will need to procure DNS service from another provider and enter that provider’s name server addresses before you can safely delete your Route 53 hosted zone for that domain name."
"What is Amazon Registrar, Inc. and what is a registrar of record?","AWS resells domain names that are registered with ICANN-accredited registrars. Amazon Registrar, Inc. is an Amazon company that is accredited by ICANN to register domains. The registrar of record is the “Sponsoring Registrar” listed in the WHOIS record for your domain to indicate which registrar your domain is registered with."
Who is Gandi?,"Amazon is a reseller of the registrar Gandi. As the registrar of record, Gandi is required by ICANN to contact the registrant to verify their contact information at the time of initial registration. You MUST verify your contact information if requested by Gandi within the first 15 days of registration in order to prevent your domain name from being suspended. Gandi also sends out reminder notices before the domain comes up for renewal."
Which top-level domains does Amazon Route 53 register through Amazon Registrar and which ones does it register through Gandi?,"See our 
documentation
 for a list of the domains that you can currently register using Amazon Route 53. This list includes information about which registrar is the current registrar of record for each TLD that we sell."
Can I transfer my .com and .net domain registrations from Gandi to Amazon?,No. We plan to add this functionality soon.
What is Whois? Why is my information shown in Whois?,"Whois is a publicly available database for domain names that lists the contact information and the name servers that are associated with a domain name. Anyone can access the Whois database by using the WHOIS command, which is widely available. It's included in many operating systems, and it's also available as a web application on many websites. The Internet Corporation for Assigned Names and Numbers (ICANN) requires that all domain names have publicly available contact information in case someone needs to get in contact with the domain name holder."
How do I transfer my domain name to Route 53?,"To get started, log into your account and click on “Domains”. Then, click the “Transfer Domain” button at the top of the screen and complete the transfer process. Please make sure before you start the transfer process, (1) your domain name is unlocked at your current registrar, (2) you have disabled privacy protection on your domain name (if applicable), and (3) that you have obtained the valid Authorization Code, or “authcode”, from your current registrar which you will need to enter as part of the transfer process."
How do I transfer my existing domain name registration to Amazon Route 53 without disrupting my existing web traffic?,"First, you need to get a list of the DNS record data for your domain name, generally available in the form of a “zone file” that you can get from your existing DNS provider. With the DNS record data in hand, you can use Route 53’s Management Console or simple web-services interface to create a hosted zone that can store the DNS records for your domain name and follow its transfer process, which will include such steps as updating the name servers for your domain name to the ones associated with your hosted zone. To complete the domain name transfer process, contact the registrar with whom you registered your domain name and follow its transfer process, which will include steps such as updating the name servers for your domain name to the ones associated with your hosted zone. As soon as your registrar propagates the new name server delegations, the DNS queries from your end users will start to get answered by the Route 53 DNS servers."
How do I check on the status of my transfer request?,You can view the status of domain name transfers in the “Alerts” section on the homepage of the Route 53 console.
What do I do if my transfer wasn’t successful?,"You will need to contact your current registrar in order to determine why your transfer failed. Once they have resolved the issue, you can resubmit your transfer request."
How do I transfer my domain name to a different registrar?,"In order to move your domain name away from Route 53, you need to initiate a transfer request with your new registrar. They will request the domain name be moved to their management."
Is there a limit to the number of domains I can manage using Amazon Route 53?,"Each new Amazon Route 53 account is limited to a maximum of 50 domains. Complete our 
request form for a higher limit
 and we will respond to your request within two business days."
Does Amazon Route 53 DNS support DNSSEC?,"Amazon Route 53’s DNS services does NOT support DNSSEC at this time. However, our domain name registration service supports configuration of signed DNSSEC keys for domains when DNS service is configured at another provider. More information on configuring DNSSEC for your domain name registration can be found 
here
."
Hello,Hello
How are you?,I’m fine thanks.
Good morning,"Hello, good morning."
Bye,"Bye, glad to have helped."
